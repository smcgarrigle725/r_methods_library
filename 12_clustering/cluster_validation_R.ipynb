{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "R", "language": "R", "name": "ir"},
  "language_info": {"name": "R"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01-overview",
   "metadata": {},
   "source": [
    "# Cluster Validation: Internal and Relative Metrics\n",
    "\n",
    "## Overview\n",
    "\n",
    "Clustering is unsupervised — there is no ground truth to compare against in practice. Validation metrics assess cluster quality without labels, using only the data and cluster assignments.\n",
    "\n",
    "**Three categories:**\n",
    "\n",
    "| Category | What it measures | When to use |\n",
    "|---|---|---|\n",
    "| **Internal** | Compactness and separation using only data | Primary tool; always compute |\n",
    "| **Relative** | Compare solutions across k or algorithms | Choosing k; comparing methods |\n",
    "| **External** | Agreement with known labels | When ground truth exists (research/benchmarking) |\n",
    "\n",
    "**Internal metrics reference:**\n",
    "\n",
    "| Metric | Formula intuition | Better when | Range |\n",
    "|---|---|---|---|\n",
    "| **Silhouette width** | (between − within) / max | Closer to 1 | [−1, 1] |\n",
    "| **Calinski-Harabasz (CH)** | Between-cluster SS / within-cluster SS | Higher | [0, ∞) |\n",
    "| **Davies-Bouldin (DB)** | Mean of worst-case cluster similarity ratios | Lower | [0, ∞) |\n",
    "| **Dunn index** | Min inter-cluster / max intra-cluster distance | Higher | [0, ∞) |\n",
    "\n",
    "No single metric is universally best — use multiple and look for agreement.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02-setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(cluster)       # silhouette()\n",
    "library(clusterSim)    # index.DB() Davies-Bouldin\n",
    "library(fpc)           # cluster.stats() — CH, Dunn, many more\n",
    "library(factoextra)\n",
    "library(patchwork)\n",
    "library(mclust)        # adjustedRandIndex()\n",
    "\n",
    "set.seed(42)\n",
    "\n",
    "# ── Simulate data with 3 known clusters ───────────────────────────────────────\n",
    "n_per <- 80\n",
    "val_data <- bind_rows(\n",
    "  tibble(nitrate=rnorm(n_per,2,0.6),  water_qual=rnorm(n_per,8,0.7),\n",
    "         phosphorus=rnorm(n_per,0.3,0.1), turbidity=rnorm(n_per,3,0.9),\n",
    "         true_group=\"reference\"),\n",
    "  tibble(nitrate=rnorm(n_per,5.5,0.7),water_qual=rnorm(n_per,5,0.8),\n",
    "         phosphorus=rnorm(n_per,0.8,0.15),turbidity=rnorm(n_per,8,1.2),\n",
    "         true_group=\"restored\"),\n",
    "  tibble(nitrate=rnorm(n_per,9,0.9),  water_qual=rnorm(n_per,2.5,0.8),\n",
    "         phosphorus=rnorm(n_per,1.6,0.25),turbidity=rnorm(n_per,16,2),\n",
    "         true_group=\"degraded\")\n",
    ")\n",
    "\n",
    "X     <- val_data %>% select(nitrate, water_qual, phosphorus, turbidity)\n",
    "X_sc  <- scale(X)\n",
    "d_mat <- dist(X_sc)\n",
    "\n",
    "# Pre-fit k-means for k = 2..8\n",
    "km_list <- map(2:8, ~kmeans(X_sc, centers=.x, nstart=25, iter.max=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03-silhouette",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Silhouette Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03-sil-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette width for observation i:\n",
    "# s(i) = (b(i) - a(i)) / max(a(i), b(i))\n",
    "# a(i) = mean distance to observations in same cluster (compactness)\n",
    "# b(i) = mean distance to observations in nearest other cluster (separation)\n",
    "\n",
    "sil_scores <- map_dbl(km_list, function(km) {\n",
    "  mean(cluster::silhouette(km$cluster, d_mat)[, 3])\n",
    "})\n",
    "\n",
    "# Per-observation silhouette for k=3\n",
    "km3  <- km_list[[2]]   # k=3 is index 2 (k=2..8)\n",
    "sil3 <- cluster::silhouette(km3$cluster, d_mat)\n",
    "\n",
    "p_sil_bar <- tibble(k=2:8, silhouette=sil_scores) %>%\n",
    "  ggplot(aes(x=k, y=silhouette, fill=silhouette==max(silhouette))) +\n",
    "  geom_col(alpha=0.85) +\n",
    "  scale_fill_manual(values=c(\"FALSE\"=\"#4a8fff\",\"TRUE\"=\"#ff6b6b\"), guide=\"none\") +\n",
    "  scale_x_continuous(breaks=2:8) +\n",
    "  labs(title=\"Mean Silhouette Width by k\",\n",
    "       subtitle=\"Red = optimal k; higher is better\",\n",
    "       x=\"k\", y=\"Mean silhouette width\") +\n",
    "  theme_minimal()\n",
    "\n",
    "p_sil_plot <- factoextra::fviz_silhouette(sil3, palette=\"jco\",\n",
    "                                           ggtheme=theme_minimal()) +\n",
    "  labs(title=\"Silhouette Plot: k=3\",\n",
    "       subtitle=\"Negative = misassigned; all bars same sign = well-separated clusters\")\n",
    "\n",
    "(p_sil_bar | p_sil_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04-ch-db",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Calinski-Harabasz and Davies-Bouldin Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04-ch-db-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── All metrics across k using fpc::cluster.stats() ──────────────────────────\n",
    "metrics_df <- map_dfr(km_list, function(km) {\n",
    "  cs <- fpc::cluster.stats(d_mat, km$cluster)\n",
    "  tibble(\n",
    "    k              = max(km$cluster),\n",
    "    silhouette     = cs$avg.silwidth,\n",
    "    calinski_harabasz = cs$ch,          # between / within SS ratio; higher = better\n",
    "    dunn           = cs$dunn,           # min inter / max intra; higher = better\n",
    "    within_ss      = cs$within.cluster.ss\n",
    "  )\n",
    "})\n",
    "\n",
    "# Davies-Bouldin: mean of max within/between ratio; lower = better\n",
    "metrics_df$davies_bouldin <- map_dbl(km_list, function(km) {\n",
    "  clusterSim::index.DB(X_sc, km$cluster)$DB\n",
    "})\n",
    "\n",
    "print(metrics_df %>% mutate(across(where(is.numeric), ~round(.x, 4))))\n",
    "\n",
    "# ── Plot all metrics ──────────────────────────────────────────────────────────\n",
    "metrics_long <- metrics_df %>%\n",
    "  select(k, silhouette, calinski_harabasz, davies_bouldin, dunn) %>%\n",
    "  pivot_longer(-k, names_to=\"metric\", values_to=\"value\") %>%\n",
    "  mutate(better = case_when(\n",
    "    metric %in% c(\"silhouette\",\"calinski_harabasz\",\"dunn\") ~ \"higher\",\n",
    "    metric == \"davies_bouldin\" ~ \"lower\"\n",
    "  ))\n",
    "\n",
    "ggplot(metrics_long, aes(x=k, y=value)) +\n",
    "  geom_line(color=\"#4a8fff\", linewidth=1) +\n",
    "  geom_point(size=2.5, color=\"#4a8fff\") +\n",
    "  facet_wrap(~metric, scales=\"free_y\", ncol=2,\n",
    "             labeller=labeller(metric=c(\n",
    "               silhouette=\"Silhouette (↑)\",\n",
    "               calinski_harabasz=\"Calinski-Harabasz (↑)\",\n",
    "               davies_bouldin=\"Davies-Bouldin (↓)\",\n",
    "               dunn=\"Dunn Index (↑)\"\n",
    "             ))) +\n",
    "  scale_x_continuous(breaks=2:8) +\n",
    "  labs(title=\"Cluster Validation Metrics Across k\",\n",
    "       subtitle=\"Look for agreement: optimal k should be optimal on multiple metrics\",\n",
    "       x=\"k\", y=\"Value\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05-external",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## External Validation: When Ground Truth Exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05-external-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# External metrics compare cluster assignments to known labels\n",
    "# Only valid in research/benchmarking contexts — not available in practice\n",
    "\n",
    "true_labels <- as.integer(factor(val_data$true_group))\n",
    "\n",
    "ext_metrics <- map_dfr(km_list, function(km) {\n",
    "  cs <- fpc::cluster.stats(d_mat, km$cluster, alt.clustering=true_labels)\n",
    "  tibble(\n",
    "    k   = max(km$cluster),\n",
    "    ari = mclust::adjustedRandIndex(km$cluster, true_labels),  # [-1,1]; 1=perfect\n",
    "    vi  = cs$vi   # variation of information; lower = better\n",
    "  )\n",
    "})\n",
    "\n",
    "print(ext_metrics %>% mutate(across(where(is.numeric), ~round(.x, 4))))\n",
    "\n",
    "# ARI interpretation:\n",
    "# 1.0 = perfect agreement with true labels\n",
    "# 0.0 = no better than random assignment\n",
    "# Negative = worse than random (unusual; usually a sign of k mismatch)\n",
    "\n",
    "# Contingency table for k=3\n",
    "cat(\"\\nContingency table (k=3 vs. true groups):\\n\")\n",
    "print(table(cluster=km3$cluster, true_group=val_data$true_group))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06-pitfalls",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "**1. Using a single validation metric to choose k**  \n",
    "Each metric captures a different aspect of cluster quality and can disagree. Silhouette favours compact, well-separated clusters; CH can be biased toward larger k; DB can be fooled by non-convex shapes. Always compute at least three metrics and require agreement before concluding on k.\n",
    "\n",
    "**2. Applying internal validation metrics without understanding their assumptions**  \n",
    "All three primary metrics (silhouette, CH, DB) assume clusters are convex and relatively compact. They will systematically underperform for DBSCAN results on irregular shapes, or for GMM components with very different orientations. The metric and the clustering algorithm should be aligned in their geometric assumptions.\n",
    "\n",
    "**3. Conflating high silhouette with meaningful clusters**  \n",
    "A solution with silhouette = 0.75 indicates that the clusters are well-separated *relative to each other*, not that the clusters correspond to real-world groupings. Always validate cluster interpretability with domain knowledge and descriptive profiling — see `cluster_profiling.ipynb`.\n",
    "\n",
    "**4. Using external validation as the primary criterion in exploratory clustering**  \n",
    "If known labels exist and you optimise k to maximise ARI against them, you are doing supervised classification, not unsupervised clustering. External validation is legitimate for benchmarking algorithms but not for choosing the final k in applied work.\n",
    "\n",
    "**5. Not checking whether the \"best\" k is sensitive to small changes in the data**  \n",
    "Stability analysis — rerunning clustering on bootstrap subsamples and measuring ARI between solutions — is a valuable complement to metric-based selection. If the optimal k changes frequently across subsamples, the cluster structure is unstable and may not be reliable.\n",
    "\n",
    "---\n",
    "*r_methods_library · Samantha McGarrigle · [github.com/samantha-mcgarrigle](https://github.com/samantha-mcgarrigle)*"
   ]
  }
 ]
}"
