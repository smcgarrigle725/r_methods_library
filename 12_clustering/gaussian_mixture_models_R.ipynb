{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "R", "language": "R", "name": "ir"},
  "language_info": {"name": "R"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01-overview",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Models with `mclust`\n",
    "\n",
    "## Overview\n",
    "\n",
    "Gaussian Mixture Models (GMMs) model the data as a weighted sum of k Gaussian distributions. Unlike k-means, they produce **soft assignments** — each observation has a probability of belonging to each cluster — and allow clusters of different shapes, sizes, and orientations.\n",
    "\n",
    "**GMM vs. k-means:**\n",
    "\n",
    "| Feature | k-Means | GMM |\n",
    "|---|---|---|\n",
    "| Assignment | Hard (one cluster) | Soft (probabilities) |\n",
    "| Cluster shape | Spherical only | Elliptical (all orientations) |\n",
    "| Cluster size | Equal assumed | Variable |\n",
    "| Model selection | Elbow / silhouette | BIC (automatic) |\n",
    "| Probabilistic | No | Yes |\n",
    "\n",
    "**`mclust` model notation:** Models are parameterised by three properties:\n",
    "- **Volume (E/V):** Equal or Variable cluster volume\n",
    "- **Shape (E/V):** Equal or Variable cluster shape\n",
    "- **Orientation (I/E/V):** Identity, Equal, or Variable cluster orientation\n",
    "\n",
    "e.g. `EEE` = equal volume, shape, orientation (spherical clusters); `VVV` = fully flexible.\n",
    "\n",
    "`mclust` automatically selects both k and the covariance model by maximising BIC.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02-setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(mclust)        # Mclust(), densityMclust(), mclustBIC()\n",
    "library(patchwork)\n",
    "\n",
    "set.seed(42)\n",
    "\n",
    "# ── Simulate: clusters with different shapes and orientations ─────────────────\n",
    "n_per <- 100\n",
    "\n",
    "MASS_mvrnorm <- function(n, mu, Sigma) {\n",
    "  MASS::mvrnorm(n=n, mu=mu, Sigma=Sigma)\n",
    "}\n",
    "\n",
    "gmm_data <- bind_rows(\n",
    "  # Cluster 1: elongated, NE orientation\n",
    "  as_tibble(MASS_mvrnorm(n_per, c(2,6), matrix(c(1.5,1.1,1.1,0.8),2))) %>%\n",
    "    setNames(c(\"nitrate\",\"water_qual\")) %>% mutate(group=\"reference\"),\n",
    "  # Cluster 2: small, spherical\n",
    "  as_tibble(MASS_mvrnorm(n_per, c(6,5), matrix(c(0.4,0,0,0.4),2))) %>%\n",
    "    setNames(c(\"nitrate\",\"water_qual\")) %>% mutate(group=\"restored\"),\n",
    "  # Cluster 3: large, elongated, NW orientation\n",
    "  as_tibble(MASS_mvrnorm(n_per, c(9,3), matrix(c(1.5,-1.0,-1.0,0.9),2))) %>%\n",
    "    setNames(c(\"nitrate\",\"water_qual\")) %>% mutate(group=\"degraded\")\n",
    ")\n",
    "\n",
    "X <- gmm_data %>% select(nitrate, water_qual) %>% as.matrix()\n",
    "\n",
    "ggplot(gmm_data, aes(x=nitrate, y=water_qual, color=group)) +\n",
    "  geom_point(alpha=0.6, size=1.5) +\n",
    "  scale_color_manual(values=c(reference=\"#4a8fff\",restored=\"#4fffb0\",degraded=\"#ff6b6b\")) +\n",
    "  labs(title=\"Simulated Data: Different Cluster Shapes and Orientations\",\n",
    "       x=\"Nitrate\", y=\"Water quality\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03-fit",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Fit GMM with Automatic Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03-fit-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mclust fits all combinations of covariance models and k=1..9\n",
    "# Selects the best by BIC (higher = better in mclust's convention)\n",
    "gmm_fit <- mclust::Mclust(X, G=1:9)\n",
    "\n",
    "cat(sprintf(\"Selected model: %s\\n\",  gmm_fit$modelName))\n",
    "cat(sprintf(\"Selected k:     %d\\n\",  gmm_fit$G))\n",
    "cat(sprintf(\"BIC:            %.1f\\n\", gmm_fit$bic))\n",
    "\n",
    "# ── BIC plot across all models ────────────────────────────────────────────────\n",
    "plot(gmm_fit, what=\"BIC\")\n",
    "# Each line = one covariance model; each point = one k\n",
    "# Model with highest BIC (top right) is selected\n",
    "\n",
    "# ── Cluster summary ───────────────────────────────────────────────────────────\n",
    "summary(gmm_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04-soft",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Soft Assignments and Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04-soft-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Classification: hard assignments ─────────────────────────────────────────\n",
    "hard_clusters <- gmm_fit$classification\n",
    "\n",
    "# ── Probabilities: soft assignments ──────────────────────────────────────────\n",
    "probs <- gmm_fit$z   # n × k matrix of cluster membership probabilities\n",
    "\n",
    "# Uncertainty: 1 - max probability (how confident is the assignment?)\n",
    "uncertainty <- apply(probs, 1, function(p) 1 - max(p))\n",
    "\n",
    "results <- gmm_data %>%\n",
    "  mutate(\n",
    "    cluster     = factor(hard_clusters),\n",
    "    uncertainty = uncertainty\n",
    "  )\n",
    "\n",
    "# Plot: uncertainty as point transparency\n",
    "p_hard <- ggplot(results, aes(x=nitrate, y=water_qual, color=cluster)) +\n",
    "  geom_point(size=1.5, alpha=0.8) +\n",
    "  scale_color_manual(values=c(\"#4a8fff\",\"#4fffb0\",\"#ff6b6b\")) +\n",
    "  labs(title=\"Hard Assignments\", color=\"Cluster\") + theme_minimal()\n",
    "\n",
    "p_uncert <- ggplot(results, aes(x=nitrate, y=water_qual,\n",
    "                                 color=cluster, alpha=1-uncertainty)) +\n",
    "  geom_point(size=1.5) +\n",
    "  scale_color_manual(values=c(\"#4a8fff\",\"#4fffb0\",\"#ff6b6b\")) +\n",
    "  scale_alpha_continuous(range=c(0.15, 1), name=\"Confidence\") +\n",
    "  labs(title=\"Assignment Uncertainty\",\n",
    "       subtitle=\"Faded = uncertain; concentrated near boundaries\",\n",
    "       color=\"Cluster\") + theme_minimal()\n",
    "\n",
    "(p_hard | p_uncert)\n",
    "\n",
    "cat(sprintf(\"\\nMean uncertainty: %.4f\\n\", mean(uncertainty)))\n",
    "cat(sprintf(\"Observations >10%% uncertainty: %d (%.1f%%)\\n\",\n",
    "            sum(uncertainty>0.1), mean(uncertainty>0.1)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05-density",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Density Estimation and Classification Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05-density-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the fitted GMM density contours\n",
    "plot(gmm_fit, what=\"classification\")\n",
    "title(\"GMM Classification with Fitted Ellipses\",\n",
    "      sub=\"Ellipses = 2 SD contours of each Gaussian component\")\n",
    "\n",
    "# Uncertainty plot (mclust built-in)\n",
    "plot(gmm_fit, what=\"uncertainty\")\n",
    "title(\"Assignment Uncertainty Map\",\n",
    "      sub=\"Darker = more uncertain; uncertainty concentrated at cluster boundaries\")\n",
    "\n",
    "# Agreement with true groups\n",
    "cat(\"\\nContingency table (GMM cluster vs. true group):\\n\")\n",
    "print(table(GMM=results$cluster, true=gmm_data$group))\n",
    "\n",
    "# Adjusted Rand Index: 1 = perfect agreement, 0 = random\n",
    "ari <- mclust::adjustedRandIndex(gmm_fit$classification, gmm_data$group)\n",
    "cat(sprintf(\"Adjusted Rand Index: %.4f\\n\", ari))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06-pitfalls",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "**1. Assuming BIC always selects the correct number of clusters**  \n",
    "BIC selects the model that best balances fit and complexity given the Gaussian assumption. If the true clusters are non-Gaussian (e.g. skewed, multimodal within cluster), BIC may select more components than expected to approximate the non-Gaussian shape. Always validate the selected k with domain knowledge and silhouette scores.\n",
    "\n",
    "**2. Not examining the uncertainty of assignments**  \n",
    "GMMs produce soft assignments, but analysts often use only the hard classifications. Observations with high uncertainty (near cluster boundaries) should be flagged — they may represent genuinely intermediate cases, transitional states, or poor model fit in that region.\n",
    "\n",
    "**3. Using GMMs with non-Gaussian features without transformation**  \n",
    "GMMs assume multivariate normality within each cluster. Highly skewed features (e.g. concentrations, counts) should be log-transformed before fitting. Check within-cluster normality after fitting using Q-Q plots on each component.\n",
    "\n",
    "**4. Over-interpreting the covariance model selected by BIC**  \n",
    "The selected model (e.g. `VVV` = unconstrained) reflects the BIC-optimal representation of the data, not necessarily the true data-generating process. Models within 2 BIC units of the best are plausible alternatives — check whether cluster assignments are similar across competitive models.\n",
    "\n",
    "**5. Ignoring cluster degeneracy warnings**  \n",
    "A degenerate solution occurs when a cluster collapses to a single point (zero variance). This produces infinite likelihood and invalid results. If `mclust` reports a degenerate solution for some k values, reduce the maximum k or inspect the data for near-duplicate observations.\n",
    "\n",
    "---\n",
    "*r_methods_library · Samantha McGarrigle · [github.com/samantha-mcgarrigle](https://github.com/samantha-mcgarrigle)*"
   ]
  }
 ]
}"
