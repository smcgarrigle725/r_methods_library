{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "R", "language": "R", "name": "ir"},
  "language_info": {"name": "R"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01-overview",
   "metadata": {},
   "source": [
    "# Principal Components Analysis (PCA)\n",
    "\n",
    "## Overview\n",
    "\n",
    "PCA finds the orthogonal linear combinations of features (principal components) that successively maximise variance. The first PC captures the most variance, the second the most of what remains, and so on.\n",
    "\n",
    "**Key outputs:**\n",
    "\n",
    "| Output | What it tells you |\n",
    "|---|---|\n",
    "| **Eigenvalues / scree plot** | How much variance each PC explains |\n",
    "| **Loadings** | Which features contribute most to each PC; direction of association |\n",
    "| **Scores** | Each observation's position in PC space |\n",
    "| **Biplot** | Observations and variable vectors in the same plot |\n",
    "\n",
    "**PCA vs. factor analysis:** PCA is a variance decomposition — it explains variance in the observed variables. Factor analysis models latent variables that cause covariance among observed variables. Use PCA for dimensionality reduction and visualisation; use FA when latent constructs are the target of inference.\n",
    "\n",
    "**Scaling:** PCA on unscaled data is dominated by high-variance features. Always scale to unit variance unless features are on commensurable scales (e.g. all measurements in the same unit).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02-setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(factoextra)    # fviz_pca_*(), fviz_eig()\n",
    "library(ggfortify)     # autoplot() for prcomp\n",
    "library(patchwork)\n",
    "\n",
    "set.seed(42)\n",
    "\n",
    "# ── Simulate: 200 water quality monitoring sites, 8 measurements ──────────────\n",
    "n <- 200\n",
    "pca_data <- tibble(\n",
    "  nitrate      = rnorm(n, 4, 1.5),\n",
    "  phosphorus   = nitrate * 0.15 + rnorm(n, 0, 0.2),   # correlated with nitrate\n",
    "  ammonia      = nitrate * 0.08 + rnorm(n, 0, 0.1),\n",
    "  turbidity    = nitrate * 2.5  + rnorm(n, 0, 2),\n",
    "  water_qual   = 10 - nitrate * 0.6 + rnorm(n, 0, 0.8),\n",
    "  dissolved_O2 = water_qual * 0.9 + rnorm(n, 0, 0.5),  # correlated with WQ\n",
    "  conductivity = nitrate * 30 + rnorm(n, 100, 20),\n",
    "  pH           = 7.5 - nitrate * 0.1 + rnorm(n, 0, 0.3),\n",
    "  site_type    = factor(sample(c(\"reference\",\"restored\",\"degraded\"), n,\n",
    "                               replace=TRUE, prob=c(.35,.35,.30)))\n",
    ")\n",
    "\n",
    "X <- pca_data %>% select(-site_type)\n",
    "cat(sprintf(\"%d observations × %d features\\n\", nrow(X), ncol(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03-fit",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Fit PCA and Inspect Variance Explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03-fit-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# center=TRUE, scale.=TRUE: standardise to zero mean and unit variance\n",
    "pca_fit <- prcomp(X, center=TRUE, scale.=TRUE)\n",
    "\n",
    "# Variance explained\n",
    "var_exp <- pca_fit$sdev^2 / sum(pca_fit$sdev^2)\n",
    "cum_var <- cumsum(var_exp)\n",
    "\n",
    "var_df <- tibble(\n",
    "  PC     = paste0(\"PC\", seq_along(var_exp)),\n",
    "  var    = var_exp * 100,\n",
    "  cumvar = cum_var * 100\n",
    ")\n",
    "print(round(var_df, 2))\n",
    "\n",
    "# PCs needed to explain 80% and 90% of variance\n",
    "cat(sprintf(\"\\nPCs for 80%% variance: %d\\n\", which(cum_var >= 0.80)[1]))\n",
    "cat(sprintf(\"PCs for 90%% variance: %d\\n\", which(cum_var >= 0.90)[1]))\n",
    "\n",
    "# ── Scree plot ────────────────────────────────────────────────────────────────\n",
    "p_scree <- factoextra::fviz_eig(\n",
    "  pca_fit, addlabels=TRUE, ncp=8,\n",
    "  barfill=\"#4a8fff\", barcolor=NA, linecolor=\"#ff6b6b\"\n",
    ") +\n",
    "  geom_hline(yintercept=100/ncol(X), linetype=\"dashed\", color=\"gray50\") +\n",
    "  labs(title=\"Scree Plot\",\n",
    "       subtitle=sprintf(\"Dashed = equal-share threshold (%.1f%%); keep PCs above it\",\n",
    "                        100/ncol(X))) +\n",
    "  theme_minimal()\n",
    "\n",
    "p_cumvar <- ggplot(var_df, aes(x=PC, y=cumvar, group=1)) +\n",
    "  geom_line(color=\"#4a8fff\", linewidth=1) +\n",
    "  geom_point(size=3, color=\"#4a8fff\") +\n",
    "  geom_hline(yintercept=c(80,90), linetype=\"dashed\", color=\"gray50\") +\n",
    "  labs(title=\"Cumulative Variance Explained\",\n",
    "       subtitle=\"Dashed = 80% and 90% thresholds\",\n",
    "       x=\"PC\", y=\"Cumulative variance (%)\") +\n",
    "  theme_minimal()\n",
    "\n",
    "(p_scree | p_cumvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04-loadings",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Loadings: What Does Each PC Represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04-load-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loadings = correlation between each original variable and the PC\n",
    "# (when data is scaled; otherwise divide by sdev)\n",
    "loadings <- as_tibble(pca_fit$rotation[, 1:4], rownames=\"feature\") %>%\n",
    "  mutate(across(where(is.numeric), ~round(.x, 3)))\n",
    "print(loadings)\n",
    "\n",
    "# ── Loading heatmap ───────────────────────────────────────────────────────────\n",
    "loadings %>%\n",
    "  pivot_longer(-feature, names_to=\"PC\", values_to=\"loading\") %>%\n",
    "  ggplot(aes(x=PC, y=fct_rev(feature), fill=loading)) +\n",
    "  geom_tile(color=\"white\", linewidth=0.4) +\n",
    "  geom_text(aes(label=round(loading,2),\n",
    "                color=abs(loading)>0.35), size=3.2) +\n",
    "  scale_fill_gradient2(low=\"#d73027\", mid=\"white\", high=\"#1a9641\",\n",
    "                        midpoint=0, limits=c(-1,1)) +\n",
    "  scale_color_manual(values=c(\"TRUE\"=\"white\",\"FALSE\"=\"gray30\"), guide=\"none\") +\n",
    "  labs(title=\"PCA Loadings: PC1–PC4\",\n",
    "       subtitle=\"Green = positive association; red = negative; bold = |loading| > 0.35\",\n",
    "       x=NULL, y=NULL, fill=\"Loading\") +\n",
    "  theme_minimal()\n",
    "\n",
    "# Interpretation:\n",
    "# Features with large absolute loadings on a PC define what that PC measures\n",
    "# Opposite signs = inverse relationship within the PC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05-biplot",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Biplot: Observations + Variable Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05-biplot-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biplot: observations (points) + variables (arrows) in same PC space\n",
    "# Arrow direction: high values of that variable → observations in that direction\n",
    "# Arrow length: contribution to this plane\n",
    "# Arrow angle: correlation (small angle = high positive correlation)\n",
    "\n",
    "factoextra::fviz_pca_biplot(\n",
    "  pca_fit,\n",
    "  habillage    = pca_data$site_type,\n",
    "  palette      = c(\"#4a8fff\",\"#4fffb0\",\"#ff6b6b\"),\n",
    "  addEllipses  = TRUE, ellipse.type=\"convex\",\n",
    "  label        = \"var\",\n",
    "  col.var      = \"gray30\",\n",
    "  alpha.ind    = 0.55,\n",
    "  repel        = TRUE,\n",
    "  ggtheme      = theme_minimal()\n",
    ") +\n",
    "  labs(\n",
    "    title    = \"PCA Biplot\",\n",
    "    subtitle = sprintf(\"PC1: %.1f%% | PC2: %.1f%% | Combined: %.1f%%\",\n",
    "                       var_exp[1]*100, var_exp[2]*100,\n",
    "                       (var_exp[1]+var_exp[2])*100)\n",
    "  )\n",
    "\n",
    "# ── Contribution plot: which variables drive PC1 and PC2? ─────────────────────\n",
    "p_c1 <- factoextra::fviz_contrib(pca_fit, choice=\"var\", axes=1, top=8,\n",
    "                                   fill=\"#4a8fff\", color=NA) +\n",
    "  theme_minimal() + labs(title=\"Contributions to PC1\")\n",
    "p_c2 <- factoextra::fviz_contrib(pca_fit, choice=\"var\", axes=2, top=8,\n",
    "                                   fill=\"#ff6b6b\", color=NA) +\n",
    "  theme_minimal() + labs(title=\"Contributions to PC2\")\n",
    "(p_c1 | p_c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06-scores",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PC Scores and Downstream Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06-scores-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PC scores: each observation's coordinates in PC space\n",
    "scores_df <- as_tibble(pca_fit$x) %>%\n",
    "  bind_cols(site_type=pca_data$site_type)\n",
    "\n",
    "# Use scores as features in a downstream model\n",
    "# Select PCs explaining >= 80% variance\n",
    "n_pcs <- which(cum_var >= 0.80)[1]\n",
    "pc_features <- scores_df %>% select(PC1:all_of(paste0(\"PC\", n_pcs)))\n",
    "cat(sprintf(\"Using %d PCs as features (%.1f%% variance)\\n\",\n",
    "            n_pcs, cum_var[n_pcs]*100))\n",
    "\n",
    "# Predict new observations using the fitted PCA\n",
    "new_sites <- tibble(\n",
    "  nitrate=c(2.1, 8.5), phosphorus=c(0.3, 1.2), ammonia=c(0.15, 0.7),\n",
    "  turbidity=c(5, 22), water_qual=c(9.1, 3.2), dissolved_O2=c(8.8, 4.5),\n",
    "  conductivity=c(160, 380), pH=c(7.6, 6.9)\n",
    ")\n",
    "new_scores <- predict(pca_fit, newdata=new_sites)\n",
    "cat(\"\\nNew site PC scores:\\n\")\n",
    "print(round(new_scores[, 1:3], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07-pitfalls",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "**1. Not scaling features before PCA**  \n",
    "PCA maximises variance. A feature with SD = 100 dominates a feature with SD = 0.1 regardless of biological importance. Always use `scale.=TRUE` unless all features are in the same unit and comparable scales. Inspect feature variances with `apply(X, 2, var)` before deciding.\n",
    "\n",
    "**2. Choosing the number of PCs by the Kaiser criterion alone**  \n",
    "Kaiser's rule (retain PCs with eigenvalue > 1) was developed for factor analysis of correlation matrices and is a poor general guide. Use the scree plot elbow, the equal-share threshold (eigenvalue > mean eigenvalue), and cumulative variance (80–90%) together. The right number of PCs is context-dependent.\n",
    "\n",
    "**3. Interpreting PC axes as if they are unique**  \n",
    "PCA loadings are not unique — any rotation of the PC space explains exactly the same total variance. Varimax rotation (used in factor analysis) often produces more interpretable axes. If interpretation is the primary goal, consider `psych::principal()` with rotation.\n",
    "\n",
    "**4. Applying PCA to the test set using test set statistics**  \n",
    "When using PCA as a preprocessing step before modelling, the centering and scaling statistics must come from the training set only. Use `predict(pca_fit, newdata=test)` — this applies the training-set rotation without recomputing statistics from test data.\n",
    "\n",
    "**5. Reporting biplot interpretation for PC1+PC2 when they explain little variance**  \n",
    "A biplot of PC1 vs. PC2 is only meaningful if those two PCs capture substantial variance. If PC1 + PC2 explain only 35%, the biplot shows a small and potentially misleading slice of the structure. Report the percentage explained prominently and consider PC3 vs. PC4 or 3D biplots.\n",
    "\n",
    "---\n",
    "*r_methods_library · Samantha McGarrigle · [github.com/samantha-mcgarrigle](https://github.com/samantha-mcgarrigle)*"
   ]
  }
 ]
}"
