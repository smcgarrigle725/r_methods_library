{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "R", "language": "R", "name": "ir"},
  "language_info": {"name": "R"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01-overview",
   "metadata": {},
   "source": [
    "# MCMC Diagnostics in R\n",
    "\n",
    "## Overview\n",
    "\n",
    "MCMC diagnostics confirm that the sampler has explored the posterior distribution adequately. A converged chain has: (1) mixed well across the parameter space, (2) reached its stationary distribution, and (3) produced enough effective samples for reliable inference.\n",
    "\n",
    "**Core diagnostics:**\n",
    "\n",
    "| Diagnostic | What it checks | Threshold |\n",
    "|---|---|---|\n",
    "| **Trace plot** | Visual: chains mixing and overlapping | Caterpillar shape; no drift or sticking |\n",
    "| **R-hat** ($\\hat{R}$) | Between-chain vs. within-chain variance | < 1.01 (strict); < 1.05 (lenient) |\n",
    "| **Bulk ESS** | Effective samples in the centre of the posterior | > 400 per parameter; > 100 × n_chains |\n",
    "| **Tail ESS** | Effective samples in the tails (for CI reliability) | > 400 per parameter |\n",
    "| **Energy / BFMI** | HMC-specific: geometry of the posterior | BFMI > 0.3 |\n",
    "| **Divergences** | HMC-specific: sampler got lost | 0 divergences after warmup |\n",
    "| **Posterior predictive check** | Model adequacy, not just sampler adequacy | Simulated data resembles observed |\n",
    "\n",
    "**Important distinction:** Convergence diagnostics confirm the *sampler* worked. Posterior predictive checks confirm the *model* is adequate. Both are necessary.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02-setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(brms)\n",
    "library(bayesplot)   # mcmc_trace(), mcmc_acf(), mcmc_rhat(), ppc_*\n",
    "library(posterior)   # rhat(), ess_bulk(), ess_tail() — modern interface\n",
    "library(patchwork)\n",
    "\n",
    "set.seed(42)\n",
    "\n",
    "# ── Fit a well-behaved model ──────────────────────────────────────────────────\n",
    "n <- 100\n",
    "diag_data <- tibble(\n",
    "  x = rnorm(n),\n",
    "  y = 5 + 2*x + rnorm(n)\n",
    ")\n",
    "\n",
    "m_good <- brm(\n",
    "  y ~ x, data=diag_data, family=gaussian(),\n",
    "  prior=c(prior(normal(5,5), class=Intercept),\n",
    "          prior(normal(0,3),  class=b),\n",
    "          prior(exponential(1), class=sigma)),\n",
    "  chains=4, iter=3000, warmup=1000, cores=4, seed=42, silent=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03-trace",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Trace Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03-trace-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract posterior draws as array (chains × iterations × parameters)\n",
    "draws_array <- as.array(m_good)\n",
    "params      <- c(\"b_Intercept\",\"b_x\",\"sigma\")\n",
    "\n",
    "# ── Trace plot ────────────────────────────────────────────────────────────────\n",
    "bayesplot::mcmc_trace(draws_array, pars=params,\n",
    "                      facet_args=list(ncol=1)) +\n",
    "  labs(title=\"Trace Plots\",\n",
    "       subtitle=\"Good: all 4 chains overlap; bad: drift, sticking, or non-overlap\") +\n",
    "  theme_minimal()\n",
    "\n",
    "# ── Rank plot (alternative to trace — better for detecting non-mixing) ────────\n",
    "bayesplot::mcmc_rank_overlay(draws_array, pars=params) +\n",
    "  labs(title=\"Rank Plots\",\n",
    "       subtitle=\"Uniform distribution per chain = good mixing\") +\n",
    "  theme_minimal()\n",
    "\n",
    "# Signs of a BAD trace plot:\n",
    "# - Slow drift upward or downward (non-stationarity)\n",
    "# - Long horizontal runs (getting stuck — high autocorrelation)\n",
    "# - Chains in different locations (non-convergence)\n",
    "# - Sudden jumps without return (bimodal posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04-rhat-ess",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## R-hat and Effective Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04-rhat-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── R-hat: between-chain / within-chain variance ratio ───────────────────────\n",
    "# R-hat = 1.00: chains identical (converged)\n",
    "# R-hat > 1.01: chains different — do not use results\n",
    "\n",
    "rhat_vals <- brms::rhat(m_good)\n",
    "cat(sprintf(\"R-hat values:\\n\"))\n",
    "print(round(rhat_vals, 4))\n",
    "cat(sprintf(\"\\nMax R-hat: %.4f  (must be < 1.01)\\n\", max(rhat_vals, na.rm=TRUE)))\n",
    "\n",
    "# Visualise\n",
    "bayesplot::mcmc_rhat(rhat_vals) +\n",
    "  labs(title=\"R-hat Values\",\n",
    "       subtitle=\"All should fall left of the 1.01 threshold line\") +\n",
    "  theme_minimal()\n",
    "\n",
    "# ── Effective Sample Size ─────────────────────────────────────────────────────\n",
    "# ESS is less than raw iterations because MCMC samples are autocorrelated\n",
    "# Bulk ESS: reliability of posterior mean and bulk quantiles\n",
    "# Tail ESS: reliability of extreme quantiles (credible interval bounds)\n",
    "\n",
    "neff  <- brms::neff_ratio(m_good)  # ESS / total draws\n",
    "cat(sprintf(\"\\nESS ratio (should be > 0.1):\\n\"))\n",
    "print(round(neff, 3))\n",
    "\n",
    "# Total draws = n_chains × (n_iter - n_warmup) = 4 × 2000 = 8000\n",
    "total_draws <- 4 * (3000 - 1000)\n",
    "cat(sprintf(\"\\nTotal draws: %d\\n\", total_draws))\n",
    "cat(sprintf(\"Min effective draws: %.0f  (must be > 400)\\n\",\n",
    "            min(neff, na.rm=TRUE) * total_draws))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05-autocorr",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Autocorrelation and HMC-Specific Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05-auto-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── ACF plot: how quickly autocorrelation decays ─────────────────────────────\n",
    "bayesplot::mcmc_acf(draws_array, pars=params, lags=30) +\n",
    "  labs(title=\"Autocorrelation Function of MCMC Chains\",\n",
    "       subtitle=\"Fast decay to zero = good mixing; slow decay = need more iterations\") +\n",
    "  theme_minimal()\n",
    "\n",
    "# ── HMC-specific: divergences ─────────────────────────────────────────────────\n",
    "# Divergences occur when the sampler's step size is too large and it\n",
    "# flies off the posterior geometry. Even 1 divergence can indicate bias.\n",
    "nuts_params <- brms::nuts_params(m_good)\n",
    "n_divergent <- sum(nuts_params$Value[nuts_params$Parameter==\"divergent__\"] == 1)\n",
    "cat(sprintf(\"Post-warmup divergences: %d  (must be 0)\\n\", n_divergent))\n",
    "\n",
    "# ── Pairs plot: detect funnel geometries ──────────────────────────────────────\n",
    "# Divergent transitions (if any) appear in a specific region of parameter space\n",
    "bayesplot::mcmc_pairs(\n",
    "  draws_array,\n",
    "  pars       = c(\"b_Intercept\",\"b_x\",\"sigma\"),\n",
    "  off_diag_args = list(size=0.4, alpha=0.4)\n",
    ") +\n",
    "  labs(title=\"Pairs Plot\",\n",
    "       subtitle=\"Funnel shapes or points in corners indicate geometry issues\")\n",
    "\n",
    "# ── BFMI (Bayesian Fraction of Missing Information) ───────────────────────────\n",
    "bfmi <- sapply(1:4, function(c) {\n",
    "  e <- nuts_params %>% filter(Chain==c, Parameter==\"energy__\") %>% pull(Value)\n",
    "  var(diff(e)) / var(e)\n",
    "})\n",
    "cat(sprintf(\"\\nBFMI per chain: %s  (should be > 0.3)\\n\",\n",
    "            paste(round(bfmi, 3), collapse=\", \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06-ppc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Posterior Predictive Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06-ppc-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw replicated datasets from the fitted model\n",
    "y_rep <- posterior_predict(m_good, ndraws=200)\n",
    "\n",
    "# ── Density overlay ───────────────────────────────────────────────────────────\n",
    "p1 <- bayesplot::ppc_dens_overlay(diag_data$y, y_rep[1:100,]) +\n",
    "  labs(title=\"PPC: Density\") + theme_minimal()\n",
    "\n",
    "# ── Test statistics: mean, SD, min, max ───────────────────────────────────────\n",
    "p2 <- bayesplot::ppc_stat(diag_data$y, y_rep, stat=\"mean\") +\n",
    "  labs(title=\"PPC: Mean\") + theme_minimal()\n",
    "\n",
    "p3 <- bayesplot::ppc_stat_2d(diag_data$y, y_rep,\n",
    "                              stat=c(\"mean\",\"sd\")) +\n",
    "  labs(title=\"PPC: Mean vs SD\") + theme_minimal()\n",
    "\n",
    "# ── Intervals: point estimates and uncertainty ────────────────────────────────\n",
    "p4 <- bayesplot::ppc_intervals(\n",
    "  diag_data$y, y_rep[1:50,],\n",
    "  x=diag_data$x\n",
    ") +\n",
    "  labs(title=\"PPC: Prediction Intervals vs x\") + theme_minimal()\n",
    "\n",
    "(p1 | p2) / (p3 | p4)\n",
    "\n",
    "# What to look for:\n",
    "# - Density: observed curve should fall within the envelope of replicated curves\n",
    "# - Test stats: observed statistic (dark line) should fall in the bulk of the\n",
    "#   histogram of replicated statistics\n",
    "# - If observed is in the tail: model is missing important structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07-bad-chain",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Diagnosing and Fixing a Poorly Mixing Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07-fix-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Common causes of poor mixing and fixes ────────────────────────────────────\n",
    "\n",
    "# 1. High posterior correlation between parameters\n",
    "#    Fix: centre/scale predictors; use non-centred parameterisation in hierarchical models\n",
    "\n",
    "# 2. Divergences in hierarchical models — the \"funnel\" problem\n",
    "#    Fix: non-centred parameterisation (brms does this automatically when possible)\n",
    "#    Fix: increase adapt_delta (default 0.80; try 0.95-0.99)\n",
    "m_adapt <- brm(\n",
    "  y ~ x, data=diag_data, family=gaussian(),\n",
    "  prior=c(prior(normal(5,5), class=Intercept),\n",
    "          prior(normal(0,3),  class=b),\n",
    "          prior(exponential(1), class=sigma)),\n",
    "  chains=4, iter=4000, warmup=2000, cores=4, seed=42, silent=2,\n",
    "  control=list(\n",
    "    adapt_delta   = 0.95,   # higher = smaller step size = fewer divergences\n",
    "    max_treedepth = 12      # default 10; increase if hitting max treedepth warnings\n",
    "  )\n",
    ")\n",
    "\n",
    "# 3. Too few iterations\n",
    "#    Fix: increase iter; or warm up longer (warmup ~ 50% of total)\n",
    "\n",
    "# 4. Multimodal posterior\n",
    "#    Fix: check model specification; consider whether the model is identifiable\n",
    "\n",
    "cat(\"Controls for common mixing problems shown above.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08-pitfalls",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "**1. Reporting results without checking any diagnostics**  \n",
    "Always check R-hat, ESS, trace plots, and divergence count before reporting any posterior summaries. A non-converged chain gives wrong answers with no warning in the output table.\n",
    "\n",
    "**2. Treating R-hat < 1.1 as the convergence standard**  \n",
    "The older threshold of R-hat < 1.1 is too lenient. The current standard (Vehtari et al. 2021) is R-hat < 1.01, using the improved split-R-hat algorithm implemented in `posterior::rhat()` and recent `brms`.\n",
    "\n",
    "**3. Discarding or thinning samples to remove autocorrelation**  \n",
    "Autocorrelated samples are still valid samples — they just represent fewer effective draws. Thinning wastes information. Instead, run more iterations to accumulate enough ESS. Aim for bulk ESS > 400 per parameter, not a target autocorrelation.\n",
    "\n",
    "**4. Ignoring divergences**  \n",
    "Even a single post-warmup divergence is a red flag. Divergences indicate regions of the posterior that the sampler could not explore, leading to biased estimates. Do not dismiss them as acceptable — increase `adapt_delta` or reparameterise.\n",
    "\n",
    "**5. Confusing MCMC diagnostics with model diagnostics**  \n",
    "Good R-hat and zero divergences confirm the sampler converged, not that the model is correct. A perfectly converged chain from a misspecified model gives you the exact wrong answer. Always also run posterior predictive checks.\n",
    "\n",
    "---\n",
    "*r_methods_library · Samantha McGarrigle · [github.com/samantha-mcgarrigle](https://github.com/samantha-mcgarrigle)*"
   ]
  }
 ]
}"
