{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "R", "language": "R", "name": "ir"},
  "language_info": {"name": "R"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01-overview",
   "metadata": {},
   "source": [
    "# The Principled Bayesian Workflow\n",
    "\n",
    "## Overview\n",
    "\n",
    "A Bayesian workflow is an iterative cycle of model construction, criticism, and revision. Simply fitting a model and reporting the posterior is not the workflow — it is one step in it.\n",
    "\n",
    "**The full workflow (Gelman et al. 2020):**\n",
    "\n",
    "```\n",
    "1. Understand the problem domain\n",
    "       ↓\n",
    "2. Choose a model family (likelihood + link)\n",
    "       ↓\n",
    "3. Specify priors\n",
    "       ↓\n",
    "4. Prior predictive check — do priors imply plausible data?\n",
    "       ↓\n",
    "5. Fit the model\n",
    "       ↓\n",
    "6. MCMC diagnostics — did the sampler converge?\n",
    "       ↓\n",
    "7. Posterior predictive check — does the model reproduce the data?\n",
    "       ↓\n",
    "8. Model criticism — what does the model get wrong?\n",
    "       ↓\n",
    "9. Model comparison / revision  ←→  back to step 2 or 3\n",
    "       ↓\n",
    "10. Report with uncertainty\n",
    "```\n",
    "\n",
    "This notebook walks through all 10 steps on a single ecological dataset, demonstrating how each step informs the next and how failures at each step are diagnosed and resolved.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02-setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(brms)\n",
    "library(tidybayes)\n",
    "library(bayesplot)\n",
    "library(patchwork)\n",
    "\n",
    "set.seed(42)\n",
    "\n",
    "# ── Dataset: invertebrate count data (overdispersed counts) ───────────────────\n",
    "# True data-generating process: negative binomial\n",
    "# A naive analyst might start with Poisson — the workflow reveals the mistake\n",
    "n <- 120\n",
    "workflow_data <- tibble(\n",
    "  site_id   = 1:n,\n",
    "  nitrate   = rnorm(n, 3, 1.2),\n",
    "  habitat   = factor(sample(c(\"reference\",\"restored\",\"degraded\"), n,\n",
    "                            replace=TRUE, prob=c(.35,.35,.30)),\n",
    "                     levels=c(\"reference\",\"restored\",\"degraded\")),\n",
    "  log_mu    = 3.2 +\n",
    "              case_when(habitat==\"reference\"~0, habitat==\"restored\"~-.3, habitat==\"degraded\"~-.9) +\n",
    "              -.4 * scale(nitrate)[,1],\n",
    "  # True process is NegBin with overdispersion\n",
    "  count     = MASS::rnegbin(n, mu=exp(log_mu), theta=3)\n",
    ")\n",
    "\n",
    "ggplot(workflow_data, aes(x=count, fill=habitat)) +\n",
    "  geom_histogram(bins=30, position=\"identity\", alpha=0.5) +\n",
    "  scale_fill_manual(values=c(reference=\"#4a8fff\",restored=\"#4fffb0\",degraded=\"#ff6b6b\")) +\n",
    "  labs(title=\"Step 1: Explore the Data\",\n",
    "       subtitle=\"Counts; right-skewed; possible overdispersion\",\n",
    "       x=\"Invertebrate count\", y=\"Frequency\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03-steps-1-3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Steps 1–3: Problem Understanding, Model Family, and Priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03-prior-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Domain understanding\n",
    "# - Response is a count (non-negative integer)\n",
    "# - Variance likely exceeds mean (overdispersion common in ecological counts)\n",
    "# - Start with Poisson; Negative Binomial as alternative\n",
    "\n",
    "# Step 2: Model family\n",
    "# M1: Poisson (assumes mean = variance)\n",
    "# M2: Negative Binomial (allows overdispersion)\n",
    "\n",
    "# Step 3: Prior specification — think on the log scale (log link)\n",
    "# exp(Intercept) = mean count at reference habitat, mean nitrate\n",
    "# Reasonable count: 10–50 → log(20) ≈ 3, so Intercept ~ Normal(3, 1)\n",
    "# Nitrate effect: -0.5 to +0.5 on log scale is substantial, so Normal(0, 0.5)\n",
    "# Habitat effects: ~-0.5 to -1 on log scale, Normal(0, 1)\n",
    "\n",
    "priors_pois <- c(\n",
    "  prior(normal(3, 1),   class = Intercept),\n",
    "  prior(normal(0, 0.5), class = b, coef = nitrate),\n",
    "  prior(normal(0, 1),   class = b, coef = habitatrestored),\n",
    "  prior(normal(0, 1),   class = b, coef = habitatdegraded)\n",
    ")\n",
    "\n",
    "priors_nb <- c(\n",
    "  priors_pois,\n",
    "  prior(gamma(2, 0.5),  class = shape)   # NegBin overdispersion; mode=2, reasonable\n",
    ")\n",
    "\n",
    "# Step 4: Prior predictive check — fit with data but sample_prior='only'\n",
    "m_prior <- brm(\n",
    "  count ~ nitrate + habitat,\n",
    "  data         = workflow_data,\n",
    "  family       = poisson(),\n",
    "  prior        = priors_pois,\n",
    "  sample_prior = \"only\",\n",
    "  chains=2, iter=1000, warmup=500, cores=2, seed=42, silent=2\n",
    ")\n",
    "\n",
    "brms::pp_check(m_prior, ndraws=50, type=\"hist\") +\n",
    "  scale_x_continuous(limits=c(0, 300)) +\n",
    "  labs(title=\"Step 4: Prior Predictive Check\",\n",
    "       subtitle=\"Prior-implied counts should span plausible range without extreme values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04-fit",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Fit the Initial Model (Poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04-fit-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_poisson <- brm(\n",
    "  count ~ nitrate + habitat,\n",
    "  data   = workflow_data,\n",
    "  family = poisson(),\n",
    "  prior  = priors_pois,\n",
    "  chains=4, iter=3000, warmup=1000, cores=4, seed=42, silent=2\n",
    ")\n",
    "print(m_poisson)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05-diag",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: MCMC Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05-diag-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick diagnostic check — full treatment in mcmc_diagnostics.ipynb\n",
    "rhat_vals <- brms::rhat(m_poisson)\n",
    "ess_ratio  <- brms::neff_ratio(m_poisson)\n",
    "\n",
    "cat(sprintf(\"Max R-hat: %.4f  (need < 1.01)\\n\", max(rhat_vals, na.rm=TRUE)))\n",
    "cat(sprintf(\"Min ESS ratio: %.3f  (need > 0.1)\\n\", min(ess_ratio, na.rm=TRUE)))\n",
    "cat(sprintf(\"Post-warmup divergences: %d  (need 0)\\n\",\n",
    "            sum(nuts_params(m_poisson)$Value[nuts_params(m_poisson)$Parameter==\"divergent__\"]==1)))\n",
    "\n",
    "# Trace plots\n",
    "plot(m_poisson, variable=c(\"b_Intercept\",\"b_nitrate\",\"b_habitatdegraded\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06-ppc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 7: Posterior Predictive Check — Discovering Model Failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06-ppc-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPC: the Poisson model should fail because data are overdispersed\n",
    "\n",
    "p1 <- brms::pp_check(m_poisson, ndraws=100, type=\"dens_overlay\") +\n",
    "  labs(title=\"PPC: Density — Poisson\",\n",
    "       subtitle=\"Model likely underestimates tail counts\")\n",
    "\n",
    "# Test statistic: variance / mean (should be ~1 for Poisson)\n",
    "var_mean_ratio <- function(y) var(y) / mean(y)\n",
    "\n",
    "p2 <- brms::pp_check(m_poisson, ndraws=500, type=\"stat\", stat=var_mean_ratio) +\n",
    "  labs(title=\"PPC: Variance/Mean Ratio\",\n",
    "       subtitle=\"Observed ratio (blue line) far right of Poisson predictions → overdispersion\")\n",
    "\n",
    "p3 <- brms::pp_check(m_poisson, ndraws=100, type=\"rootogram\") +\n",
    "  labs(title=\"PPC: Rootogram\",\n",
    "       subtitle=\"Hanging bars below zero = counts the model predicts too rarely\")\n",
    "\n",
    "(p1 | p2) / p3\n",
    "\n",
    "# Expected finding: observed variance/mean >> 1; Poisson model consistently\n",
    "# underestimates the spread → clear signal to move to Negative Binomial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07-revision",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Steps 8–9: Model Criticism and Revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07-rev-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Diagnosis — Poisson PPC fails on variance/mean test → overdispersion\n",
    "# Step 9: Revision — fit Negative Binomial\n",
    "\n",
    "m_negbin <- brm(\n",
    "  count ~ nitrate + habitat,\n",
    "  data   = workflow_data,\n",
    "  family = negbinomial(),\n",
    "  prior  = priors_nb,\n",
    "  chains=4, iter=3000, warmup=1000, cores=4, seed=42, silent=2\n",
    ")\n",
    "\n",
    "# ── PPC for NegBin: should pass the variance/mean test ───────────────────────\n",
    "p4 <- brms::pp_check(m_negbin, ndraws=100, type=\"dens_overlay\") +\n",
    "  labs(title=\"PPC: Density — NegBin\")\n",
    "p5 <- brms::pp_check(m_negbin, ndraws=500, type=\"stat\", stat=var_mean_ratio) +\n",
    "  labs(title=\"PPC: Variance/Mean — NegBin\",\n",
    "       subtitle=\"Observed ratio should now fall within the predicted distribution\")\n",
    "(p4 | p5)\n",
    "\n",
    "# ── Formal model comparison ───────────────────────────────────────────────────\n",
    "m_poisson <- add_criterion(m_poisson, \"loo\")\n",
    "m_negbin  <- add_criterion(m_negbin,  \"loo\")\n",
    "loo_compare(m_poisson, m_negbin)\n",
    "# NegBin should have substantially better ELPD (larger negative elpd_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08-report",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 10: Report with Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08-report-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model: NegBin\n",
    "print(m_negbin)\n",
    "\n",
    "# Posterior summaries on the rate ratio (IRR) scale: exp(coef)\n",
    "irr_summary <- tidybayes::gather_draws(\n",
    "  m_negbin, b_nitrate, b_habitatrestored, b_habitatdegraded\n",
    ") %>%\n",
    "  mutate(.value = exp(.value)) %>%   # convert log-rate to IRR\n",
    "  group_by(.variable) %>%\n",
    "  summarise(\n",
    "    IRR       = round(mean(.value), 3),\n",
    "    q2.5      = round(quantile(.value, 0.025), 3),\n",
    "    q97.5     = round(quantile(.value, 0.975), 3),\n",
    "    p_lt_1    = round(mean(.value < 1), 3)   # P(rate < reference | data)\n",
    "  )\n",
    "print(irr_summary)\n",
    "\n",
    "# ── Prediction plot ───────────────────────────────────────────────────────────\n",
    "newdata_pred <- tidyr::expand_grid(\n",
    "  habitat  = levels(workflow_data$habitat),\n",
    "  nitrate  = seq(min(workflow_data$nitrate), max(workflow_data$nitrate), length.out=50)\n",
    ") %>%\n",
    "  mutate(habitat = factor(habitat, levels=levels(workflow_data$habitat)))\n",
    "\n",
    "pred <- tidybayes::add_epred_draws(m_negbin, newdata=newdata_pred) %>%\n",
    "  group_by(habitat, nitrate) %>%\n",
    "  summarise(\n",
    "    mean    = mean(.epred),\n",
    "    q2.5    = quantile(.epred, 0.025),\n",
    "    q97.5   = quantile(.epred, 0.975),\n",
    "    .groups = \"drop\"\n",
    "  )\n",
    "\n",
    "pal <- c(reference=\"#4a8fff\", restored=\"#4fffb0\", degraded=\"#ff6b6b\")\n",
    "\n",
    "ggplot(pred, aes(x=nitrate, y=mean, color=habitat, fill=habitat)) +\n",
    "  geom_line(linewidth=1) +\n",
    "  geom_ribbon(aes(ymin=q2.5, ymax=q97.5), alpha=0.15, color=NA) +\n",
    "  geom_jitter(data=workflow_data, aes(y=count),\n",
    "              width=0.05, height=0, alpha=0.3, size=1.2) +\n",
    "  scale_color_manual(values=pal) +\n",
    "  scale_fill_manual(values=pal) +\n",
    "  labs(\n",
    "    title    = \"Step 10: Final Model Predictions (NegBin)\",\n",
    "    subtitle  = \"Lines = posterior mean; band = 95% CI; points = observed\",\n",
    "    x = \"Nitrate\", y = \"Expected invertebrate count\",\n",
    "    color=\"Habitat\", fill=\"Habitat\"\n",
    "  ) +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09-summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Workflow Checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09-check-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat(\"\n",
    "BAYESIAN WORKFLOW CHECKLIST\n",
    "===========================\n",
    "\n",
    "[ ] 1. Domain understanding\n",
    "       - What is the data-generating process?\n",
    "       - What are plausible parameter ranges?\n",
    "       - What is the appropriate response distribution?\n",
    "\n",
    "[ ] 2. Model family\n",
    "       - Response type: Gaussian / Poisson / NegBin / Binomial / ...\n",
    "       - Link function: identity / log / logit / ...\n",
    "       - Hierarchical structure? (sites within catchments, etc.)\n",
    "\n",
    "[ ] 3. Prior specification\n",
    "       - Reason about priors on the parameter scale (e.g. log scale for Poisson)\n",
    "       - Check get_prior() for which priors brms needs\n",
    "\n",
    "[ ] 4. Prior predictive check\n",
    "       - sample_prior='only'\n",
    "       - Do simulated datasets look like plausible real data?\n",
    "       - Adjust if priors imply impossible values (negatives, > 100%, etc.)\n",
    "\n",
    "[ ] 5. Fit the model\n",
    "       - chains >= 4, iter enough for ESS > 400\n",
    "\n",
    "[ ] 6. MCMC diagnostics\n",
    "       - R-hat < 1.01 for all parameters\n",
    "       - Bulk and Tail ESS > 400\n",
    "       - Zero post-warmup divergences\n",
    "       - Trace plots: caterpillar-shaped\n",
    "\n",
    "[ ] 7. Posterior predictive check\n",
    "       - pp_check() density overlay\n",
    "       - pp_check() on key test statistics (mean, SD, variance/mean, max)\n",
    "       - Does the model reproduce the main features of the data?\n",
    "\n",
    "[ ] 8. Model criticism\n",
    "       - What does the model consistently get wrong?\n",
    "       - Is the failure systematic (wrong family? missing predictor?)\n",
    "\n",
    "[ ] 9. Model revision / comparison\n",
    "       - Address identified failures: change family, add predictors, etc.\n",
    "       - Compare with LOO-CV (see model_comparison_waic.ipynb)\n",
    "\n",
    "[ ] 10. Report with uncertainty\n",
    "        - Full posterior summaries (mean, SD, 95% CI)\n",
    "        - Posterior probabilities of key hypotheses\n",
    "        - Document prior choices and sensitivity (see prior_sensitivity.ipynb)\n",
    "        - Prediction plots with uncertainty bands\n",
    "\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10-pitfalls",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "**1. Stopping after getting a converged fit**  \n",
    "Convergence is step 6 of 10. A perfectly converged chain from a misspecified model gives you the exactly wrong answer with great confidence. Posterior predictive checks (step 7) are non-negotiable.\n",
    "\n",
    "**2. Using the posterior predictive check only as a density overlay**  \n",
    "The density overlay is the most common PPC but is not always the most sensitive. Choose test statistics that reflect the specific failure modes of the model family — for Poisson, test variance/mean; for binary outcomes, test calibration; for time series, test autocorrelation in residuals.\n",
    "\n",
    "**3. Treating the workflow as linear rather than iterative**  \n",
    "The workflow loops. A failed PPC sends you back to model revision. A sensitivity analysis (step 9 area) may reveal the need to revisit priors. Expect to cycle through steps 2–9 multiple times on a real analysis.\n",
    "\n",
    "**4. Selecting the model with the best LOO without prior predictive checking the alternatives**  \n",
    "LOO model comparison (step 9) selects the best-predicting model from a set of candidates. It does not validate that any of the candidates is well-specified. Always PPC every candidate model before relying on LOO to distinguish them.\n",
    "\n",
    "**5. Reporting only point estimates from the final model**  \n",
    "The entire point of Bayesian inference is the posterior distribution. Report posterior means and credible intervals, show prediction uncertainty on plots, and state posterior probabilities for key hypotheses. A table of point estimates discards the most distinctive feature of the Bayesian result.\n",
    "\n",
    "---\n",
    "*r_methods_library · Samantha McGarrigle · [github.com/samantha-mcgarrigle](https://github.com/samantha-mcgarrigle)*"
   ]
  }
 ]
}"
