{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "R", "language": "R", "name": "ir"},
  "language_info": {"name": "R"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01-overview",
   "metadata": {},
   "source": [
    "# Power Analysis and Sample Size Calculation\n",
    "\n",
    "## Overview\n",
    "\n",
    "Statistical power is the probability of detecting a true effect when it exists: Power = 1 − β (where β = Type II error rate). A study with insufficient power wastes resources and may produce a false negative — concluding there is no effect when one exists.\n",
    "\n",
    "**The four quantities that determine power:**\n",
    "\n",
    "| Quantity | Symbol | Typical value | Relationship |\n",
    "|---|---|---|---|\n",
    "| Significance level | α | 0.05 | Lower α → lower power |\n",
    "| Power | 1−β | 0.80 | Higher power → larger n |\n",
    "| Effect size | d, f, w | Context-specific | Smaller effect → larger n |\n",
    "| Sample size | n | To calculate | — |\n",
    "\n",
    "Fix any three; solve for the fourth. In practice: specify α, 1−β, and the **minimum detectable effect (MDE)** → compute required n.\n",
    "\n",
    "**Effect size conventions (Cohen):**\n",
    "\n",
    "| Test | Small | Medium | Large |\n",
    "|---|---|---|---|\n",
    "| t-test (Cohen's d) | 0.2 | 0.5 | 0.8 |\n",
    "| ANOVA (Cohen's f) | 0.1 | 0.25 | 0.4 |\n",
    "| Proportion (Cohen's h) | 0.2 | 0.5 | 0.8 |\n",
    "| Correlation (Cohen's q) | 0.1 | 0.3 | 0.5 |\n",
    "\n",
    "Cohen's conventions are a last resort — use domain knowledge or pilot data to specify a practically meaningful effect size.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02-setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(pwr)           # pwr.t.test(), pwr.2p.test(), pwr.anova.test()\n",
    "library(patchwork)\n",
    "\n",
    "# ── Common power analysis scenarios ──────────────────────────────────────────\n",
    "# Scenario: testing whether a restoration intervention improves species richness\n",
    "# Pilot data suggests: control mean=18, SD=5; MDE = 3 species (16.7% increase)\n",
    "# α = 0.05, power = 0.80\n",
    "\n",
    "control_mean <- 18\n",
    "control_sd   <- 5\n",
    "mde          <- 3          # minimum detectable effect (units: species)\n",
    "cohen_d      <- mde / control_sd  # standardised effect size\n",
    "cat(sprintf(\"Cohen's d = %.2f / %.2f = %.3f\\n\", mde, control_sd, cohen_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03-ttest",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Two-Sample t-Test Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03-ttest-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwr.t.test: two-sample, equal group sizes\n",
    "t_power <- pwr::pwr.t.test(\n",
    "  d    = cohen_d,\n",
    "  sig.level = 0.05,\n",
    "  power     = 0.80,\n",
    "  type      = \"two.sample\",\n",
    "  alternative = \"two.sided\"\n",
    ")\n",
    "cat(sprintf(\"Required n per group: %d (total: %d)\\n\",\n",
    "            ceiling(t_power$n), ceiling(t_power$n)*2))\n",
    "\n",
    "# ── Power curve: n vs. power for varying effect sizes ────────────────────────\n",
    "power_curves <- expand_grid(\n",
    "  n    = seq(10, 200, by=5),\n",
    "  d    = c(0.2, 0.35, 0.5, 0.65, 0.8)\n",
    ") %>%\n",
    "  mutate(\n",
    "    power = map2_dbl(n, d, ~pwr::pwr.t.test(\n",
    "      n=.x, d=.y, sig.level=0.05,\n",
    "      type=\"two.sample\", alternative=\"two.sided\"\n",
    "    )$power)\n",
    "  )\n",
    "\n",
    "ggplot(power_curves, aes(x=n, y=power, color=factor(d), group=factor(d))) +\n",
    "  geom_line(linewidth=1) +\n",
    "  geom_hline(yintercept=0.80, linetype=\"dashed\", color=\"gray40\") +\n",
    "  scale_color_viridis_d(name=\"Cohen's d\", option=\"plasma\") +\n",
    "  scale_y_continuous(labels=scales::percent, limits=c(0,1)) +\n",
    "  labs(title=\"Power Curves: Two-Sample t-Test\",\n",
    "       subtitle=\"Dashed = 80% power threshold; n is per group\",\n",
    "       x=\"Sample size (n per group)\", y=\"Power\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04-other-tests",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Power for Other Common Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04-other-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Proportion test (Cohen's h) ───────────────────────────────────────────────\n",
    "# Control conversion: 15%; MDE: detect 20% (absolute +5pp)\n",
    "p1 <- 0.15; p2 <- 0.20\n",
    "h  <- pwr::ES.h(p2, p1)   # Cohen's h effect size for proportions\n",
    "prop_power <- pwr::pwr.2p.test(\n",
    "  h=h, sig.level=0.05, power=0.80, alternative=\"two.sided\"\n",
    ")\n",
    "cat(sprintf(\"Proportions (%.0f%% vs %.0f%%): h=%.3f → n=%d per group\\n\",\n",
    "            p1*100, p2*100, h, ceiling(prop_power$n)))\n",
    "\n",
    "# ── One-way ANOVA (Cohen's f) ─────────────────────────────────────────────────\n",
    "# 3 site types; expected between-group SD=3, within-group SD=5\n",
    "f_effect <- 3/5   # Cohen's f = sigma_means / sigma_within\n",
    "anova_power <- pwr::pwr.anova.test(\n",
    "  k=3, f=f_effect, sig.level=0.05, power=0.80\n",
    ")\n",
    "cat(sprintf(\"One-way ANOVA (k=3): f=%.3f → n=%d per group\\n\",\n",
    "            f_effect, ceiling(anova_power$n)))\n",
    "\n",
    "# ── Chi-squared test (Cohen's w) ─────────────────────────────────────────────\n",
    "# Observed vs. expected distribution across 4 habitat categories\n",
    "chisq_power <- pwr::pwr.chisq.test(\n",
    "  w=0.3, df=3, sig.level=0.05, power=0.80\n",
    ")\n",
    "cat(sprintf(\"Chi-squared (df=3): w=0.3 → n=%d total\\n\",\n",
    "            ceiling(chisq_power$N)))\n",
    "\n",
    "# ── Correlation (Cohen's q) ───────────────────────────────────────────────────\n",
    "corr_power <- pwr::pwr.r.test(\n",
    "  r=0.3, sig.level=0.05, power=0.80, alternative=\"two.sided\"\n",
    ")\n",
    "cat(sprintf(\"Correlation (r=0.3): n=%d\\n\", ceiling(corr_power$n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05-sensitivity",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Sensitivity Analysis: What Power Do We Have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05-sens-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrospective / sensitivity: given a fixed n, what effects can we detect?\n",
    "# Useful when n is constrained by budget or available sites\n",
    "\n",
    "fixed_n <- 40  # sites per group; budget constraint\n",
    "\n",
    "detectable <- tibble(\n",
    "  power_target = c(0.70, 0.80, 0.90)\n",
    ") %>%\n",
    "  mutate(\n",
    "    min_d = map_dbl(power_target, ~pwr::pwr.t.test(\n",
    "      n=fixed_n, sig.level=0.05, power=.x,\n",
    "      type=\"two.sample\", alternative=\"two.sided\"\n",
    "    )$d),\n",
    "    min_effect_species = min_d * control_sd\n",
    "  )\n",
    "\n",
    "cat(sprintf(\"With n=%d per group (α=0.05):\\n\", fixed_n))\n",
    "print(detectable %>% mutate(across(where(is.numeric), ~round(.x, 3))))\n",
    "cat(\"\\n→ Ask: is this minimum detectable effect scientifically meaningful?\\n\")\n",
    "cat(\"  If not: collect more data, or accept the study is underpowered.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06-pitfalls",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "**1. Using Cohen's conventional effect sizes instead of domain-specific MDEs**  \n",
    "Cohen's small/medium/large benchmarks were derived from social psychology literature and have no relevance to ecology, medicine, or industry conversion rates. A \"medium\" effect in one field may be enormous or trivial in another. Always ground the MDE in what would be scientifically or practically meaningful — see `minimum_detectable_effect.ipynb`.\n",
    "\n",
    "**2. Conducting post-hoc power analysis after a non-significant result**  \n",
    "Post-hoc power computed from the observed effect size is mathematically equivalent to a function of the p-value and adds no information. A non-significant result with \"low post-hoc power\" does not mean the study was underpowered — it means the observed effect was small. Report the confidence interval for the effect size instead.\n",
    "\n",
    "**3. Not accounting for attrition, clustering, or multiple outcomes**  \n",
    "Standard power formulas assume complete data, independent observations, and a single primary outcome. Add 10–20% to account for dropout; multiply n by the design effect (DEFF = 1 + (m−1)×ICC) for clustered designs; apply a correction for multiple primary outcomes. Ignoring these systematically underestimates required n.\n",
    "\n",
    "**4. Calculating power for a one-tailed test when the analysis will be two-tailed**  \n",
    "One-tailed tests require smaller n and are tempting to justify post hoc. Unless the direction of the effect is specified in advance and a result in the opposite direction would be completely uninterpretable, use two-tailed power calculations and report two-tailed tests.\n",
    "\n",
    "**5. Treating the power calculation as a one-time exercise**  \n",
    "Power calculations should be revisited if the SD estimate changes after piloting, if the expected effect size is revised based on new information, or if the analysis plan changes (e.g. switching from t-test to ANCOVA). Document the assumptions and revisit them before data collection begins.\n",
    "\n",
    "---\n",
    "*r_methods_library · Samantha McGarrigle · [github.com/samantha-mcgarrigle](https://github.com/samantha-mcgarrigle)*"
   ]
  }
 ]
}"
