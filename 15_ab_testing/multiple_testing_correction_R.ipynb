{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "R", "language": "R", "name": "ir"},
  "language_info": {"name": "R"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01-overview",
   "metadata": {},
   "source": [
    "# Multiple Testing Correction\n",
    "\n",
    "## Overview\n",
    "\n",
    "When testing m hypotheses simultaneously at α=0.05, the probability of at least one false positive is 1−(1−0.05)^m. With m=20 tests, this exceeds 64%. Multiple testing corrections control either the **family-wise error rate (FWER)** or the **false discovery rate (FDR)**.\n",
    "\n",
    "**FWER vs. FDR:**\n",
    "\n",
    "| | Controls | Appropriate when | Conservative? |\n",
    "|---|---|---|---|\n",
    "| **Bonferroni** | FWER: P(any false positive) | Any false positive is costly; m small | Most conservative |\n",
    "| **Holm** | FWER (stepdown) | Same as Bonferroni; uniformly more powerful | Less conservative than Bonferroni |\n",
    "| **Benjamini-Hochberg** | FDR: expected proportion of false discoveries | Exploratory; some false positives tolerable; m large | Least conservative |\n",
    "| **Benjamini-Yekutieli** | FDR under dependence | Tests are correlated | More conservative than B-H |\n",
    "\n",
    "**When no correction is needed:**\n",
    "- Pre-specified single primary outcome (the other tests are exploratory)\n",
    "- Replication across independent datasets\n",
    "- Mechanistically related tests where the family of comparisons is conceptually one question\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02-setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(patchwork)\n",
    "\n",
    "set.seed(42)\n",
    "\n",
    "# ── Simulate: 50 species tested for differential abundance ───────────────────\n",
    "# 8 truly different; 42 are null (no real effect)\n",
    "m       <- 50\n",
    "n_true  <- 8\n",
    "n_null  <- m - n_true\n",
    "\n",
    "# True effects: larger mean difference\n",
    "true_pvals <- map_dbl(1:n_true, ~t.test(\n",
    "  rnorm(30, mean=2.5, sd=3),\n",
    "  rnorm(30, mean=0,   sd=3)\n",
    ")$p.value)\n",
    "\n",
    "# Null effects: no difference → p-values uniform under H0\n",
    "null_pvals <- map_dbl(1:n_null, ~t.test(\n",
    "  rnorm(30, mean=0, sd=3),\n",
    "  rnorm(30, mean=0, sd=3)\n",
    ")$p.value)\n",
    "\n",
    "results <- tibble(\n",
    "  species   = paste0(\"sp\", 1:m),\n",
    "  raw_p     = c(true_pvals, null_pvals),\n",
    "  truly_sig = c(rep(TRUE, n_true), rep(FALSE, n_null))\n",
    ") %>% arrange(raw_p)\n",
    "\n",
    "cat(sprintf(\"m=%d tests | %d true positives | %d nulls\\n\",\n",
    "            m, n_true, n_null))\n",
    "cat(sprintf(\"Naive: %d significant at α=0.05 (includes ~%.0f false positives)\\n\",\n",
    "            sum(results$raw_p < 0.05),\n",
    "            sum(!results$truly_sig & results$raw_p < 0.05)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03-corrections",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Applying Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03-corrections-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "results <- results %>%\n",
    "  mutate(\n",
    "    p_bonferroni = p.adjust(raw_p, method=\"bonferroni\"),\n",
    "    p_holm       = p.adjust(raw_p, method=\"holm\"),\n",
    "    p_BH         = p.adjust(raw_p, method=\"BH\"),    # Benjamini-Hochberg FDR\n",
    "    p_BY         = p.adjust(raw_p, method=\"BY\")     # Benjamini-Yekutieli\n",
    "  )\n",
    "\n",
    "# Summary: how many discoveries at α=0.05 after correction?\n",
    "discovery_summary <- tibble(\n",
    "  method      = c(\"None\",\"Bonferroni\",\"Holm\",\"BH (FDR)\",\"BY (FDR)\"),\n",
    "  discoveries = c(\n",
    "    sum(results$raw_p     < 0.05),\n",
    "    sum(results$p_bonferroni < 0.05),\n",
    "    sum(results$p_holm    < 0.05),\n",
    "    sum(results$p_BH      < 0.05),\n",
    "    sum(results$p_BY      < 0.05)\n",
    "  ),\n",
    "  false_positives = c(\n",
    "    sum(!results$truly_sig & results$raw_p     < 0.05),\n",
    "    sum(!results$truly_sig & results$p_bonferroni < 0.05),\n",
    "    sum(!results$truly_sig & results$p_holm    < 0.05),\n",
    "    sum(!results$truly_sig & results$p_BH      < 0.05),\n",
    "    sum(!results$truly_sig & results$p_BY      < 0.05)\n",
    "  )\n",
    ") %>%\n",
    "  mutate(true_positives = discoveries - false_positives,\n",
    "         missed         = n_true - true_positives)\n",
    "\n",
    "print(discovery_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04-visualise",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Visualising: p-Value Histogram and Correction Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04-viz-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── p-Value histogram: diagnostic ─────────────────────────────────────────────\n",
    "# Under H0: p-values uniform. Spike near 0 = true positives exist.\n",
    "# Anti-conservative tests: spike near 1. Bimodal: something unusual.\n",
    "p_hist <- ggplot(results, aes(x=raw_p, fill=truly_sig)) +\n",
    "  geom_histogram(bins=20, boundary=0, color=\"white\", linewidth=0.3) +\n",
    "  scale_fill_manual(values=c(\"TRUE\"=\"#4a8fff\",\"FALSE\"=\"#cccccc\"),\n",
    "                    labels=c(\"TRUE\"=\"True positive\",\"FALSE\"=\"Null\")) +\n",
    "  labs(title=\"p-Value Histogram\",\n",
    "       subtitle=\"Spike near 0 = true effects; flat tail = null tests (uniform under H0)\",\n",
    "       x=\"Raw p-value\", y=\"Count\", fill=NULL) +\n",
    "  theme_minimal()\n",
    "\n",
    "# ── BH procedure: step-by-step visualisation ─────────────────────────────────\n",
    "bh_df <- results %>%\n",
    "  arrange(raw_p) %>%\n",
    "  mutate(\n",
    "    rank      = row_number(),\n",
    "    bh_thresh = rank / m * 0.05,\n",
    "    rejected  = raw_p <= bh_thresh\n",
    "  )\n",
    "\n",
    "p_bh <- ggplot(bh_df, aes(x=rank, y=raw_p, color=rejected, shape=truly_sig)) +\n",
    "  geom_line(aes(y=bh_thresh), color=\"#ff6b6b\", linewidth=1, inherit.aes=FALSE,\n",
    "            data=bh_df) +\n",
    "  geom_point(size=2.5) +\n",
    "  scale_color_manual(values=c(\"TRUE\"=\"#4fffb0\",\"FALSE\"=\"#cccccc\"),\n",
    "                     labels=c(\"TRUE\"=\"Rejected\",\"FALSE\"=\"Not rejected\")) +\n",
    "  scale_shape_manual(values=c(\"TRUE\"=16,\"FALSE\"=1),\n",
    "                     labels=c(\"TRUE\"=\"True effect\",\"FALSE\"=\"Null\")) +\n",
    "  labs(title=\"Benjamini-Hochberg Procedure\",\n",
    "       subtitle=\"Red line = BH threshold k·α/m; points below line are rejected\",\n",
    "       x=\"Rank (sorted by p-value)\", y=\"p-value\",\n",
    "       color=\"Decision\", shape=\"Ground truth\") +\n",
    "  theme_minimal()\n",
    "\n",
    "(p_hist | p_bh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05-fdr-rate",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## FDR vs. FWER: Empirical Comparison Across Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05-sim-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate 1000 experiments; measure actual FWER and FDR achieved\n",
    "simulate_testing <- function(m=50, n_true=8, n_per=30, nsim=500) {\n",
    "  map_dfr(1:nsim, function(sim) {\n",
    "    p_true <- map_dbl(1:n_true,  ~t.test(rnorm(n_per,2,3),rnorm(n_per,0,3))$p.value)\n",
    "    p_null <- map_dbl(1:(m-n_true), ~t.test(rnorm(n_per,0,3),rnorm(n_per,0,3))$p.value)\n",
    "    ps     <- c(p_true, p_null)\n",
    "    sig    <- c(rep(TRUE,n_true), rep(FALSE,m-n_true))\n",
    "\n",
    "    p_bon <- p.adjust(ps, \"bonferroni\")\n",
    "    p_bh  <- p.adjust(ps, \"BH\")\n",
    "\n",
    "    tibble(\n",
    "      method       = c(\"Bonferroni\",\"BH (FDR)\"),\n",
    "      any_fp       = c(any(!sig & p_bon<0.05), any(!sig & p_bh<0.05)),\n",
    "      fdr          = c(sum(!sig & p_bon<0.05)/max(sum(p_bon<0.05),1),\n",
    "                       sum(!sig & p_bh<0.05)/max(sum(p_bh<0.05),1)),\n",
    "      power        = c(mean(sig[p_bon<0.05]), mean(sig[p_bh<0.05]))\n",
    "    )\n",
    "  })\n",
    "}\n",
    "\n",
    "sim_results <- simulate_testing(nsim=300)\n",
    "\n",
    "sim_results %>%\n",
    "  group_by(method) %>%\n",
    "  summarise(\n",
    "    FWER        = round(mean(any_fp), 3),\n",
    "    mean_FDR    = round(mean(fdr),    3),\n",
    "    mean_power  = round(mean(power, na.rm=TRUE), 3)\n",
    "  ) %>%\n",
    "  print()\n",
    "# BH: lower power cost than Bonferroni; controls FDR ≤ 0.05; FWER may exceed 0.05\n",
    "# Bonferroni: guaranteed FWER ≤ 0.05; fewer true discoveries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06-pitfalls",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "**1. Applying Bonferroni correction to all tests regardless of context**  \n",
    "Bonferroni controls the probability of any false positive across the entire family. If each test is a separate scientific question (different species, different outcomes, different studies), they are not a family and no correction is needed. Only tests that collectively form a single inferential claim require family-wise correction.\n",
    "\n",
    "**2. Confusing FDR control with FWER control**  \n",
    "Benjamini-Hochberg controls the expected proportion of false positives among all discoveries — not the probability of any false positive. With BH at q=0.05, you expect 5% of your significant results to be false positives. This is appropriate for exploratory screening; it is not appropriate when any single false positive has serious consequences.\n",
    "\n",
    "**3. Applying the correction to exploratory tests while reporting them as confirmatory**  \n",
    "Running 50 tests, applying BH correction, and reporting the 12 significant ones as confirmed findings is circular — BH controls the FDR in expectation, not per-experiment. Significant results from corrected exploratory analyses require independent replication before being treated as confirmed.\n",
    "\n",
    "**4. Not inspecting the p-value histogram before applying correction**  \n",
    "The shape of the p-value histogram is informative: a uniform distribution with a spike near zero indicates true effects exist; a non-uniform distribution across the bulk suggests model misspecification or test violations. Anti-conservative tests (spike near 1) indicate inflation. Always plot the raw p-value histogram before applying any correction.\n",
    "\n",
    "**5. Using Bonferroni when tests are positively correlated**  \n",
    "Bonferroni assumes independence (or uses a worst-case bound). When tests are positively correlated — as they typically are in ecological data where species co-occur — Bonferroni over-corrects. Holm is uniformly more powerful than Bonferroni at the same FWER level. For strongly correlated tests, consider permutation-based corrections that account for the actual dependence structure.\n",
    "\n",
    "---\n",
    "*r_methods_library · Samantha McGarrigle · [github.com/samantha-mcgarrigle](https://github.com/samantha-mcgarrigle)*"
   ]
  }
 ]
}"
