{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "R", "language": "R", "name": "ir"},
  "language_info": {"name": "R"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01-overview",
   "metadata": {},
   "source": [
    "# Permutation-Based Inference in R\n",
    "\n",
    "## Overview\n",
    "\n",
    "Permutation tests (randomization tests) are a broad class of inference procedures that build a null distribution by repeatedly shuffling the data. They make **no parametric distributional assumptions** — the null distribution is generated empirically from the data itself.\n",
    "\n",
    "**The core idea:**\n",
    "1. Compute a test statistic T from the observed data\n",
    "2. Repeatedly shuffle the group labels (or the response values) and recompute T\n",
    "3. The p-value = proportion of permuted T values ≥ observed T\n",
    "\n",
    "**When to use permutation tests:**\n",
    "- You want to test a custom statistic with no known parametric distribution\n",
    "- Sample size is too small for asymptotic approximations\n",
    "- Data clearly violate parametric assumptions and no transformation helps\n",
    "- You want to avoid any distributional assumption and let the data speak\n",
    "- You are analyzing multivariate data (PERMANOVA, Mantel test — already covered)\n",
    "\n",
    "**Permutation vs. bootstrap:**  \n",
    "Permutation tests assess significance under a specific null hypothesis (e.g., no group difference). Bootstrap estimates confidence intervals and sampling variability without a specific null. They answer different questions and are complementary.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02-setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02-setup-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(coin)        # framework for permutation tests with complex designs\n",
    "library(perm)        # permTS() — two-sample permutation t-test\n",
    "\n",
    "set.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03-from-scratch",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## From Scratch: Building Intuition\n",
    "\n",
    "The best way to understand permutation tests is to write one from scratch before using packaged implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03-scratch-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Data: two independent groups ─────────────────────────────────────────────\n",
    "group_a <- c(12, 9, 15, 18, 11, 14, 22, 8, 17, 13)\n",
    "group_b <- c(7,  4, 11,  9,  6,  8, 12, 5, 10,  7)\n",
    "\n",
    "# ── Observed test statistic: difference in means ──────────────────────────────\n",
    "obs_stat <- mean(group_a) - mean(group_b)\n",
    "cat(sprintf(\"Observed mean difference: %.3f\\n\", obs_stat))\n",
    "\n",
    "# ── Permutation procedure ─────────────────────────────────────────────────────\n",
    "n_perm  <- 9999\n",
    "all_obs <- c(group_a, group_b)\n",
    "n_a     <- length(group_a)\n",
    "\n",
    "perm_stats <- replicate(n_perm, {\n",
    "  shuffled <- sample(all_obs)          # shuffle all labels\n",
    "  mean(shuffled[1:n_a]) - mean(shuffled[(n_a + 1):length(all_obs)])\n",
    "})\n",
    "\n",
    "# ── Permutation p-value (two-sided) ──────────────────────────────────────────\n",
    "p_perm <- mean(abs(perm_stats) >= abs(obs_stat))\n",
    "cat(sprintf(\"Permutation p-value (two-sided): %.4f\\n\", p_perm))\n",
    "cat(sprintf(\"Parametric t-test p-value:       %.4f\\n\",\n",
    "            t.test(group_a, group_b)$p.value))\n",
    "# Should be similar for well-behaved data\n",
    "\n",
    "# ── Visualize the null distribution ──────────────────────────────────────────\n",
    "ggplot(tibble(stat = perm_stats), aes(x = stat)) +\n",
    "  geom_histogram(bins = 60, fill = \"#4a8fff\", alpha = 0.7, color = \"white\") +\n",
    "  geom_vline(xintercept = c(obs_stat, -obs_stat),\n",
    "             color = \"#ff6b6b\", linewidth = 1.2, linetype = \"dashed\") +\n",
    "  annotate(\"text\", x = obs_stat, y = Inf,\n",
    "           label = sprintf(\"  Observed = %.2f\", obs_stat),\n",
    "           vjust = 1.5, hjust = 0, color = \"#ff6b6b\", size = 3.5) +\n",
    "  labs(\n",
    "    title    = \"Permutation Null Distribution\",\n",
    "    subtitle = sprintf(\"p = %.4f: proportion of |perm stats| ≥ |observed|\", p_perm),\n",
    "    x        = \"Permuted Mean Difference\",\n",
    "    y        = \"Count\"\n",
    "  ) +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04-custom-stat",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Custom Test Statistics\n",
    "\n",
    "The real power of permutation tests: any statistic can be tested, even those with no known null distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04-custom-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Simulate ecological data ──────────────────────────────────────────────────\n",
    "n <- 40\n",
    "eco_data <- tibble(\n",
    "  habitat  = rep(c(\"reference\", \"degraded\"), each = n/2),\n",
    "  richness = c(MASS::rnegbin(n/2, mu=15, theta=2),\n",
    "               MASS::rnegbin(n/2, mu=8,  theta=2))\n",
    ")\n",
    "\n",
    "# ── Test statistic 1: difference in medians ───────────────────────────────────\n",
    "obs_med_diff <- with(eco_data,\n",
    "  median(richness[habitat==\"reference\"]) -\n",
    "  median(richness[habitat==\"degraded\"]))\n",
    "\n",
    "perm_med <- replicate(9999, {\n",
    "  perm <- eco_data %>% mutate(habitat = sample(habitat))\n",
    "  with(perm,\n",
    "    median(richness[habitat==\"reference\"]) -\n",
    "    median(richness[habitat==\"degraded\"]))\n",
    "})\n",
    "p_med <- mean(abs(perm_med) >= abs(obs_med_diff))\n",
    "cat(sprintf(\"Permutation test: median difference = %.1f, p = %.4f\\n\",\n",
    "            obs_med_diff, p_med))\n",
    "\n",
    "# ── Test statistic 2: ratio of variances ─────────────────────────────────────\n",
    "# (no simple parametric null distribution for this)\n",
    "obs_var_ratio <- with(eco_data,\n",
    "  var(richness[habitat==\"reference\"]) /\n",
    "  var(richness[habitat==\"degraded\"]))\n",
    "\n",
    "perm_var <- replicate(9999, {\n",
    "  perm <- eco_data %>% mutate(habitat = sample(habitat))\n",
    "  with(perm,\n",
    "    var(richness[habitat==\"reference\"]) /\n",
    "    var(richness[habitat==\"degraded\"]))\n",
    "})\n",
    "p_var <- mean(perm_var >= obs_var_ratio | perm_var <= 1/obs_var_ratio)\n",
    "cat(sprintf(\"Permutation test: variance ratio = %.3f, p = %.4f\\n\",\n",
    "            obs_var_ratio, p_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05-coin",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Using the `coin` Package\n",
    "\n",
    "`coin` provides a rigorous framework for permutation tests with exact, asymptotic, and Monte Carlo approximations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05-coin-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Two-sample permutation test via coin ─────────────────────────────────────\n",
    "coin_test <- coin::oneway_test(\n",
    "  richness ~ factor(habitat),\n",
    "  data         = eco_data,\n",
    "  distribution = coin::approximate(nresample = 9999)  # Monte Carlo\n",
    "  # distribution = \"exact\"       # exact for small n\n",
    "  # distribution = \"asymptotic\"  # fast approximation for large n\n",
    ")\n",
    "print(coin_test)\n",
    "\n",
    "# ── Permutation Wilcoxon via coin (exact p-value with ties) ───────────────────\n",
    "coin_wilcox <- coin::wilcox_test(\n",
    "  richness ~ factor(habitat),\n",
    "  data         = eco_data,\n",
    "  distribution = coin::approximate(nresample = 9999)\n",
    ")\n",
    "print(coin_wilcox)\n",
    "\n",
    "# ── Permutation correlation test ──────────────────────────────────────────────\n",
    "env_data <- eco_data %>%\n",
    "  mutate(pH = 5 + 0.2 * richness + rnorm(n, 0, 0.5))\n",
    "\n",
    "coin_corr <- coin::spearman_test(\n",
    "  richness ~ pH,\n",
    "  data         = env_data,\n",
    "  distribution = coin::approximate(nresample = 9999)\n",
    ")\n",
    "print(coin_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06-permutation-regression",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Permutation Test for Regression Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06-regression-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Observed regression slope ─────────────────────────────────────────────────\n",
    "n_reg <- 50\n",
    "reg_data <- tibble(\n",
    "  x = runif(n_reg, 0, 10),\n",
    "  y = 2 + 0.8 * x + rnorm(n_reg, 0, 2)\n",
    ")\n",
    "\n",
    "obs_slope <- coef(lm(y ~ x, data = reg_data))[\"x\"]\n",
    "\n",
    "# ── Permute y to break x-y association ───────────────────────────────────────\n",
    "perm_slopes <- replicate(9999, {\n",
    "  coef(lm(sample(y) ~ x, data = reg_data))[\"x\"]\n",
    "})\n",
    "\n",
    "p_slope <- mean(abs(perm_slopes) >= abs(obs_slope))\n",
    "\n",
    "# ── Compare to parametric ─────────────────────────────────────────────────────\n",
    "lm_p <- summary(lm(y ~ x, data = reg_data))$coefficients[\"x\", \"Pr(>|t|)\"]\n",
    "\n",
    "cat(sprintf(\"Observed slope: %.4f\\n\", obs_slope))\n",
    "cat(sprintf(\"Permutation p:  %.4f\\n\", p_slope))\n",
    "cat(sprintf(\"Parametric t p: %.4f\\n\", lm_p))\n",
    "\n",
    "# ── Visualize ─────────────────────────────────────────────────────────────────\n",
    "ggplot(tibble(slope = perm_slopes), aes(x = slope)) +\n",
    "  geom_histogram(bins = 60, fill = \"#4fffb0\", alpha = 0.7, color = \"white\") +\n",
    "  geom_vline(xintercept = c(obs_slope, -obs_slope),\n",
    "             color = \"#ff6b6b\", linewidth = 1.2, linetype = \"dashed\") +\n",
    "  labs(\n",
    "    title    = \"Permutation Null Distribution for Regression Slope\",\n",
    "    subtitle = sprintf(\"Observed slope = %.3f; p = %.4f\", obs_slope, p_slope),\n",
    "    x = \"Permuted Slope\", y = \"Count\"\n",
    "  ) +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07-reporting",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reporting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07-reporting-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard reporting format:\n",
    "# \"We used a permutation test (9,999 random permutations) to assess\n",
    "#  whether mean invertebrate richness differed between habitat types,\n",
    "#  as the small sample size precluded reliable use of parametric tests.\n",
    "#  Reference sites had significantly higher median richness than degraded\n",
    "#  sites (observed median difference = XX.X; permutation p = .XXX).\"\n",
    "#\n",
    "# \"A permutation test of the regression slope was conducted to avoid\n",
    "#  assumptions about residual normality (9,999 permutations of the\n",
    "#  response variable). The slope was significantly positive\n",
    "#  (β = X.XX, permutation p = .XXX), consistent with the parametric\n",
    "#  result (p = .XXX).\"\n",
    "#\n",
    "# Always report:\n",
    "# - The test statistic used\n",
    "# - The number of permutations\n",
    "# - The exact permutation p-value (not just < 0.05)\n",
    "# - Rationale for using permutation over parametric test\n",
    "cat(\"Reporting guidance printed above.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08-pitfalls",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "**1. Permuting the wrong quantity**  \n",
    "For a two-sample test, permute the group labels (not the response values). For a regression slope, permute the response values (not the predictor). The correct permutation scheme depends on what the null hypothesis is.\n",
    "\n",
    "**2. Using too few permutations**  \n",
    "999 permutations is the absolute minimum; the smallest achievable p-value is 1/(n_perm + 1) = 0.001. For publication, use 9,999 or 99,999 permutations, especially when p is near the decision threshold.\n",
    "\n",
    "**3. Treating permutation p-values as exact when they are approximate**  \n",
    "Monte Carlo permutation p-values are random — they will vary slightly between runs. Set a seed for reproducibility and report the number of permutations.\n",
    "\n",
    "**4. Confusing permutation tests with bootstrap confidence intervals**  \n",
    "Permutation tests assess significance under H₀ by shuffling labels. Bootstrap estimates variability and constructs CIs by resampling with replacement. They are not interchangeable.\n",
    "\n",
    "**5. Using permutation tests as an excuse to avoid model checking**  \n",
    "Permutation tests are assumption-free about the null distribution — but they still require that observations are exchangeable under H₀. This fails with clustered, temporal, or spatial dependence. Use restricted permutations (e.g., `coin` or `permute` package) when samples are not freely interchangeable.\n",
    "\n",
    "---\n",
    "*r_methods_library · Samantha McGarrigle · [github.com/samantha-mcgarrigle](https://github.com/samantha-mcgarrigle)*"
   ]
  }
 ]
}"
