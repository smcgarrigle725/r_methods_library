{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "R", "language": "R", "name": "ir"},
  "language_info": {"name": "R"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01-overview",
   "metadata": {},
   "source": [
    "# AIC/AICc-Based Model Selection and Multi-Model Inference\n",
    "\n",
    "## Overview\n",
    "\n",
    "The Akaike Information Criterion (AIC) estimates the expected relative Kullback-Leibler divergence between the fitted model and the true data-generating process. It balances goodness-of-fit against model complexity:\n",
    "\n",
    "$$\\text{AIC} = -2\\log\\hat{L} + 2k$$\n",
    "\n",
    "where $\\hat{L}$ is the maximised likelihood and $k$ is the number of estimated parameters.\n",
    "\n",
    "**AICc** (corrected AIC) applies a finite-sample correction — use it whenever n/k < 40:\n",
    "$$\\text{AICc} = \\text{AIC} + \\frac{2k(k+1)}{n-k-1}$$\n",
    "\n",
    "**Interpreting differences (ΔAIC):**\n",
    "\n",
    "| ΔAIC | Evidence against higher-AIC model |\n",
    "|---|---|\n",
    "| 0–2 | Substantial support; models plausible |\n",
    "| 4–7 | Considerably less support |\n",
    "| > 10 | Essentially no support |\n",
    "\n",
    "**AIC vs. BIC vs. LOO-CV:**\n",
    "- AIC: minimises prediction error for new observations from the same process; preferred for prediction\n",
    "- BIC: consistent model selection (recovers true model as n→∞); preferred when parsimony matters and n is large\n",
    "- LOO-CV: directly estimates predictive accuracy; preferred for Bayesian models (see `model_comparison_waic.ipynb`)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02-setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(AICcmodavg)   # AICc, model averaging, evidence ratios\n",
    "library(MuMIn)        # dredge(), model.avg()\n",
    "library(broom)\n",
    "library(patchwork)\n",
    "\n",
    "set.seed(42)\n",
    "\n",
    "n <- 150\n",
    "aic_data <- tibble(\n",
    "  nitrate     = rnorm(n, 3, 1.2),\n",
    "  water_qual  = rnorm(n, 6, 1.5),\n",
    "  distance_km = rexp(n, 0.4),\n",
    "  elevation   = rnorm(n, 200, 80),\n",
    "  slope_pct   = abs(rnorm(n, 10, 5)),\n",
    "  habitat     = factor(sample(c(\"reference\",\"restored\",\"degraded\"), n,\n",
    "                              replace=TRUE, prob=c(.35,.35,.30)),\n",
    "                       levels=c(\"reference\",\"restored\",\"degraded\")),\n",
    "  richness    = round(\n",
    "    22 - 2.5*nitrate + 1.2*water_qual - 0.5*distance_km +\n",
    "    case_when(habitat==\"reference\"~2, habitat==\"restored\"~0, habitat==\"degraded\"~ -4) +\n",
    "    rnorm(n, 0, 3)\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03-candidate-models",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Fit Candidate Models and Build a Model Selection Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03-models-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate models based on a priori biological hypotheses\n",
    "# IMPORTANT: candidate models should be defined before seeing the data;\n",
    "# post-hoc exploration of all possible subsets inflates false discovery rates\n",
    "\n",
    "m1  <- lm(richness ~ nitrate,                                     data=aic_data)\n",
    "m2  <- lm(richness ~ water_qual,                                   data=aic_data)\n",
    "m3  <- lm(richness ~ nitrate + water_qual,                         data=aic_data)\n",
    "m4  <- lm(richness ~ nitrate + water_qual + distance_km,           data=aic_data)\n",
    "m5  <- lm(richness ~ nitrate + water_qual + habitat,               data=aic_data)\n",
    "m6  <- lm(richness ~ nitrate + water_qual + distance_km + habitat, data=aic_data)\n",
    "m7  <- lm(richness ~ nitrate + water_qual + distance_km + habitat +\n",
    "                     elevation + slope_pct,                        data=aic_data)\n",
    "m_null <- lm(richness ~ 1,                                         data=aic_data)\n",
    "\n",
    "# Model names for the table\n",
    "model_list  <- list(null=m_null, m1=m1, m2=m2, m3=m3, m4=m4,\n",
    "                    m5=m5, m6=m6, m7=m7)\n",
    "model_names <- names(model_list)\n",
    "\n",
    "# ── AICc model selection table ────────────────────────────────────────────────\n",
    "aic_table <- AICcmodavg::aictab(\n",
    "  cand.models = model_list,\n",
    "  modnames    = model_names,\n",
    "  second.ord  = TRUE   # TRUE = AICc; FALSE = AIC\n",
    ")\n",
    "print(aic_table)\n",
    "# Columns:\n",
    "#   K:      number of parameters\n",
    "#   AICc:   corrected AIC value\n",
    "#   Delta_AICc: difference from best model\n",
    "#   AICcWt: Akaike weight (posterior probability of model being best)\n",
    "#   Cum.Wt: cumulative weight\n",
    "#   LL:     log-likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04-weights",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Akaike Weights and Evidence Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04-weights-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Akaike weights: w_i = exp(-0.5 * delta_i) / sum(exp(-0.5 * delta_j))\n",
    "# Interpretation: probability that model i is the K-L best model\n",
    "#   given the data and the candidate set\n",
    "\n",
    "wt_df <- as_tibble(aic_table) %>%\n",
    "  select(Modnames, K, Delta_AICc, AICcWt) %>%\n",
    "  arrange(Delta_AICc) %>%\n",
    "  mutate(AICcWt = round(AICcWt, 4),\n",
    "         Delta_AICc = round(Delta_AICc, 2))\n",
    "\n",
    "# Evidence ratio: w_best / w_i — how many times more support has the best model\n",
    "best_wt <- wt_df$AICcWt[1]\n",
    "wt_df   <- wt_df %>% mutate(evidence_ratio = round(best_wt / AICcWt, 1))\n",
    "print(wt_df)\n",
    "\n",
    "# ── Visualise weights ─────────────────────────────────────────────────────────\n",
    "ggplot(wt_df, aes(x=AICcWt,\n",
    "                  y=fct_reorder(Modnames, AICcWt),\n",
    "                  fill=AICcWt)) +\n",
    "  geom_col(alpha=0.85) +\n",
    "  geom_text(aes(label=sprintf(\"Δ=%.1f\", Delta_AICc)), hjust=-0.1, size=3) +\n",
    "  scale_fill_gradient(low=\"#ffcccc\", high=\"#4a8fff\", guide=\"none\") +\n",
    "  scale_x_continuous(limits=c(0, 1.1)) +\n",
    "  labs(title=\"Akaike Weights: Evidence for Each Candidate Model\",\n",
    "       subtitle=\"Width = probability of being K-L best model; Δ = AICc difference from best\",\n",
    "       x=\"Akaike weight\", y=NULL) +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05-averaging",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05-avg-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model averaging: weight parameter estimates by Akaike weights\n",
    "# More honest than selecting a single best model when ΔAIC < 4\n",
    "\n",
    "# ── Full model average (all models, weighted) ─────────────────────────────────\n",
    "avg_full <- AICcmodavg::modavg(\n",
    "  cand.models = model_list,\n",
    "  modnames    = model_names,\n",
    "  parm        = \"nitrate\",\n",
    "  second.ord  = TRUE\n",
    ")\n",
    "cat(\"Model-averaged coefficient for nitrate:\\n\")\n",
    "print(avg_full)\n",
    "\n",
    "# ── Variable importance: sum of Akaike weights across models containing the variable ──\n",
    "# High summed weight: variable appears in the best models\n",
    "importance <- AICcmodavg::importance(\n",
    "  cand.models = model_list,\n",
    "  modnames    = model_names,\n",
    "  parm        = c(\"nitrate\",\"water_qual\",\"distance_km\",\n",
    "                  \"habitatrestored\",\"habitatdegraded\",\n",
    "                  \"elevation\",\"slope_pct\"),\n",
    "  second.ord  = TRUE\n",
    ")\n",
    "cat(\"\\nVariable importance (summed Akaike weights):\\n\")\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06-aic-bic",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## AIC vs. BIC vs. Adjusted R²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06-compare-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare criteria across candidate models\n",
    "criteria_df <- map_dfr(names(model_list), function(nm) {\n",
    "  m   <- model_list[[nm]]\n",
    "  gl  <- glance(m)\n",
    "  tibble(\n",
    "    model    = nm,\n",
    "    k        = length(coef(m)),\n",
    "    AIC      = AIC(m),\n",
    "    AICc     = AICcmodavg::AICc(m),\n",
    "    BIC      = BIC(m),\n",
    "    adj_r2   = gl$adj.r.squared\n",
    "  )\n",
    "}) %>%\n",
    "  mutate(\n",
    "    delta_AIC  = AIC  - min(AIC),\n",
    "    delta_BIC  = BIC  - min(BIC),\n",
    "    delta_AICc = AICc - min(AICc)\n",
    "  ) %>%\n",
    "  arrange(AICc) %>%\n",
    "  mutate(across(where(is.numeric), ~round(.x, 2)))\n",
    "\n",
    "print(criteria_df)\n",
    "# Note: AIC and AICc often agree on rankings;\n",
    "# BIC tends to favour simpler models, especially at larger n;\n",
    "# adjusted R² does not account for prediction on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07-pitfalls",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "**1. Using AIC as a hypothesis test**  \n",
    "ΔAIC is not a p-value. A model with ΔAIC = 3 is not \"significantly worse\" — it has moderately less support under the K-L framework. AIC is a measure of relative evidence within the candidate set, not an absolute test of model adequacy.\n",
    "\n",
    "**2. Using AIC instead of AICc with small samples**  \n",
    "AIC underpenalises complex models in small samples. Use AICc whenever n/k < 40 (where k is the number of parameters in the most complex candidate model). For most ecological datasets, AICc should be the default.\n",
    "\n",
    "**3. Data dredging: fitting all possible subsets and selecting by AIC**  \n",
    "Using `MuMIn::dredge()` to exhaustively search all 2^p subsets capitalises on chance. With p=10 predictors, there are 1024 candidate models — the best-AIC model is almost certainly overfit and the variable importance values are inflated. AIC model selection requires a biologically motivated candidate set defined before seeing the data.\n",
    "\n",
    "**4. Comparing models with different response distributions or data subsets**  \n",
    "AIC values are only comparable across models that use the same likelihood function applied to identical data. You cannot compare an lm() and a glm(Poisson) using AIC, nor models fitted to different subsets of the data (e.g., after different missing-data exclusions).\n",
    "\n",
    "**5. Interpreting variable importance from model averaging as a significance test**  \n",
    "Summed Akaike weights reflect how consistently a variable appears in competitive models — they are not equivalent to p-values or effect sizes. A variable with weight 0.9 is not necessarily \"more important\" than one with weight 0.6 in any inferential sense.\n",
    "\n",
    "---\n",
    "*r_methods_library · Samantha McGarrigle · [github.com/samantha-mcgarrigle](https://github.com/samantha-mcgarrigle)*"
   ]
  }
 ]
}"
