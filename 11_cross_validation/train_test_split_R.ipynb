{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "R", "language": "R", "name": "ir"},
  "language_info": {"name": "R"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01-overview",
   "metadata": {},
   "source": [
    "# Train/Validation/Test Split Discipline and Data Leakage\n",
    "\n",
    "## Overview\n",
    "\n",
    "Correct data partitioning is the foundation of honest model evaluation. Errors here invalidate every downstream metric regardless of how carefully the model is built.\n",
    "\n",
    "**The three-way split:**\n",
    "\n",
    "| Split | Purpose | Touch during... |\n",
    "|---|---|---|\n",
    "| **Training set** | Fit model parameters | Model training |\n",
    "| **Validation set** | Select hyperparameters, compare models | Tuning / model selection |\n",
    "| **Test set** | Final unbiased performance estimate | Once, at the very end |\n",
    "\n",
    "The test set must be set aside before any analysis and touched **exactly once**. Any decision informed by test set performance — model choice, feature engineering, threshold selection — contaminates the test estimate and makes it optimistic.\n",
    "\n",
    "**Data leakage** occurs when information from outside the training set is used to build the model, causing performance estimates to be unrealistically optimistic.\n",
    "\n",
    "**Common leakage sources:**\n",
    "\n",
    "| Leakage type | Example | Fix |\n",
    "|---|---|---|\n",
    "| **Preprocessing on full data** | Scaling using the full dataset mean/SD | Fit scaler on train only; transform test |\n",
    "| **Target leakage** | Including a feature that encodes the outcome | Remove leaky features before splitting |\n",
    "| **Temporal leakage** | Using future data to predict the past | Strict train < cutoff; test ≥ cutoff |\n",
    "| **Group leakage** | Same subject in train and test | Group-aware splitting |\n",
    "| **Imputation leakage** | Imputing missing values using full dataset statistics | Impute within training folds only |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02-setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(rsample)     # tidymodels resampling\n",
    "library(recipes)     # tidymodels preprocessing pipelines\n",
    "library(ranger)\n",
    "library(yardstick)\n",
    "\n",
    "set.seed(42)\n",
    "\n",
    "n <- 600\n",
    "split_data <- tibble(\n",
    "  site_id    = 1:n,\n",
    "  catchment  = sample(1:20, n, replace=TRUE),   # group structure\n",
    "  date       = sort(as.Date(\"2018-01-01\") + sample(0:1460, n)),  # temporal structure\n",
    "  nitrate    = rnorm(n, 3, 1.5),\n",
    "  water_qual = rnorm(n, 6, 1.5),\n",
    "  elevation  = rnorm(n, 200, 80),\n",
    "  present    = factor(rbinom(n, 1,\n",
    "                       plogis(-1 + 0.5*water_qual - 0.6*nitrate)),\n",
    "                      levels=c(0,1), labels=c(\"absent\",\"present\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03-basic-split",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Basic Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03-split-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 60/20/20 split ────────────────────────────────────────────────────────────\n",
    "initial_split  <- rsample::initial_split(split_data, prop=0.80, strata=present)\n",
    "train_val_data <- rsample::training(initial_split)\n",
    "test_data      <- rsample::testing(initial_split)\n",
    "\n",
    "# Further split train_val into train / validation\n",
    "val_split  <- rsample::initial_split(train_val_data, prop=0.75, strata=present)\n",
    "train_data <- rsample::training(val_split)\n",
    "val_data   <- rsample::testing(val_split)\n",
    "\n",
    "cat(sprintf(\"Train:      %d (%.0f%%)\\n\", nrow(train_data), nrow(train_data)/n*100))\n",
    "cat(sprintf(\"Validation: %d (%.0f%%)\\n\", nrow(val_data),   nrow(val_data)/n*100))\n",
    "cat(sprintf(\"Test:       %d (%.0f%%)\\n\", nrow(test_data),  nrow(test_data)/n*100))\n",
    "\n",
    "# strata= ensures class proportions are preserved across splits\n",
    "cat(\"\\nClass prevalence:\\n\")\n",
    "map_dfr(\n",
    "  list(Train=train_data, Validation=val_data, Test=test_data),\n",
    "  ~tibble(pct_present = mean(.x$present==\"present\") * 100),\n",
    "  .id=\"split\"\n",
    ") %>% print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04-leakage-demo",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Demonstrating Preprocessing Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04-leak-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── WRONG: scale using full dataset statistics ────────────────────────────────\n",
    "wrong_data <- split_data %>%\n",
    "  mutate(\n",
    "    nitrate_s    = scale(nitrate)[,1],\n",
    "    water_qual_s = scale(water_qual)[,1],\n",
    "    elevation_s  = scale(elevation)[,1]\n",
    "  )\n",
    "# Problem: scaling statistics computed on test observations;\n",
    "# the model indirectly \"sees\" test data during training\n",
    "\n",
    "# ── RIGHT: fit preprocessing on training data only ────────────────────────────\n",
    "# Use a recipe — preprocessing pipeline that is fit on train, applied to all\n",
    "preproc_rec <- recipe(\n",
    "  present ~ nitrate + water_qual + elevation,\n",
    "  data = train_data\n",
    ") %>%\n",
    "  step_normalize(all_numeric_predictors()) %>%  # fit mean/SD on train only\n",
    "  step_impute_median(all_numeric_predictors())  # impute if any missings\n",
    "\n",
    "# Prep: compute statistics from training data\n",
    "preproc_fitted <- prep(preproc_rec, training=train_data)\n",
    "\n",
    "# Bake: apply fitted transformations to each split\n",
    "train_proc <- bake(preproc_fitted, new_data=train_data)\n",
    "val_proc   <- bake(preproc_fitted, new_data=val_data)\n",
    "test_proc  <- bake(preproc_fitted, new_data=test_data)\n",
    "\n",
    "cat(\"Training set mean (should be ~0):\",  round(mean(train_proc$nitrate), 4), \"\\n\")\n",
    "cat(\"Validation set mean (may differ):\",  round(mean(val_proc$nitrate),   4), \"\\n\")\n",
    "cat(\"Test set mean (may differ):\",         round(mean(test_proc$nitrate),  4), \"\\n\")\n",
    "# Validation and test means will not be exactly 0 — this is correct and expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05-group-split",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Group-Aware Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05-group-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When observations are nested within groups (sites within catchments),\n",
    "# random splitting puts the same catchment in both train and test.\n",
    "# The model can implicitly learn catchment-level effects from the training set\n",
    "# and exploit them in the test set — artificially inflating performance.\n",
    "\n",
    "# ── Group split: all observations from a catchment go to one split ─────────────\n",
    "group_split <- rsample::group_initial_split(\n",
    "  split_data,\n",
    "  group = catchment,   # all rows from the same catchment stay together\n",
    "  prop  = 0.80\n",
    ")\n",
    "\n",
    "train_group <- rsample::training(group_split)\n",
    "test_group  <- rsample::testing(group_split)\n",
    "\n",
    "# Verify no catchment overlap\n",
    "shared_catchments <- intersect(\n",
    "  unique(train_group$catchment),\n",
    "  unique(test_group$catchment)\n",
    ")\n",
    "cat(sprintf(\"Shared catchments between train and test: %d (should be 0)\\n\",\n",
    "            length(shared_catchments)))\n",
    "cat(sprintf(\"Train catchments: %d | Test catchments: %d\\n\",\n",
    "            n_distinct(train_group$catchment),\n",
    "            n_distinct(test_group$catchment)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06-temporal-split",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Temporal Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06-temporal-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For temporal data: train on earlier observations, test on later ones\n",
    "# Random splitting allows future observations to appear in the training set\n",
    "# (temporal leakage)\n",
    "\n",
    "cutoff_date <- quantile(split_data$date, 0.80)\n",
    "train_temporal <- split_data %>% filter(date < cutoff_date)\n",
    "test_temporal  <- split_data %>% filter(date >= cutoff_date)\n",
    "\n",
    "cat(sprintf(\"Temporal split at %s:\\n\", cutoff_date))\n",
    "cat(sprintf(\"  Train: %d obs | %s to %s\\n\",\n",
    "            nrow(train_temporal), min(train_temporal$date), max(train_temporal$date)))\n",
    "cat(sprintf(\"  Test:  %d obs | %s to %s\\n\",\n",
    "            nrow(test_temporal), min(test_temporal$date), max(test_temporal$date)))\n",
    "\n",
    "# Using rsample::initial_time_split() for temporal splits\n",
    "temporal_split <- rsample::initial_time_split(\n",
    "  split_data %>% arrange(date),\n",
    "  prop = 0.80\n",
    ")\n",
    "cat(sprintf(\"\\ninitial_time_split: %d train | %d test\\n\",\n",
    "            nrow(rsample::training(temporal_split)),\n",
    "            nrow(rsample::testing(temporal_split))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07-leakage-types",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Target Leakage: A Worked Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07-target-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target leakage: a feature that is measured after or simultaneously with the\n",
    "# outcome, or that encodes the outcome indirectly\n",
    "\n",
    "# Example: 'colonisation_score' is computed FROM presence/absence — it leaks\n",
    "leaky_data <- split_data %>%\n",
    "  mutate(\n",
    "    # 'post_hoc_score' is computed after knowing the outcome — leaks target\n",
    "    post_hoc_score = ifelse(present==\"present\",\n",
    "                            rnorm(n, 8, 1),   # higher when present\n",
    "                            rnorm(n, 4, 1))\n",
    "  )\n",
    "\n",
    "# Demonstrate inflated performance with leaky feature\n",
    "train_l <- leaky_data[1:400,]; test_l <- leaky_data[401:600,]\n",
    "\n",
    "# Model with leaky feature\n",
    "rf_leaky <- ranger(\n",
    "  present ~ nitrate + water_qual + elevation + post_hoc_score,\n",
    "  data=train_l, num.trees=200, probability=TRUE, seed=42\n",
    ")\n",
    "\n",
    "# Model without leaky feature\n",
    "rf_clean <- ranger(\n",
    "  present ~ nitrate + water_qual + elevation,\n",
    "  data=train_l, num.trees=200, probability=TRUE, seed=42\n",
    ")\n",
    "\n",
    "auc_leaky <- yardstick::roc_auc(\n",
    "  test_l %>% mutate(prob=predict(rf_leaky, data=test_l)$predictions[,\"present\"]),\n",
    "  truth=present, prob, event_level=\"second\"\n",
    ")$.estimate\n",
    "\n",
    "auc_clean <- yardstick::roc_auc(\n",
    "  test_l %>% mutate(prob=predict(rf_clean, data=test_l)$predictions[,\"present\"]),\n",
    "  truth=present, prob, event_level=\"second\"\n",
    ")$.estimate\n",
    "\n",
    "cat(sprintf(\"AUC with leaky feature: %.3f  (unrealistically high)\\n\", auc_leaky))\n",
    "cat(sprintf(\"AUC without leaky feature: %.3f  (honest estimate)\\n\",  auc_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08-pitfalls",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "**1. Inspecting the test set before model finalisation**  \n",
    "Any exploratory analysis, distribution check, or outlier investigation on the test set contaminates it — even if you believe you are \"just looking.\" Set the test set aside at the very start and do not touch it until all modelling decisions are final.\n",
    "\n",
    "**2. Fitting preprocessing transformations on the full dataset**  \n",
    "Scaling, PCA, imputation, and encoding statistics must be computed on the training fold only and applied to validation/test using those training statistics. The `recipes` workflow enforces this correctly via `prep()` on training data and `bake()` on all splits.\n",
    "\n",
    "**3. Ignoring group structure when splitting**  \n",
    "When observations are not independent (sites within catchments, repeated measures from patients, multiple years from the same plot), random splitting causes group leakage. Use `group_initial_split()` or `group_vfold_cv()` to ensure all observations from a group stay in the same partition.\n",
    "\n",
    "**4. Using the validation set performance to select the final model, then re-evaluating on validation**  \n",
    "If you select hyperparameters using validation set performance, then report that same validation performance as your final estimate, the estimate is biased upward. The test set is the only unbiased estimate after model selection.\n",
    "\n",
    "**5. Not checking for temporal structure before random splitting**  \n",
    "If observations are collected over time and the outcome has a temporal trend, random splitting will put future observations in the training set. Always plot the time distribution of the data before deciding on a splitting strategy.\n",
    "\n",
    "---\n",
    "*r_methods_library · Samantha McGarrigle · [github.com/samantha-mcgarrigle](https://github.com/samantha-mcgarrigle)*"
   ]
  }
 ]
}"
