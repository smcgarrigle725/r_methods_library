{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "R", "language": "R", "name": "ir"},
  "language_info": {"name": "R"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01-overview",
   "metadata": {},
   "source": [
    "# k-Fold and Stratified k-Fold Cross-Validation\n",
    "\n",
    "## Overview\n",
    "\n",
    "k-fold CV partitions the data into k equal-sized folds. Each fold serves as the validation set exactly once while the remaining k−1 folds form the training set. The k performance estimates are averaged for a single CV estimate.\n",
    "\n",
    "**Key choices:**\n",
    "\n",
    "| Choice | Trade-off | Typical recommendation |\n",
    "|---|---|---|\n",
    "| **k = 5** | Lower variance of estimate; more bias; faster | Default for most problems |\n",
    "| **k = 10** | Less bias; more variance; slower | When compute allows |\n",
    "| **k = n (LOOCV)** | Minimal bias; high variance; very slow | See `loocv.ipynb` |\n",
    "| **Stratified** | Preserves class balance in each fold | Always use for classification |\n",
    "| **Repeated k-fold** | Averages over multiple random partitions; reduces variance | When k-fold variance is high |\n",
    "| **Group k-fold** | Groups stay intact; prevents leakage | When observations share a group |\n",
    "\n",
    "**CV error vs. test error:** CV error estimates generalisation performance on unseen data from the same distribution. It is used for model comparison and hyperparameter selection — not as the final reported performance (that requires a held-out test set).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02-setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(rsample)     # vfold_cv(), group_vfold_cv()\n",
    "library(recipes)\n",
    "library(parsnip)     # tidymodels model specs\n",
    "library(workflows)   # bundle recipe + model\n",
    "library(tune)        # fit_resamples()\n",
    "library(yardstick)\n",
    "library(patchwork)\n",
    "\n",
    "set.seed(42)\n",
    "\n",
    "n <- 500\n",
    "cv_data <- tibble(\n",
    "  catchment  = sample(1:25, n, replace=TRUE),\n",
    "  nitrate    = rnorm(n, 3, 1.2),\n",
    "  water_qual = rnorm(n, 6, 1.5),\n",
    "  distance   = rexp(n, 0.4),\n",
    "  elevation  = rnorm(n, 200, 80),\n",
    "  present    = factor(rbinom(n, 1,\n",
    "                       plogis(-1 + 0.6*water_qual - 0.7*nitrate)),\n",
    "                      levels=c(0,1), labels=c(\"absent\",\"present\"))\n",
    ")\n",
    "\n",
    "# Hold out a proper test set — CV is for model selection only\n",
    "init_split <- rsample::initial_split(cv_data, prop=0.80, strata=present)\n",
    "train_data <- rsample::training(init_split)\n",
    "test_data  <- rsample::testing(init_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03-kfold",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Standard k-Fold CV with tidymodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03-kfold-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Resampling scheme ─────────────────────────────────────────────────────────\n",
    "kfold_10    <- rsample::vfold_cv(train_data, v=10, strata=present)\n",
    "kfold_5     <- rsample::vfold_cv(train_data, v=5,  strata=present)\n",
    "repeated_kf <- rsample::vfold_cv(train_data, v=10, repeats=3, strata=present)\n",
    "\n",
    "cat(sprintf(\"10-fold:         %d resamples\\n\", nrow(kfold_10)))\n",
    "cat(sprintf(\"5-fold:          %d resamples\\n\", nrow(kfold_5)))\n",
    "cat(sprintf(\"10-fold ×3 rep:  %d resamples\\n\", nrow(repeated_kf)))\n",
    "\n",
    "# ── Define a model + recipe workflow ─────────────────────────────────────────\n",
    "rec <- recipe(present ~ nitrate + water_qual + distance + elevation,\n",
    "              data=train_data) %>%\n",
    "  step_normalize(all_numeric_predictors())\n",
    "\n",
    "rf_spec <- parsnip::rand_forest(\n",
    "  mode  = \"classification\",\n",
    "  trees = 500,\n",
    "  mtry  = 3\n",
    ") %>%\n",
    "  set_engine(\"ranger\", importance=\"permutation\", seed=42)\n",
    "\n",
    "wf <- workflows::workflow() %>%\n",
    "  add_recipe(rec) %>%\n",
    "  add_model(rf_spec)\n",
    "\n",
    "# ── Fit across resamples ──────────────────────────────────────────────────────\n",
    "metrics_set <- yardstick::metric_set(roc_auc, accuracy, f_meas)\n",
    "\n",
    "cv_results <- tune::fit_resamples(\n",
    "  wf,\n",
    "  resamples = kfold_10,\n",
    "  metrics   = metrics_set,\n",
    "  control   = tune::control_resamples(save_pred=TRUE)\n",
    ")\n",
    "\n",
    "# Summary: mean ± SE across folds\n",
    "tune::collect_metrics(cv_results) %>%\n",
    "  select(.metric, mean, std_err, n) %>%\n",
    "  mutate(across(c(mean, std_err), ~round(.x, 4))) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04-fold-comparison",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Comparing k Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04-compare-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare CV estimates across k=5, 10, and repeated 10-fold\n",
    "fit_cv <- function(resamples, label) {\n",
    "  tune::fit_resamples(wf, resamples=resamples,\n",
    "                      metrics=metric_set(roc_auc)) %>%\n",
    "    tune::collect_metrics() %>%\n",
    "    mutate(scheme=label)\n",
    "}\n",
    "\n",
    "cv_comparison <- bind_rows(\n",
    "  fit_cv(kfold_5,     \"5-fold\"),\n",
    "  fit_cv(kfold_10,    \"10-fold\"),\n",
    "  fit_cv(repeated_kf, \"10-fold ×3 repeated\")\n",
    ")\n",
    "\n",
    "ggplot(cv_comparison, aes(x=scheme, y=mean,\n",
    "                           ymin=mean-std_err, ymax=mean+std_err)) +\n",
    "  geom_pointrange(color=\"#4a8fff\", linewidth=0.8, fatten=3) +\n",
    "  scale_y_continuous(limits=c(0.7, 1.0)) +\n",
    "  labs(title=\"CV AUC-ROC Estimates: Effect of k and Repetitions\",\n",
    "       subtitle=\"Point = mean; bars = ±1 SE across folds\",\n",
    "       x=\"CV scheme\", y=\"Mean AUC-ROC\") +\n",
    "  theme_minimal()\n",
    "\n",
    "# Per-fold distribution — shows variance across folds\n",
    "tune::collect_metrics(cv_results, summarize=FALSE) %>%\n",
    "  filter(.metric==\"roc_auc\") %>%\n",
    "  ggplot(aes(x=id, y=.estimate)) +\n",
    "  geom_col(fill=\"#4a8fff\", alpha=0.7) +\n",
    "  geom_hline(yintercept=mean(\n",
    "    tune::collect_metrics(cv_results, summarize=FALSE) %>%\n",
    "    filter(.metric==\"roc_auc\") %>% pull(.estimate)\n",
    "  ), linetype=\"dashed\", color=\"#ff6b6b\") +\n",
    "  labs(title=\"AUC-ROC per Fold\",\n",
    "       subtitle=\"Red dashed = mean across folds; variance shows fold-to-fold instability\",\n",
    "       x=\"Fold\", y=\"AUC-ROC\") +\n",
    "  theme_minimal() + theme(axis.text.x=element_text(angle=45, hjust=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05-group-cv",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Group k-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05-group-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group CV: all observations from the same catchment stay in the same fold\n",
    "group_cv <- rsample::group_vfold_cv(\n",
    "  train_data,\n",
    "  group = \"catchment\",\n",
    "  v     = 5    # 5 groups-of-catchments as validation each time\n",
    ")\n",
    "\n",
    "group_results <- tune::fit_resamples(\n",
    "  wf,\n",
    "  resamples = group_cv,\n",
    "  metrics   = metric_set(roc_auc)\n",
    ")\n",
    "\n",
    "standard_auc <- tune::collect_metrics(cv_results) %>%\n",
    "  filter(.metric==\"roc_auc\") %>% pull(mean)\n",
    "\n",
    "group_auc <- tune::collect_metrics(group_results) %>%\n",
    "  filter(.metric==\"roc_auc\") %>% pull(mean)\n",
    "\n",
    "cat(sprintf(\"Standard 10-fold CV AUC: %.4f\\n\", standard_auc))\n",
    "cat(sprintf(\"Group-aware  5-fold CV AUC: %.4f\\n\", group_auc))\n",
    "# Group CV is typically lower — it is a more honest estimate because the model\n",
    "# cannot exploit catchment-level effects from training to predict test observations\n",
    "# from the same catchments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06-pitfalls",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "**1. Fitting preprocessing inside the CV loop manually instead of using a workflow**  \n",
    "If you normalise features before creating folds, the scaling statistics are computed on all data including the validation fold — preprocessing leakage. The `workflow()` + `fit_resamples()` pipeline fits the recipe inside each fold on training data only, and applies it to the validation fold correctly.\n",
    "\n",
    "**2. Reporting CV performance as the final model performance**  \n",
    "CV estimates are for model selection. The final reported performance must come from the held-out test set, evaluated exactly once after all model decisions are made. Reporting CV mean AUC as the result is optimistic because it was used to make decisions.\n",
    "\n",
    "**3. Not using stratified folds for imbalanced classification**  \n",
    "Without `strata=`, a fold may contain very few minority class observations by chance, making its AUC estimate unreliable and unrepresentative. Always use `strata=present` for binary classification with any imbalance.\n",
    "\n",
    "**4. Ignoring the SE across folds**  \n",
    "A CV mean AUC of 0.82 from k=5 folds could have SE of 0.04 — models with AUC estimates of 0.80 and 0.83 are indistinguishable. Always report the SE and avoid selecting models based on differences smaller than 1–2 SE.\n",
    "\n",
    "**5. Using random k-fold when group structure exists**  \n",
    "If sites within catchments, patients with repeated measures, or temporally structured observations are split randomly across folds, the CV estimate is optimistic. Use `group_vfold_cv()` or `rolling_origin()` as appropriate.\n",
    "\n",
    "---\n",
    "*r_methods_library · Samantha McGarrigle · [github.com/samantha-mcgarrigle](https://github.com/samantha-mcgarrigle)*"
   ]
  }
 ]
}"
