{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "R", "language": "R", "name": "ir"},
  "language_info": {"name": "R"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01-overview",
   "metadata": {},
   "source": [
    "# Time-Series-Aware Cross-Validation\n",
    "\n",
    "## Overview\n",
    "\n",
    "Standard k-fold CV randomly shuffles observations across folds. For time series, this creates **temporal leakage**: future observations appear in the training set, and the model learns from data it would not have had in production. This makes CV estimates unrealistically optimistic.\n",
    "\n",
    "**Time-series CV strategies:**\n",
    "\n",
    "| Strategy | Description | When to use |\n",
    "|---|---|---|\n",
    "| **Rolling origin** (expanding window) | Train on t=1…k, validate on t=k+1…k+h; expand training each fold | Standard; most commonly needed |\n",
    "| **Rolling window** (sliding window) | Fixed-size training window slides forward | When stationarity is doubtful or older data is less relevant |\n",
    "| **Single cutoff** | One train/test split at a fixed time point | Simplest; use when only one evaluation is needed |\n",
    "| **Blocked CV** | Non-overlapping blocks treated as folds | Panel data; weakly dependent observations |\n",
    "\n",
    "**The `lag` / `skip` parameters:**\n",
    "- `lag`: gap between end of training set and start of validation — mimics real-world forecasting delay\n",
    "- `skip`: folds to skip between successive training windows — reduces correlation between folds at the cost of fewer evaluation points\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02-setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(rsample)     # rolling_origin()\n",
    "library(recipes)\n",
    "library(parsnip)\n",
    "library(workflows)\n",
    "library(tune)\n",
    "library(yardstick)\n",
    "library(patchwork)\n",
    "\n",
    "set.seed(42)\n",
    "\n",
    "# ── Simulate a monthly ecological time series (5 years) ───────────────────────\n",
    "n_months <- 60\n",
    "ts_data <- tibble(\n",
    "  month       = 1:n_months,\n",
    "  date        = seq(as.Date(\"2018-01-01\"), by=\"month\", length.out=n_months),\n",
    "  temperature = 12 + 8*sin(2*pi*month/12) + rnorm(n_months, 0, 1.5),\n",
    "  rainfall    = pmax(rnorm(n_months, 60, 25), 0),\n",
    "  nitrate     = 3 + 0.5*sin(2*pi*month/12 + pi) + rnorm(n_months, 0, 0.5)\n",
    ") %>%\n",
    "  mutate(\n",
    "    # Target: invertebrate richness with trend + seasonality\n",
    "    richness = round(\n",
    "      15 + 0.05*month +                          # slight upward trend\n",
    "      5*sin(2*pi*month/12) +                     # seasonality\n",
    "      -2*nitrate + 0.02*rainfall +\n",
    "      rnorm(n_months, 0, 2)\n",
    "    )\n",
    "  )\n",
    "\n",
    "ggplot(ts_data, aes(x=date, y=richness)) +\n",
    "  geom_line(color=\"#4a8fff\", linewidth=0.9) +\n",
    "  geom_point(size=1.5, color=\"#4a8fff\") +\n",
    "  labs(title=\"Monthly Invertebrate Richness Time Series\",\n",
    "       x=NULL, y=\"Richness\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03-rolling-origin",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Rolling Origin CV (Expanding Window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03-ro-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Create rolling origin resamples ──────────────────────────────────────────\n",
    "ro_splits <- rsample::rolling_origin(\n",
    "  ts_data,\n",
    "  initial    = 24,   # minimum 24 months (2 years) for training\n",
    "  assess     = 6,    # validate on the next 6 months\n",
    "  skip       = 5,    # skip 5 time points between successive origins\n",
    "  cumulative = TRUE  # expanding window (set FALSE for sliding window)\n",
    ")\n",
    "\n",
    "cat(sprintf(\"Rolling origin resamples: %d\\n\", nrow(ro_splits)))\n",
    "\n",
    "# ── Visualise the splits ──────────────────────────────────────────────────────\n",
    "splits_viz <- map_dfr(seq_len(nrow(ro_splits)), function(i) {\n",
    "  sp    <- ro_splits$splits[[i]]\n",
    "  train <- rsample::analysis(sp)\n",
    "  valid <- rsample::assessment(sp)\n",
    "  bind_rows(\n",
    "    tibble(split=i, month=train$month, role=\"Train\"),\n",
    "    tibble(split=i, month=valid$month, role=\"Validate\")\n",
    "  )\n",
    "})\n",
    "\n",
    "ggplot(splits_viz, aes(x=month, y=split, color=role)) +\n",
    "  geom_point(size=2, alpha=0.8) +\n",
    "  scale_color_manual(values=c(Train=\"#4a8fff\", Validate=\"#ff6b6b\")) +\n",
    "  labs(title=\"Rolling Origin CV: Training and Validation Windows\",\n",
    "       subtitle=\"Each row = one fold; blue = train; red = validate. Training expands over time.\",\n",
    "       x=\"Month\", y=\"Fold\", color=NULL) +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04-fit",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Fitting a Model with Rolling Origin CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04-fit-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression model: richness ~ temperature + rainfall + nitrate + lagged richness\n",
    "ts_data_lagged <- ts_data %>%\n",
    "  mutate(\n",
    "    richness_lag1 = lag(richness, 1),\n",
    "    richness_lag2 = lag(richness, 2)\n",
    "  ) %>%\n",
    "  drop_na()\n",
    "\n",
    "ro_lag_splits <- rsample::rolling_origin(\n",
    "  ts_data_lagged,\n",
    "  initial=22, assess=6, skip=5, cumulative=TRUE\n",
    ")\n",
    "\n",
    "rec <- recipe(richness ~ temperature + rainfall + nitrate + richness_lag1 + richness_lag2,\n",
    "              data=ts_data_lagged) %>%\n",
    "  step_normalize(all_numeric_predictors())\n",
    "\n",
    "lm_spec <- linear_reg() %>% set_engine(\"lm\")\n",
    "wf      <- workflow() %>% add_recipe(rec) %>% add_model(lm_spec)\n",
    "\n",
    "cv_results <- tune::fit_resamples(\n",
    "  wf,\n",
    "  resamples = ro_lag_splits,\n",
    "  metrics   = metric_set(rmse, rsq, mae)\n",
    ")\n",
    "\n",
    "tune::collect_metrics(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05-naive-compare",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Demonstrating Temporal Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05-leak-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare: random k-fold (leaky) vs. rolling origin (correct)\n",
    "\n",
    "random_splits <- rsample::vfold_cv(ts_data_lagged, v=5)\n",
    "\n",
    "rmse_random <- tune::fit_resamples(wf, random_splits,\n",
    "                                   metrics=metric_set(rmse)) %>%\n",
    "  collect_metrics() %>% pull(mean)\n",
    "\n",
    "rmse_rolling <- tune::fit_resamples(wf, ro_lag_splits,\n",
    "                                    metrics=metric_set(rmse)) %>%\n",
    "  collect_metrics() %>% pull(mean)\n",
    "\n",
    "cat(sprintf(\"Random k-fold CV RMSE (LEAKY):    %.3f\\n\", rmse_random))\n",
    "cat(sprintf(\"Rolling origin CV RMSE (CORRECT): %.3f\\n\", rmse_rolling))\n",
    "cat(\"\\nRandom CV is typically lower — temporal leakage makes it optimistic.\\n\")\n",
    "\n",
    "# Per-fold RMSE for rolling origin — shows performance as training grows\n",
    "tune::collect_metrics(cv_results, summarize=FALSE) %>%\n",
    "  filter(.metric==\"rmse\") %>%\n",
    "  mutate(fold=as.integer(str_extract(id, \"[0-9]+\"))) %>%\n",
    "  ggplot(aes(x=fold, y=.estimate)) +\n",
    "  geom_line(color=\"#4a8fff\", linewidth=1) +\n",
    "  geom_point(size=3, color=\"#4a8fff\") +\n",
    "  labs(title=\"Rolling Origin CV: RMSE per Fold\",\n",
    "       subtitle=\"Later folds have more training data; RMSE should generally decrease\",\n",
    "       x=\"Fold (chronological)\", y=\"RMSE\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06-sliding",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Sliding Window vs. Expanding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06-sliding-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding window: fixed training size; older data is discarded\n",
    "# Use when the relationship is non-stationary or older data hurts performance\n",
    "\n",
    "sliding_splits <- rsample::rolling_origin(\n",
    "  ts_data_lagged,\n",
    "  initial    = 22,\n",
    "  assess     = 6,\n",
    "  skip       = 5,\n",
    "  cumulative = FALSE   # sliding window: training size stays fixed at 22\n",
    ")\n",
    "\n",
    "rmse_sliding <- tune::fit_resamples(wf, sliding_splits,\n",
    "                                    metrics=metric_set(rmse)) %>%\n",
    "  collect_metrics() %>% pull(mean)\n",
    "\n",
    "cat(sprintf(\"Expanding window RMSE: %.3f\\n\", rmse_rolling))\n",
    "cat(sprintf(\"Sliding window RMSE:   %.3f\\n\", rmse_sliding))\n",
    "cat(\"\\nIf sliding < expanding: older data hurts (non-stationary or structural break)\\n\")\n",
    "cat(\"If expanding < sliding: more data always helps (stationary process)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07-pitfalls",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "**1. Using random k-fold CV on time series data**  \n",
    "This is the most common error in time series model evaluation. Future observations appear in training folds, allowing the model to implicitly learn future patterns. CV estimates are unrealistically optimistic. Always use `rolling_origin()` or `initial_time_split()` for temporal data.\n",
    "\n",
    "**2. Not including a `lag` gap between training end and validation start**  \n",
    "If a model is intended to forecast h steps ahead, the validation fold should start h time steps after the training fold ends. Without a lag, the validation immediately follows training — which is too optimistic if the real forecasting horizon is longer.\n",
    "\n",
    "**3. Creating lagged features before splitting into folds**  \n",
    "Lagged predictors computed on the full dataset before creating folds can leak future information into the training window if lags span the training/validation boundary. Create lag features inside each fold using `step_lag()` in a recipe, or use `ts_data %>% lag()` only within the analysis() portion of each split.\n",
    "\n",
    "**4. Treating all folds as equally informative**  \n",
    "The first few rolling origin folds have very small training sets and may produce unstable estimates. Weight later folds more heavily or require a minimum training window size before including a fold in performance summaries.\n",
    "\n",
    "**5. Using rolling origin CV for panel data without blocking by group**  \n",
    "If multiple sites are measured over the same time period, `rolling_origin()` treats all sites as a single ordered series. Sites measured in the validation period but in the same training rows as training-period observations will leak. Consider `group_vfold_cv()` with time-ordered groups or a blocked design.\n",
    "\n",
    "---\n",
    "*r_methods_library · Samantha McGarrigle · [github.com/samantha-mcgarrigle](https://github.com/samantha-mcgarrigle)*"
   ]
  }
 ]
}"
