{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "R", "language": "R", "name": "ir"},
  "language_info": {"name": "R"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01-overview",
   "metadata": {},
   "source": [
    "# Nested Cross-Validation\n",
    "\n",
    "## Overview\n",
    "\n",
    "Standard CV with hyperparameter tuning produces a biased performance estimate: the hyperparameters were chosen to maximise CV performance on the same folds used to evaluate it. This is **selection bias** — the reported CV error is optimistic.\n",
    "\n",
    "**Nested CV** uses two independent CV loops to separate tuning from evaluation:\n",
    "\n",
    "```\n",
    "Outer loop (k_outer folds) — estimates generalisation performance\n",
    "│\n",
    "└── For each outer fold:\n",
    "    ├── Outer training set → Inner loop (k_inner folds) — tunes hyperparameters\n",
    "    │   └── Select best hyperparameters from inner CV\n",
    "    └── Refit with best hyperparameters on outer training set\n",
    "        └── Evaluate on outer validation fold → one unbiased performance estimate\n",
    "```\n",
    "\n",
    "The outer CV produces k_outer performance estimates. Their mean is an approximately unbiased estimate of the true generalisation error.\n",
    "\n",
    "**When is the bias large enough to matter?**\n",
    "- Small datasets (n < 500): often 2–10% AUC inflation with naive CV\n",
    "- Large hyperparameter spaces: more candidates = more selection bias\n",
    "- Small inner CV (k=5 with few outer folds): high variance amplifies bias\n",
    "\n",
    "**Computational cost:** Nested CV with k_outer=5, k_inner=5, and 30 hyperparameter candidates requires 5 × 5 × 30 = 750 model fits. Use with fast models or parallelism.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02-setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(rsample)\n",
    "library(recipes)\n",
    "library(parsnip)\n",
    "library(workflows)\n",
    "library(tune)\n",
    "library(dials)\n",
    "library(yardstick)\n",
    "library(patchwork)\n",
    "\n",
    "set.seed(42)\n",
    "\n",
    "n <- 300   # deliberately small to make selection bias visible\n",
    "nested_data <- tibble(\n",
    "  nitrate     = rnorm(n, 3, 1.2),\n",
    "  water_qual  = rnorm(n, 6, 1.5),\n",
    "  distance_km = rexp(n, 0.4),\n",
    "  elevation   = rnorm(n, 200, 80),\n",
    "  slope_pct   = abs(rnorm(n, 10, 5)),\n",
    "  present     = factor(rbinom(n, 1,\n",
    "                   plogis(-1 + 0.6*water_qual - 0.7*nitrate - 0.2*distance_km)),\n",
    "                   levels=c(0,1), labels=c(\"absent\",\"present\"))\n",
    ")\n",
    "\n",
    "cat(sprintf(\"n=%d | Prevalence: %.1f%%\\n\",\n",
    "            n, mean(nested_data$present==\"present\")*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03-naive-cv",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Naive CV (Demonstrates Optimistic Bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03-naive-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec <- recipe(present ~ nitrate + water_qual + distance_km + elevation + slope_pct,\n",
    "              data=nested_data) %>%\n",
    "  step_normalize(all_numeric_predictors())\n",
    "\n",
    "rf_spec <- rand_forest(\n",
    "  mode  = \"classification\",\n",
    "  trees = 300,\n",
    "  mtry  = tune(),\n",
    "  min_n = tune()\n",
    ") %>% set_engine(\"ranger\", seed=42)\n",
    "\n",
    "wf <- workflow() %>% add_recipe(rec) %>% add_model(rf_spec)\n",
    "\n",
    "# Naive CV: tune on the same folds used to evaluate\n",
    "cv_folds_naive <- vfold_cv(nested_data, v=5, strata=present)\n",
    "\n",
    "tune_grid_small <- grid_regular(\n",
    "  mtry(range=c(1, 5)), min_n(range=c(2, 20)), levels=c(3, 3)\n",
    ")\n",
    "\n",
    "naive_results <- tune_grid(\n",
    "  wf, resamples=cv_folds_naive,\n",
    "  grid=tune_grid_small, metrics=metric_set(roc_auc)\n",
    ")\n",
    "\n",
    "best_naive <- select_best(naive_results, metric=\"roc_auc\")\n",
    "naive_auc  <- show_best(naive_results, metric=\"roc_auc\", n=1)$mean\n",
    "cat(sprintf(\"Naive CV AUC (optimistic): %.4f\\n\", naive_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04-nested",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Nested CV (Unbiased Estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04-nested-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer CV: 5 folds for performance estimation\n",
    "outer_folds <- vfold_cv(nested_data, v=5, strata=present)\n",
    "\n",
    "# For each outer fold: tune on outer training set using inner CV,\n",
    "# then evaluate the best model on the outer validation fold\n",
    "\n",
    "nested_auc_per_fold <- map_dfr(\n",
    "  seq_len(nrow(outer_folds)), function(i) {\n",
    "    outer_split   <- outer_folds$splits[[i]]\n",
    "    outer_train   <- analysis(outer_split)\n",
    "    outer_val     <- assessment(outer_split)\n",
    "\n",
    "    # Inner CV: 5 folds within the outer training set\n",
    "    inner_folds <- vfold_cv(outer_train, v=5, strata=present)\n",
    "\n",
    "    # Tune hyperparameters on the inner folds\n",
    "    inner_results <- tune_grid(\n",
    "      wf,\n",
    "      resamples = inner_folds,\n",
    "      grid      = tune_grid_small,\n",
    "      metrics   = metric_set(roc_auc),\n",
    "      control   = control_grid(verbose=FALSE)\n",
    "    )\n",
    "\n",
    "    # Best hyperparameters from inner CV\n",
    "    best_inner <- select_best(inner_results, metric=\"roc_auc\")\n",
    "\n",
    "    # Refit on full outer training set with best hyperparameters\n",
    "    final_wf   <- finalize_workflow(wf, best_inner)\n",
    "    final_fit  <- fit(final_wf, data=outer_train)\n",
    "\n",
    "    # Evaluate on the outer validation fold (never seen during tuning)\n",
    "    preds <- augment(final_fit, new_data=outer_val)\n",
    "    auc   <- roc_auc(preds, truth=present, .pred_present,\n",
    "                     event_level=\"second\")$.estimate\n",
    "\n",
    "    tibble(\n",
    "      outer_fold    = i,\n",
    "      best_mtry     = best_inner$mtry,\n",
    "      best_min_n    = best_inner$min_n,\n",
    "      auc           = auc\n",
    "    )\n",
    "  }\n",
    ")\n",
    "\n",
    "print(nested_auc_per_fold)\n",
    "\n",
    "nested_auc_mean <- mean(nested_auc_per_fold$auc)\n",
    "nested_auc_se   <- sd(nested_auc_per_fold$auc) / sqrt(nrow(nested_auc_per_fold))\n",
    "\n",
    "cat(sprintf(\"\\nNested CV AUC (unbiased): %.4f ± %.4f SE\\n\",\n",
    "            nested_auc_mean, nested_auc_se))\n",
    "cat(sprintf(\"Naive CV AUC (optimistic): %.4f\\n\", naive_auc))\n",
    "cat(sprintf(\"Selection bias: %.4f\\n\", naive_auc - nested_auc_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05-visualise",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Visualising the Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05-viz-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of outer fold AUC estimates\n",
    "p_folds <- ggplot(nested_auc_per_fold, aes(x=factor(outer_fold), y=auc)) +\n",
    "  geom_col(fill=\"#4a8fff\", alpha=0.75) +\n",
    "  geom_hline(yintercept=nested_auc_mean, linetype=\"dashed\", color=\"#4a8fff\") +\n",
    "  geom_hline(yintercept=naive_auc,       linetype=\"dashed\", color=\"#ff6b6b\") +\n",
    "  annotate(\"text\", x=0.6, y=naive_auc+0.005,\n",
    "           label=\"Naive CV (optimistic)\", color=\"#ff6b6b\", hjust=0, size=3.5) +\n",
    "  annotate(\"text\", x=0.6, y=nested_auc_mean-0.01,\n",
    "           label=\"Nested CV mean\", color=\"#4a8fff\", hjust=0, size=3.5) +\n",
    "  labs(title=\"Nested CV: AUC per Outer Fold\",\n",
    "       subtitle=\"Naive CV is optimistically biased upward vs. nested CV\",\n",
    "       x=\"Outer fold\", y=\"AUC-ROC\") +\n",
    "  coord_cartesian(ylim=c(0.55, 1.0)) +\n",
    "  theme_minimal()\n",
    "\n",
    "# Hyperparameter selections across outer folds\n",
    "p_params <- nested_auc_per_fold %>%\n",
    "  pivot_longer(c(best_mtry, best_min_n), names_to=\"param\", values_to=\"value\") %>%\n",
    "  ggplot(aes(x=factor(outer_fold), y=value, fill=param)) +\n",
    "  geom_col(position=\"dodge\", alpha=0.8) +\n",
    "  scale_fill_manual(values=c(best_mtry=\"#4a8fff\", best_min_n=\"#4fffb0\")) +\n",
    "  labs(title=\"Best Hyperparameters per Outer Fold\",\n",
    "       subtitle=\"Variation reveals instability in hyperparameter selection\",\n",
    "       x=\"Outer fold\", y=\"Value\", fill=NULL) +\n",
    "  theme_minimal()\n",
    "\n",
    "(p_folds / p_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06-pitfalls",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "**1. Confusing the outer and inner CV performance estimates**  \n",
    "The inner CV AUC is used to select hyperparameters — it is not the performance estimate. The outer CV AUC (mean over outer folds) is the unbiased estimate. Never report the inner CV performance as the result.\n",
    "\n",
    "**2. Using nested CV to select a single set of hyperparameters**  \n",
    "Nested CV estimates how well the *procedure* of tuning + fitting generalises — it does not identify the single best hyperparameter set. Different outer folds often select different hyperparameters (see the visualisation above). To deploy a model, rerun the inner CV procedure on the full dataset and use those hyperparameters.\n",
    "\n",
    "**3. Skipping nested CV on large datasets**  \n",
    "The absolute size of selection bias decreases as n grows, but it does not disappear. For publication or high-stakes applications, report nested CV regardless of sample size. The computational cost scales linearly with k_outer, so outer k=3 or k=5 is usually affordable.\n",
    "\n",
    "**4. Using a test set inside the nested CV structure**  \n",
    "The test set remains untouched throughout nested CV. The entire nested procedure — outer and inner loops — operates only on the training data. The test set is used exactly once, after all tuning and model selection are complete, to report the final performance.\n",
    "\n",
    "**5. Expecting nested CV to eliminate all optimism**  \n",
    "Nested CV removes the bias from hyperparameter selection but not from feature selection or structural model choices (which response distribution, which predictors to consider). If these were informed by the data, additional optimism remains.\n",
    "\n",
    "---\n",
    "*r_methods_library · Samantha McGarrigle · [github.com/samantha-mcgarrigle](https://github.com/samantha-mcgarrigle)*"
   ]
  }
 ]
}"
