{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "R", "language": "R", "name": "ir"},
  "language_info": {"name": "R"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01-overview",
   "metadata": {},
   "source": [
    "# Model Comparison: LRT, AIC, and Non-Nested Tests\n",
    "\n",
    "## Overview\n",
    "\n",
    "Model comparison asks: given the data, which model is preferred? The right method depends on the model relationship and inferential goal.\n",
    "\n",
    "**Comparison methods:**\n",
    "\n",
    "| Method | Models | Goal | Based on |\n",
    "|---|---|---|---|\n",
    "| **LRT** | Nested, same family | Hypothesis test | χ² distribution |\n",
    "| **F-test** | Nested OLS | Hypothesis test | F distribution |\n",
    "| **AIC / AICc** | Any models, same data | Predictive preference | K-L divergence |\n",
    "| **BIC** | Any models, same data | Parsimony / consistency | Bayesian marginal likelihood |\n",
    "| **Vuong test** | Non-nested | Hypothesis test | LR statistic |\n",
    "| **Likelihood ratio (mixed)** | Nested mixed models | Hypothesis test | Parametric bootstrap |\n",
    "\n",
    "**Nested vs. non-nested:** Model A is nested in Model B if A can be obtained by fixing some of B's parameters to zero or a constant. Poisson is nested in NB (θ→∞); a model with one predictor is nested in a model with two.\n",
    "\n",
    "**Critical rule:** Models compared by likelihood must be fitted to the **identical** dataset — same observations, same response, same offset. Any difference in n invalidates the comparison.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02-setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(lme4)          # mixed models\n",
    "library(lmtest)        # lrtest(), waldtest()\n",
    "library(AICcmodavg)    # AICc()\n",
    "library(pscl)          # vuong()\n",
    "library(MASS)          # glm.nb()\n",
    "library(pbkrtest)      # parametric bootstrap LRT for mixed models\n",
    "library(patchwork)\n",
    "\n",
    "set.seed(42)\n",
    "\n",
    "n <- 200\n",
    "comp_data <- tibble(\n",
    "  catchment  = sample(1:20, n, replace=TRUE),\n",
    "  nitrate    = runif(n, 1, 10),\n",
    "  water_qual = runif(n, 2, 9),\n",
    "  elevation  = rnorm(n, 200, 80),\n",
    "  mu         = exp(1.8 - 0.25*nitrate + 0.18*water_qual),\n",
    "  count      = rnbinom(n, mu=mu, size=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03-lrt",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Likelihood Ratio Test for Nested Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03-lrt-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LRT: 2*(logLik(full) - logLik(reduced)) ~ χ²(df = difference in parameters)\n",
    "\n",
    "m0 <- glm(count ~ 1,                           data=comp_data, family=poisson)\n",
    "m1 <- glm(count ~ nitrate,                     data=comp_data, family=poisson)\n",
    "m2 <- glm(count ~ nitrate + water_qual,        data=comp_data, family=poisson)\n",
    "m3 <- glm(count ~ nitrate + water_qual + elevation, data=comp_data, family=poisson)\n",
    "\n",
    "# Sequential LRT\n",
    "lrt_seq <- lmtest::lrtest(m0, m1, m2, m3)\n",
    "print(lrt_seq)\n",
    "\n",
    "# Specific comparison: does elevation improve on m2?\n",
    "lrt_elev <- lmtest::lrtest(m2, m3)\n",
    "cat(sprintf(\"\\nLRT (elevation added): χ²=%.3f, df=%d, p=%.4f\\n\",\n",
    "            lrt_elev$Chisq[2], lrt_elev$Df[2], lrt_elev$`Pr(>Chisq)`[2]))\n",
    "cat(ifelse(lrt_elev$`Pr(>Chisq)`[2] < 0.05,\n",
    "           \"→ elevation significantly improves model fit\\n\",\n",
    "           \"→ elevation does not significantly improve model fit\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04-aic",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## AIC/AICc Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04-aic-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIC comparison: works for nested AND non-nested models\n",
    "# Does not require same number of parameters; does require same data\n",
    "m_nb  <- MASS::glm.nb(count ~ nitrate + water_qual, data=comp_data)\n",
    "\n",
    "model_list <- list(\n",
    "  null      = m0,\n",
    "  nitrate   = m1,\n",
    "  nit_wq    = m2,\n",
    "  nit_wq_el = m3,\n",
    "  neg_bin   = m_nb\n",
    ")\n",
    "\n",
    "aic_tab <- map_dfr(names(model_list), function(nm) {\n",
    "  m <- model_list[[nm]]\n",
    "  tibble(\n",
    "    model  = nm,\n",
    "    family = family(m)$family,\n",
    "    k      = length(coef(m)),\n",
    "    AIC    = round(AIC(m), 2),\n",
    "    AICc   = round(AICcmodavg::AICc(m), 2),\n",
    "    BIC    = round(BIC(m), 2)\n",
    "  )\n",
    "}) %>%\n",
    "  mutate(\n",
    "    delta_AICc = round(AICc - min(AICc), 2),\n",
    "    weight     = round(exp(-0.5*delta_AICc) / sum(exp(-0.5*delta_AICc)), 4)\n",
    "  ) %>%\n",
    "  arrange(AICc)\n",
    "\n",
    "print(aic_tab)\n",
    "# NB model should rank first: true DGP is NB\n",
    "# BIC typically selects simpler model than AICc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05-mixed",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Comparing Mixed Models: Fixed and Random Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05-mixed-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Comparing fixed effects: use ML (not REML) ───────────────────────────────\n",
    "# REML estimates are not comparable across models with different fixed effects\n",
    "lmm_null <- lme4::lmer(count ~ 1 + (1|catchment),\n",
    "                        data=comp_data, REML=FALSE)\n",
    "lmm_nit  <- lme4::lmer(count ~ nitrate + (1|catchment),\n",
    "                        data=comp_data, REML=FALSE)\n",
    "lmm_full <- lme4::lmer(count ~ nitrate + water_qual + (1|catchment),\n",
    "                        data=comp_data, REML=FALSE)\n",
    "\n",
    "cat(\"LRT: fixed effects (ML):\\n\")\n",
    "print(anova(lmm_null, lmm_nit, lmm_full))\n",
    "\n",
    "# ── Comparing random effects: use REML ───────────────────────────────────────\n",
    "# Must have IDENTICAL fixed effects structure\n",
    "lmm_re1 <- lme4::lmer(count ~ nitrate + water_qual + (1|catchment),\n",
    "                        data=comp_data, REML=TRUE)\n",
    "lmm_re2 <- lme4::lmer(count ~ nitrate + water_qual + (nitrate|catchment),\n",
    "                        data=comp_data, REML=TRUE)\n",
    "\n",
    "cat(\"\\nLRT: random effects structure (REML, parametric bootstrap):\\n\")\n",
    "# Standard LRT is anticonservative for random effects; use parametric bootstrap\n",
    "pb_test <- pbkrtest::PBmodcomp(\n",
    "  lmm_re2, lmm_re1,\n",
    "  nsim  = 200,   # increase to 1000 for publication\n",
    "  seed  = 42\n",
    ")\n",
    "summary(pb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06-pitfalls",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "**1. Comparing models fitted to different datasets**  \n",
    "LRT and AIC are only valid when computed on identical data. If models differ in which observations were dropped due to missing values in different predictors, the log-likelihoods are not comparable. Always fit all candidate models to the same complete-case dataset, or use multiple imputation consistently across all models.\n",
    "\n",
    "**2. Using LRT to compare non-nested models**  \n",
    "LRT requires one model to be a special case of the other. Comparing a Poisson to a log-normal model is not a nested comparison — the distributional families are different. Use AIC for non-nested comparisons; use the Vuong test when you need a formal hypothesis test between two non-nested models.\n",
    "\n",
    "**3. Using standard LRT for random effects testing**  \n",
    "The standard LRT for testing whether a variance component is zero has a null distribution that is a mixture of chi-squared distributions, not a simple χ²(1). The standard p-value is anticonservative (too small). Use the parametric bootstrap (`pbkrtest::PBmodcomp()`) or halve the p-value from the standard LRT as a rough correction.\n",
    "\n",
    "**4. Comparing REML fits with different fixed effects**  \n",
    "REML likelihood is computed after integrating out fixed effects — different fixed effect structures produce non-comparable REML likelihoods. Always refit with `REML=FALSE` before comparing fixed effects structures, and switch back to `REML=TRUE` for the final model.\n",
    "\n",
    "**5. Treating a non-significant LRT as evidence that the simpler model is correct**  \n",
    "A non-significant LRT means the data are consistent with the simpler model — it does not confirm that the simpler model is true. The test may have low power with small samples. Report confidence intervals for the additional parameter(s) alongside the LRT result.\n",
    "\n",
    "---\n",
    "*r_methods_library · Samantha McGarrigle · [github.com/samantha-mcgarrigle](https://github.com/samantha-mcgarrigle)*"
   ]
  }
 ]
}"
