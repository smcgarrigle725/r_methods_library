{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "R", "language": "R", "name": "ir"},
  "language_info": {"name": "R"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01-overview",
   "metadata": {},
   "source": [
    "# Permutation-Based Feature Importance\n",
    "\n",
    "## Overview\n",
    "\n",
    "Permutation importance measures how much model performance degrades when a feature's values are randomly shuffled, breaking its relationship with the response. A large drop in performance = the feature is important; no drop = the model doesn't rely on it.\n",
    "\n",
    "**Algorithm:**\n",
    "1. Compute baseline performance metric (RMSE, AUC, etc.) on test data\n",
    "2. For each feature j:\n",
    "   - Permute feature j (shuffle its values randomly)\n",
    "   - Recompute performance on permuted data\n",
    "   - Importance_j = baseline − permuted performance\n",
    "3. Repeat K times; report mean ± SD\n",
    "\n",
    "**Permutation importance vs. alternatives:**\n",
    "\n",
    "| Method | Model-agnostic | Test-set | Handles correlations | Unbiased |\n",
    "|---|---|---|---|---|\n",
    "| Permutation | ✓ | ✓ | Partial | ✓ |\n",
    "| SHAP mean \\|SHAP\\| | ✓ | ✓ | Better | ✓ |\n",
    "| Gain (tree splits) | ✗ | ✗ | No | Biased |\n",
    "| RF out-of-bag | ✗ | Approx | No | ✓ |\n",
    "\n",
    "Key advantage: works with **any** model — linear, GAM, random forest, XGBoost, neural network.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02-setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(ranger)        # random forest\n",
    "library(xgboost)\n",
    "library(vip)           # vi_permute(), vip()\n",
    "library(tidymodels)    # for model-agnostic wrapper\n",
    "library(patchwork)\n",
    "\n",
    "set.seed(42)\n",
    "\n",
    "n <- 600\n",
    "perm_data <- tibble(\n",
    "  nitrate     = runif(n, 1, 10),\n",
    "  water_qual  = runif(n, 2, 9),\n",
    "  elevation   = rnorm(n, 200, 80),\n",
    "  slope_pct   = abs(rnorm(n, 10, 5)),\n",
    "  distance_km = rexp(n, 0.5),\n",
    "  noise_1     = rnorm(n),   # truly uninformative\n",
    "  noise_2     = rnorm(n),\n",
    "  richness    = round(\n",
    "    28 - 2.2*nitrate + 1.5*water_qual +\n",
    "    0.015*elevation - 0.3*slope_pct - 0.8*distance_km +\n",
    "    rnorm(n, 0, 3)\n",
    "  )\n",
    ")\n",
    "\n",
    "feat_cols <- c(\"nitrate\",\"water_qual\",\"elevation\",\n",
    "               \"slope_pct\",\"distance_km\",\"noise_1\",\"noise_2\")\n",
    "\n",
    "# Train/test split\n",
    "split    <- initial_split(perm_data, prop=0.75)\n",
    "train_df <- training(split)\n",
    "test_df  <- testing(split)\n",
    "\n",
    "# Fit random forest\n",
    "rf_fit <- ranger::ranger(\n",
    "  richness ~ .,\n",
    "  data      = train_df,\n",
    "  num.trees = 500,\n",
    "  importance= \"permutation\",  # built-in OOB permutation importance\n",
    "  seed      = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03-vip",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Permutation Importance with `vip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03-vip-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vip::vi_permute: model-agnostic permutation importance on test set\n",
    "# metric = \"rmse\": lower after permutation = important (metric is loss)\n",
    "# nsim = 10: repeat permutation 10 times; report mean ± SD\n",
    "\n",
    "pred_wrapper <- function(object, newdata) {\n",
    "  predict(object, data=newdata)$predictions\n",
    "}\n",
    "\n",
    "perm_imp <- vip::vi_permute(\n",
    "  object      = rf_fit,\n",
    "  train       = test_df,          # use TEST set — not training data\n",
    "  target      = \"richness\",\n",
    "  metric      = \"rmse\",\n",
    "  pred_wrapper= pred_wrapper,\n",
    "  nsim        = 20,\n",
    "  smaller_is_better = TRUE\n",
    ")\n",
    "\n",
    "print(perm_imp)\n",
    "\n",
    "# Plot with uncertainty\n",
    "vip::vip(\n",
    "  perm_imp,\n",
    "  num_features = 7,\n",
    "  geom   = \"point\",\n",
    "  include_type = TRUE,\n",
    "  aesthetics = list(color=\"#4a8fff\", fill=\"#4a8fff\", size=3)\n",
    ") +\n",
    "  labs(title=\"Permutation Feature Importance (test set)\",\n",
    "       subtitle=\"Importance = mean RMSE increase after permutation (n=20 repeats)\",\n",
    "       x=\"Mean importance (ΔRMSE)\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04-uncertainty",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Importance with Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04-uncertainty-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run permutation manually to get per-repetition values\n",
    "# This reveals variance in importance estimates — critical for small test sets\n",
    "\n",
    "baseline_rmse <- sqrt(mean((\n",
    "  predict(rf_fit, data=test_df)$predictions - test_df$richness\n",
    ")^2))\n",
    "\n",
    "n_sim <- 30\n",
    "imp_reps <- map_dfr(feat_cols, function(feat) {\n",
    "  map_dbl(1:n_sim, function(i) {\n",
    "    test_perm         <- test_df\n",
    "    test_perm[[feat]] <- sample(test_perm[[feat]])\n",
    "    preds_perm        <- predict(rf_fit, data=test_perm)$predictions\n",
    "    sqrt(mean((preds_perm - test_df$richness)^2)) - baseline_rmse\n",
    "  }) %>%\n",
    "    tibble(importance=.) %>%\n",
    "    mutate(feature=feat)\n",
    "}) %>%\n",
    "  group_by(feature) %>%\n",
    "  summarise(\n",
    "    mean_imp = mean(importance),\n",
    "    sd_imp   = sd(importance),\n",
    "    ci_lo    = quantile(importance, 0.025),\n",
    "    ci_hi    = quantile(importance, 0.975)\n",
    "  ) %>%\n",
    "  arrange(desc(mean_imp))\n",
    "\n",
    "ggplot(imp_reps,\n",
    "       aes(x=fct_reorder(feature, mean_imp), y=mean_imp,\n",
    "           ymin=ci_lo, ymax=ci_hi,\n",
    "           color=mean_imp > 0)) +\n",
    "  geom_hline(yintercept=0, linetype=\"dashed\", color=\"gray60\") +\n",
    "  geom_errorbar(width=0.3, linewidth=0.8) +\n",
    "  geom_point(size=3.5) +\n",
    "  scale_color_manual(values=c(\"FALSE\"=\"gray60\",\"TRUE\"=\"#4a8fff\"),\n",
    "                     guide=\"none\") +\n",
    "  coord_flip() +\n",
    "  labs(title=\"Permutation Importance with 95% CIs\",\n",
    "       subtitle=\"Noise variables should overlap zero; signal variables should not\",\n",
    "       x=NULL, y=\"Mean ΔRMSE (permuted − baseline)\") +\n",
    "  theme_minimal()\n",
    "\n",
    "cat(sprintf(\"\\nBaseline RMSE: %.3f\\n\", baseline_rmse))\n",
    "print(imp_reps %>% mutate(across(where(is.numeric), ~round(.x, 4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05-compare-models",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Comparing Importance Across Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05-compare-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same test set; same metric; different model families\n",
    "# Reveals whether feature importance is model-specific or data-driven\n",
    "\n",
    "# Linear model\n",
    "lm_fit <- lm(richness ~ ., data=train_df)\n",
    "lm_pred_fn <- function(object, newdata) predict(object, newdata=newdata)\n",
    "\n",
    "lm_imp <- vip::vi_permute(\n",
    "  object=lm_fit, train=test_df, target=\"richness\",\n",
    "  metric=\"rmse\", pred_wrapper=lm_pred_fn,\n",
    "  nsim=20, smaller_is_better=TRUE\n",
    ")\n",
    "\n",
    "# Combine and compare\n",
    "comparison_imp <- bind_rows(\n",
    "  perm_imp %>% mutate(model=\"Random Forest\"),\n",
    "  lm_imp   %>% mutate(model=\"Linear Model\")\n",
    ")\n",
    "\n",
    "ggplot(comparison_imp,\n",
    "       aes(x=fct_reorder(Variable, Importance), y=Importance,\n",
    "           fill=model)) +\n",
    "  geom_col(position=\"dodge\", alpha=0.85) +\n",
    "  scale_fill_manual(values=c(\"Random Forest\"=\"#4a8fff\",\"Linear Model\"=\"#4fffb0\")) +\n",
    "  coord_flip() +\n",
    "  labs(title=\"Permutation Importance: Random Forest vs. Linear Model\",\n",
    "       subtitle=\"Agreement = feature importance is data-driven; disagreement = model-specific\",\n",
    "       x=NULL, y=\"ΔRMSE\", fill=NULL) +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06-pitfalls",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "**1. Computing permutation importance on training data**  \n",
    "Training-set permutation importance is biased: it measures how much the model has memorised the training data, not how much the feature contributes to generalisation. Always permute on held-out test data. The difference between training and test importance rankings often reveals features the model has overfit.\n",
    "\n",
    "**2. Using only one permutation repeat**  \n",
    "Permutation importance has variance — different random shuffles give different RMSE changes. With only one repeat, you cannot distinguish a truly unimportant feature (importance near zero consistently) from a feature that happened to get a near-zero importance by chance. Use at least 10–20 repeats and report mean ± SD or 95% CIs.\n",
    "\n",
    "**3. Over-interpreting importance of correlated features**  \n",
    "When two features are highly correlated (e.g. nitrate and conductivity), permuting one may barely degrade performance because the model can compensate using the other. Permutation importance distributes importance arbitrarily between correlated features. Use SHAP or partial importance methods that condition on other features when collinearity is present.\n",
    "\n",
    "**4. Comparing importance across models with different baseline performance**  \n",
    "Importance is measured as ΔRMSE from baseline. If model A has baseline RMSE = 2.0 and model B has baseline RMSE = 5.0, identical ΔRMSE values represent very different relative importance. Normalise by baseline RMSE (ΔRMSE / baseline) for cross-model comparison.\n",
    "\n",
    "**5. Reporting importance from built-in tree importance instead of permutation**  \n",
    "Built-in random forest importance (mean decrease in impurity / Gini) is biased toward high-cardinality and continuous features, and is computed on training data. `ranger(importance='permutation')` uses OOB permutation which is better but still training-based. For publication, always use `vip::vi_permute()` on held-out test data.\n",
    "\n",
    "---\n",
    "*r_methods_library · Samantha McGarrigle · [github.com/samantha-mcgarrigle](https://github.com/samantha-mcgarrigle)*"
   ]
  }
 ]
}"
