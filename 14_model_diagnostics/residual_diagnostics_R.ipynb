{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "R", "language": "R", "name": "ir"},
  "language_info": {"name": "R"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01-overview",
   "metadata": {},
   "source": [
    "# Residual Diagnostics for Linear Models\n",
    "\n",
    "## Overview\n",
    "\n",
    "Regression diagnostics check whether the assumptions underlying a linear model are satisfied. Violated assumptions invalidate inference — p-values, confidence intervals, and predictions may all be wrong even when coefficient estimates look reasonable.\n",
    "\n",
    "**Linear model assumptions (LINE):**\n",
    "\n",
    "| Assumption | What to check | Diagnostic |\n",
    "|---|---|---|\n",
    "| **L**inearity | Residuals vs. fitted; partial residual plots | Curved pattern = non-linear relationship |\n",
    "| **I**ndependence | Residuals vs. order/time/space | Autocorrelation structure |\n",
    "| **N**ormality | Q-Q plot of residuals | Deviations from diagonal |\n",
    "| **E**qual variance | Scale-location plot | Fanning or funnel pattern |\n",
    "\n",
    "Additionally: **influential observations** (leverage × residual) can unduly control the fitted line.\n",
    "\n",
    "**Key distinction:** Normality of residuals matters for inference (p-values, CIs), not for coefficient estimation (OLS is unbiased regardless). With large n, the CLT makes inference robust to mild non-normality. Equal variance (homoskedasticity) matters more — heteroskedasticity inflates standard errors unevenly across the predictor range.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02-setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(broom)         # augment(), tidy(), glance()\n",
    "library(ggfortify)     # autoplot() for lm objects\n",
    "library(car)           # ncvTest(), vif(), influencePlot()\n",
    "library(lmtest)        # bptest() Breusch-Pagan, dwtest() Durbin-Watson\n",
    "library(patchwork)\n",
    "\n",
    "set.seed(42)\n",
    "\n",
    "n <- 180\n",
    "diag_data <- tibble(\n",
    "  nitrate    = runif(n, 1, 12),\n",
    "  water_qual = 10 - 0.6*nitrate + rnorm(n, 0, 1.2),\n",
    "  elevation  = rnorm(n, 200, 80),\n",
    "  richness   = round(25 - 1.8*nitrate + 0.8*water_qual +\n",
    "                     0.01*elevation + rnorm(n, 0, 2.5))\n",
    ")\n",
    "\n",
    "lm_fit <- lm(richness ~ nitrate + water_qual + elevation, data=diag_data)\n",
    "summary(lm_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03-plots",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The Four Standard Diagnostic Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03-plots-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ggfortify::autoplot() gives all four base-R diagnostic plots in ggplot style\n",
    "ggfortify::autoplot(\n",
    "  lm_fit,\n",
    "  which  = 1:4,\n",
    "  ncol   = 2,\n",
    "  colour = \"#4a8fff\",\n",
    "  smooth.colour = \"#ff6b6b\",\n",
    "  label.size = 3\n",
    ") +\n",
    "  patchwork::plot_annotation(\n",
    "    title    = \"Linear Model Diagnostic Plots\",\n",
    "    subtitle = \"Top-left: linearity | Top-right: normality | Bottom-left: homoskedasticity | Bottom-right: influence\"\n",
    "  )\n",
    "\n",
    "# ── Interpretation guide ──────────────────────────────────────────────────────\n",
    "cat(\"\n",
    "Plot 1 — Residuals vs. Fitted:\n",
    "  GOOD: points randomly scattered around zero; red line approximately horizontal\n",
    "  BAD:  curved pattern (non-linearity); funnel shape (heteroskedasticity)\n",
    "\n",
    "Plot 2 — Normal Q-Q:\n",
    "  GOOD: points follow the diagonal line\n",
    "  BAD:  S-curve (skewness); heavy tails (kurtosis); outlier points far from line\n",
    "\n",
    "Plot 3 — Scale-Location:\n",
    "  GOOD: points randomly scattered; red line approximately horizontal\n",
    "  BAD:  upward trend = variance increases with fitted values (right-skewed residuals)\n",
    "\n",
    "Plot 4 — Residuals vs. Leverage:\n",
    "  GOOD: most points inside Cook's distance contours\n",
    "  BAD:  points outside dashed Cook's lines = high influence; may warrant investigation\n",
    "\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04-formal-tests",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Formal Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04-tests-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug <- broom::augment(lm_fit)\n",
    "\n",
    "# ── Normality: Shapiro-Wilk (best for n < 5000) ───────────────────────────────\n",
    "sw <- shapiro.test(aug$.resid)\n",
    "cat(sprintf(\"Shapiro-Wilk normality: W=%.4f, p=%.4f%s\\n\",\n",
    "            sw$statistic, sw$p.value,\n",
    "            ifelse(sw$p.value < 0.05, \" ← significant departure\", \" ← no evidence against normality\")))\n",
    "\n",
    "# ── Heteroskedasticity: Breusch-Pagan ─────────────────────────────────────────\n",
    "bp <- lmtest::bptest(lm_fit)\n",
    "cat(sprintf(\"Breusch-Pagan: χ²=%.3f, df=%d, p=%.4f%s\\n\",\n",
    "            bp$statistic, bp$parameter, bp$p.value,\n",
    "            ifelse(bp$p.value < 0.05, \" ← significant heteroskedasticity\", \" ← no evidence of heteroskedasticity\")))\n",
    "\n",
    "# ── Autocorrelation: Durbin-Watson (for time-ordered data) ───────────────────\n",
    "dw <- lmtest::dwtest(lm_fit)\n",
    "cat(sprintf(\"Durbin-Watson: DW=%.4f, p=%.4f%s\\n\",\n",
    "            dw$statistic, dw$p.value,\n",
    "            ifelse(dw$p.value < 0.05, \" ← significant autocorrelation\", \" ← no evidence of autocorrelation\")))\n",
    "# DW near 2 = no autocorrelation; near 0 = positive; near 4 = negative\n",
    "\n",
    "# ── Non-constant variance: ncvTest (Score test) ───────────────────────────────\n",
    "ncv <- car::ncvTest(lm_fit)\n",
    "cat(sprintf(\"NCV Score test: χ²=%.3f, df=%d, p=%.4f\\n\",\n",
    "            ncv$ChiSquare, ncv$Df, ncv$p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05-partial-resid",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partial Residual Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05-partial-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Component + Residual (partial residual) plots\n",
    "# Show the marginal relationship between each predictor and the response\n",
    "# after accounting for all other predictors\n",
    "# Non-linear pattern = missing non-linear term (polynomial, spline)\n",
    "\n",
    "car::crPlots(\n",
    "  lm_fit,\n",
    "  smooth    = TRUE,\n",
    "  col       = \"#4a8fff\",\n",
    "  col.lines = c(\"#ff6b6b\", \"gray40\"),\n",
    "  main      = \"Component + Residual Plots\"\n",
    ")\n",
    "# Red line = smoothed partial residuals; blue line = linear term\n",
    "# If they diverge substantially → non-linearity in that predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06-heterosked-fix",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Handling Heteroskedasticity: Robust Standard Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06-robust-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(sandwich)   # vcovHC() — heteroskedasticity-consistent covariance\n",
    "library(lmtest)     # coeftest()\n",
    "\n",
    "# HC3 robust standard errors (recommended for small–moderate n)\n",
    "robust_se <- lmtest::coeftest(\n",
    "  lm_fit,\n",
    "  vcov = sandwich::vcovHC(lm_fit, type=\"HC3\")\n",
    ")\n",
    "\n",
    "# Compare OLS vs. robust SEs\n",
    "comparison <- bind_rows(\n",
    "  broom::tidy(lm_fit) %>% mutate(se_type=\"OLS\"),\n",
    "  broom::tidy(robust_se) %>% mutate(se_type=\"HC3 Robust\")\n",
    ") %>%\n",
    "  filter(term != \"(Intercept)\") %>%\n",
    "  select(se_type, term, estimate, std.error, p.value) %>%\n",
    "  mutate(across(where(is.numeric), ~round(.x, 4)))\n",
    "\n",
    "print(comparison)\n",
    "# If SEs differ substantially: OLS inference is unreliable; report robust SEs\n",
    "# Estimates are identical — only standard errors (and thus p-values) change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07-pitfalls",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "**1. Relying solely on formal tests for assumption checking**  \n",
    "The Shapiro-Wilk test has low power in small samples (may miss real non-normality) and near-certain rejection in large samples (flags trivially small departures). Always inspect the Q-Q plot visually and use formal tests as supporting evidence. The visual assessment is more informative about the nature and severity of any violation.\n",
    "\n",
    "**2. Transforming the response to fix non-normality instead of heteroskedasticity**  \n",
    "Log-transforming the response is often recommended for non-normal residuals. But if the true problem is heteroskedasticity — variance proportional to the mean — the log transform fixes both simultaneously. If the problem is only skewed residuals with constant variance, a log transform changes the model's mean function and complicates interpretation. Diagnose which assumption is violated before choosing the remedy.\n",
    "\n",
    "**3. Ignoring partial residual plots when the global residual plot looks fine**  \n",
    "A residual vs. fitted plot can look approximately flat even when individual predictors have non-linear relationships, because non-linearities from different predictors cancel out. Always inspect component-plus-residual plots for each predictor separately.\n",
    "\n",
    "**4. Treating Durbin-Watson as a general autocorrelation test**  \n",
    "Durbin-Watson only detects first-order autocorrelation (lag-1). For spatial data or higher-order temporal autocorrelation, use a variogram or ACF/PACF of residuals instead.\n",
    "\n",
    "**5. Applying linear model diagnostics to GLMs without adjustment**  \n",
    "Raw residuals from GLMs (logistic, Poisson) are not expected to be normal or have constant variance — these are features of the error distribution, not violations. Use Pearson or deviance residuals for GLMs, and DHARMa simulation-based residuals for GLMMs. See `dharma_diagnostics.ipynb`.\n",
    "\n",
    "---\n",
    "*r_methods_library · Samantha McGarrigle · [github.com/samantha-mcgarrigle](https://github.com/samantha-mcgarrigle)*"
   ]
  }
 ]
}"
