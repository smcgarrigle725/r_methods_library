{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "R", "language": "R", "name": "ir"},
  "language_info": {"name": "R"}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01-overview",
   "metadata": {},
   "source": [
    "# Multicollinearity: Detection and Remedies\n",
    "\n",
    "## Overview\n",
    "\n",
    "Multicollinearity occurs when predictors are highly correlated. It does not bias coefficient estimates, but inflates their standard errors — making it difficult to determine which predictors are driving the response. Severe collinearity makes individual coefficients unreliable even when the model predicts well.\n",
    "\n",
    "**Effects of collinearity:**\n",
    "- Inflated standard errors → wide confidence intervals\n",
    "- Unstable coefficients — small data changes produce large coefficient swings\n",
    "- Individual predictors appear non-significant despite strong joint predictive power\n",
    "- Coefficients may have unexpected signs\n",
    "\n",
    "**Detection tools:**\n",
    "\n",
    "| Tool | Threshold | Notes |\n",
    "|---|---|---|\n",
    "| Correlation matrix | \\|r\\| > 0.7 | Pairwise only; misses multivariate collinearity |\n",
    "| VIF (Variance Inflation Factor) | VIF > 5 concerning; > 10 severe | Captures multivariate collinearity |\n",
    "| Condition number | > 30 concerning | Eigenvalue-based; most sensitive |\n",
    "| Tolerance | < 0.1 | Tolerance = 1/VIF |\n",
    "\n",
    "**VIF formula:** $\\text{VIF}_j = \\frac{1}{1-R^2_j}$ where $R^2_j$ is the R² from regressing predictor $j$ on all other predictors.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02-setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(car)           # vif()\n",
    "library(corrplot)      # corrplot()\n",
    "library(glmnet)        # ridge regression\n",
    "library(patchwork)\n",
    "\n",
    "set.seed(42)\n",
    "\n",
    "n <- 200\n",
    "# Create correlated predictors\n",
    "nitrate     <- rnorm(n, 4, 1.5)\n",
    "phosphorus  <- 0.85*nitrate + rnorm(n, 0, 0.4)      # r ≈ 0.90 with nitrate\n",
    "ammonia     <- 0.70*nitrate + rnorm(n, 0, 0.6)      # r ≈ 0.75 with nitrate\n",
    "conductivity<- 30*nitrate + rnorm(n, 100, 15)        # r ≈ 0.95 with nitrate\n",
    "water_qual  <- 10 - 0.6*nitrate + rnorm(n, 0, 1)    # negatively correlated\n",
    "elevation   <- rnorm(n, 200, 80)                     # independent\n",
    "\n",
    "mc_data <- tibble(\n",
    "  nitrate, phosphorus, ammonia, conductivity, water_qual, elevation,\n",
    "  richness = 25 - 1.5*nitrate + 0.8*water_qual +\n",
    "             0.01*elevation + rnorm(n, 0, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03-detect",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03-detect-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Correlation matrix ────────────────────────────────────────────────────────\n",
    "pred_cols <- c(\"nitrate\",\"phosphorus\",\"ammonia\",\"conductivity\",\"water_qual\",\"elevation\")\n",
    "cor_mat   <- cor(mc_data[, pred_cols])\n",
    "\n",
    "corrplot::corrplot(\n",
    "  cor_mat,\n",
    "  method   = \"color\",\n",
    "  type     = \"upper\",\n",
    "  addCoef.col = \"black\",\n",
    "  number.cex  = 0.8,\n",
    "  col      = colorRampPalette(c(\"#d73027\",\"white\",\"#1a9641\"))(100),\n",
    "  tl.col   = \"gray30\",\n",
    "  title    = \"Predictor Correlation Matrix\",\n",
    "  mar      = c(0,0,2,0)\n",
    ")\n",
    "\n",
    "# ── VIF ───────────────────────────────────────────────────────────────────────\n",
    "# Fit model with all predictors\n",
    "lm_full <- lm(richness ~ nitrate + phosphorus + ammonia +\n",
    "                conductivity + water_qual + elevation,\n",
    "              data=mc_data)\n",
    "\n",
    "vif_vals <- car::vif(lm_full)\n",
    "vif_df   <- tibble(\n",
    "  predictor = names(vif_vals),\n",
    "  VIF       = round(vif_vals, 2),\n",
    "  severity  = case_when(\n",
    "    VIF < 5  ~ \"Acceptable\",\n",
    "    VIF < 10 ~ \"Concerning\",\n",
    "    TRUE     ~ \"Severe\"\n",
    "  )\n",
    ")\n",
    "print(vif_df)\n",
    "\n",
    "ggplot(vif_df, aes(x=fct_reorder(predictor, VIF), y=VIF, fill=severity)) +\n",
    "  geom_col(alpha=0.85) +\n",
    "  geom_hline(yintercept=c(5,10), linetype=\"dashed\", color=\"gray40\") +\n",
    "  scale_fill_manual(values=c(Acceptable=\"#4a8fff\",Concerning=\"#ffd166\",Severe=\"#ff6b6b\")) +\n",
    "  coord_flip() +\n",
    "  labs(title=\"Variance Inflation Factors\",\n",
    "       subtitle=\"Dashed: VIF=5 (concerning) and VIF=10 (severe)\",\n",
    "       x=NULL, y=\"VIF\", fill=NULL) +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04-remedies",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Remedies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04-remedies-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Option 1: Remove redundant predictors ─────────────────────────────────────\n",
    "# Remove conductivity (r=0.95 with nitrate; adds no independent information)\n",
    "# Remove ammonia (r=0.75 with nitrate; covered by nitrate)\n",
    "lm_reduced <- lm(richness ~ nitrate + phosphorus + water_qual + elevation,\n",
    "                 data=mc_data)\n",
    "vif_reduced <- car::vif(lm_reduced)\n",
    "cat(\"VIF after removing redundant predictors:\\n\")\n",
    "print(round(vif_reduced, 2))\n",
    "\n",
    "# ── Option 2: Ridge regression (L2 penalty shrinks collinear predictors) ───────\n",
    "X_mat  <- model.matrix(richness ~ nitrate + phosphorus + ammonia +\n",
    "                         conductivity + water_qual + elevation,\n",
    "                       data=mc_data)[, -1]\n",
    "y_vec  <- mc_data$richness\n",
    "X_sc   <- scale(X_mat)\n",
    "\n",
    "ridge_cv <- glmnet::cv.glmnet(X_sc, y_vec, alpha=0, nfolds=10)\n",
    "ridge_fit <- glmnet::glmnet(X_sc, y_vec, alpha=0,\n",
    "                             lambda=ridge_cv$lambda.min)\n",
    "\n",
    "cat(\"\\nRidge coefficients (all predictors retained but shrunk):\\n\")\n",
    "print(round(as.matrix(coef(ridge_fit)), 4))\n",
    "\n",
    "# ── Option 3: PCA on correlated predictors, then regress on PC scores ──────────\n",
    "pca_preds <- prcomp(X_mat, scale.=TRUE)\n",
    "pc_scores <- as_tibble(pca_preds$x[, 1:3]) %>%   # keep 3 PCs\n",
    "  bind_cols(richness=mc_data$richness)\n",
    "\n",
    "lm_pca <- lm(richness ~ PC1 + PC2 + PC3, data=pc_scores)\n",
    "cat(\"\\nVIF of PC scores (should all be 1.0 — orthogonal by construction):\\n\")\n",
    "print(round(car::vif(lm_pca), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05-pitfalls",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "**1. Using pairwise correlations as the sole collinearity check**  \n",
    "Two predictors may have low pairwise correlation but high multicollinearity when a third predictor is a linear combination of them. Always compute VIF, which captures multivariate dependencies that pairwise correlations miss.\n",
    "\n",
    "**2. Removing predictors based on VIF without considering their substantive importance**  \n",
    "VIF tells you which predictors are collinear — not which ones to remove. Removing a predictor with high VIF but strong theoretical justification may introduce omitted-variable bias. Consider instead whether two collinear predictors measure the same underlying construct and can be replaced by one, or whether ridge regression is more appropriate.\n",
    "\n",
    "**3. Computing VIF on standardised predictors**  \n",
    "VIF is invariant to scaling — standardising before computing VIF gives identical results. But scaling before removing predictors or building a reduced model changes coefficient interpretation. Scale for ridge regression; don't scale for predictor selection based on VIF.\n",
    "\n",
    "**4. Interpreting individual coefficients from a collinear model**  \n",
    "When VIF > 10, individual coefficients and their signs are unreliable. The model may predict well overall (high R²) while individual coefficient estimates are near-arbitrary. Report prediction intervals rather than individual coefficients, or switch to a method designed for collinear predictors (ridge, PCA regression).\n",
    "\n",
    "**5. Ignoring collinearity in GLMs and mixed models**  \n",
    "`car::vif()` works for GLMs and models fitted with `lme4`. Collinearity has the same inflating effect on standard errors in GLMs as in OLS — it is not mitigated by a non-Gaussian error family or random effects structure.\n",
    "\n",
    "---\n",
    "*r_methods_library · Samantha McGarrigle · [github.com/samantha-mcgarrigle](https://github.com/samantha-mcgarrigle)*"
   ]
  }
 ]
}"
