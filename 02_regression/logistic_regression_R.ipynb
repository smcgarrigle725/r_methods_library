{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "R"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01-overview",
   "metadata": {},
   "source": [
    "# Logistic Regression in R\n",
    "\n",
    "## Overview\n",
    "\n",
    "Logistic regression models the probability of a binary outcome (0/1, yes/no, present/absent) as a function of one or more predictors. Rather than predicting the outcome directly, it models the **log-odds** (logit) of the outcome, which is then transformed to a probability via the logistic function.\n",
    "\n",
    "| Model | Use Case |\n",
    "|---|---|\n",
    "| Binary logistic regression | Two-category outcome (the most common case) |\n",
    "| Logistic regression with interactions | Effect of one predictor on odds depends on another |\n",
    "| Logistic regression with offset | Accounting for unequal exposure or sampling effort |\n",
    "\n",
    "> **Key output: odds ratios (OR)**  \n",
    "> OR > 1: predictor increases the odds of the outcome  \n",
    "> OR < 1: predictor decreases the odds of the outcome  \n",
    "> OR = 1: no association\n",
    "\n",
    "## Applications by Sector\n",
    "\n",
    "| Sector | Example |\n",
    "|---|---|\n",
    "| **Ecology** | What environmental variables predict species presence vs. absence? Does sediment treatment predict bivalve survival (survived/died)? Do habitat characteristics predict nest success? |\n",
    "| **Healthcare** | What patient characteristics predict disease diagnosis (yes/no)? What factors predict 30-day hospital readmission? |\n",
    "| **Finance** | What features predict loan default (default/no default)? What transaction characteristics predict fraud? |\n",
    "| **Insurance** | What policyholder characteristics predict whether a claim is filed? What factors predict claim approval vs. denial? |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02-assumptions",
   "metadata": {},
   "source": [
    "## Assumptions Checklist\n",
    "\n",
    "- [ ] **Binary outcome:** Response variable has exactly two categories (coded 0/1)\n",
    "- [ ] **Independence:** Observations are independent — no repeated measures or clustering\n",
    "- [ ] **Linearity of log-odds:** Each continuous predictor has a linear relationship with the log-odds of the outcome (check with Box-Tidwell test or smoothed residual plots)\n",
    "- [ ] **No perfect separation:** No predictor (or combination) perfectly predicts the outcome — causes complete separation and unstable estimates\n",
    "- [ ] **No severe multicollinearity:** Check with VIF as in linear regression\n",
    "- [ ] **Adequate sample size:** At least 10-20 events (occurrences of the less frequent outcome) per predictor — the 'events per variable' (EPV) rule\n",
    "\n",
    "> **Logistic regression does NOT assume:**  \n",
    "> - Normally distributed residuals  \n",
    "> - Homoscedasticity  \n",
    "> - Linear relationship between predictors and the raw outcome\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03-setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03-setup-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Libraries ────────────────────────────────────────────────────────────────\n",
    "library(tidyverse)    # data manipulation and visualization\n",
    "library(ggplot2)      # visualization\n",
    "library(car)          # VIF, Box-Tidwell test\n",
    "library(pROC)         # ROC curves and AUC\n",
    "library(performance)  # model diagnostics\n",
    "library(effectsize)   # odds ratios with CIs\n",
    "library(broom)        # tidy model output\n",
    "library(ResourceSelection) # Hosmer-Lemeshow goodness-of-fit\n",
    "\n",
    "# ── Reproducibility ──────────────────────────────────────────────────────────\n",
    "set.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04-data",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We use the built-in `mtcars` dataset, recoding transmission type (`am`: 0 = automatic, 1 = manual) as the binary outcome, predicted by vehicle weight and horsepower. This is a clean, zero-dependency example — the same structure applies directly to species presence/absence, disease diagnosis, or loan default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04-data-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Prepare data ──────────────────────────────────────────────────────────────\n",
    "cars_logit <- mtcars %>%\n",
    "  select(am, wt, hp, mpg) %>%\n",
    "  mutate(am = factor(am, levels = c(0,1), labels = c(\"automatic\", \"manual\")))\n",
    "\n",
    "# ── Outcome balance ───────────────────────────────────────────────────────────\n",
    "table(cars_logit$am)\n",
    "prop.table(table(cars_logit$am))\n",
    "# Note: with small n, severe imbalance (< 10% minority class) is problematic\n",
    "\n",
    "# ── Exploratory plots ─────────────────────────────────────────────────────────\n",
    "ggplot(cars_logit, aes(x = wt, y = as.numeric(am) - 1, color = am)) +\n",
    "  geom_point(size = 2, alpha = 0.8) +\n",
    "  geom_smooth(method = \"glm\",\n",
    "              method.args = list(family = binomial),\n",
    "              se = TRUE, color = \"gray30\") +\n",
    "  scale_color_manual(values = c(\"#4a8fff\", \"#ff6b6b\")) +\n",
    "  labs(title = \"Probability of Manual Transmission vs. Vehicle Weight\",\n",
    "       subtitle = \"Logistic regression curve overlaid\",\n",
    "       x = \"Weight (1000 lbs)\", y = \"P(manual transmission)\",\n",
    "       color = \"Transmission\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05-assumptions-testing",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Assumptions Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05-assumptions-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Fit initial model for assumption checks ───────────────────────────────────\n",
    "model_logit <- glm(am ~ wt + hp, data = cars_logit, family = binomial)\n",
    "\n",
    "# ── Linearity of log-odds: Box-Tidwell test ───────────────────────────────────\n",
    "# Tests whether log(predictor) interaction is significant\n",
    "# Non-significant → linearity of log-odds assumption met\n",
    "car::boxTidwell(am ~ wt + hp,\n",
    "                data = cars_logit %>% mutate(am = as.numeric(am) - 1))\n",
    "\n",
    "# ── Alternative: plot log-odds vs. predictor ──────────────────────────────────\n",
    "# Bin continuous predictor and compute observed log-odds per bin\n",
    "cars_logit %>%\n",
    "  mutate(am_num = as.numeric(am) - 1,\n",
    "         wt_bin = cut(wt, breaks = 5)) %>%\n",
    "  group_by(wt_bin) %>%\n",
    "  summarise(p = mean(am_num), .groups = \"drop\") %>%\n",
    "  mutate(logodds = log(p / (1 - p))) %>%\n",
    "  ggplot(aes(x = wt_bin, y = logodds, group = 1)) +\n",
    "  geom_line(color = \"#4a8fff\") +\n",
    "  geom_point(size = 3) +\n",
    "  labs(title = \"Log-Odds of Manual Transmission by Weight Group\",\n",
    "       subtitle = \"Should be approximately linear\",\n",
    "       x = \"Weight (binned)\", y = \"Log-Odds\") +\n",
    "  theme_minimal()\n",
    "\n",
    "# ── Multicollinearity ─────────────────────────────────────────────────────────\n",
    "car::vif(model_logit)\n",
    "# VIF < 5: acceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06-model-fit",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Fitting & Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06-model-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Fit model ────────────────────────────────────────────────────────────────\n",
    "model_logit <- glm(am ~ wt + hp,\n",
    "                   data   = cars_logit,\n",
    "                   family = binomial(link = \"logit\"))\n",
    "summary(model_logit)\n",
    "# Output: log-odds coefficients, not probabilities or odds ratios directly\n",
    "\n",
    "# ── Odds ratios: exponentiate coefficients ────────────────────────────────────\n",
    "exp(coef(model_logit))          # point estimates\n",
    "exp(confint(model_logit))       # 95% CIs (profile likelihood — preferred)\n",
    "\n",
    "# Tidy version with ORs and CIs in one table\n",
    "broom::tidy(model_logit, exponentiate = TRUE, conf.int = TRUE) %>%\n",
    "  mutate(across(where(is.numeric), ~ round(.x, 3)))\n",
    "\n",
    "# ── Predicted probabilities ───────────────────────────────────────────────────\n",
    "# type = \"response\" converts log-odds to probability scale\n",
    "cars_logit$pred_prob <- predict(model_logit, type = \"response\")\n",
    "\n",
    "# Predicted class using 0.5 threshold (adjust based on context)\n",
    "cars_logit$pred_class <- ifelse(cars_logit$pred_prob >= 0.5, \"manual\", \"automatic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07-model-eval",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07-model-eval-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Confusion matrix ──────────────────────────────────────────────────────────\n",
    "conf_mat <- table(\n",
    "  Predicted = cars_logit$pred_class,\n",
    "  Actual    = cars_logit$am\n",
    ")\n",
    "print(conf_mat)\n",
    "\n",
    "# Accuracy\n",
    "accuracy <- sum(diag(conf_mat)) / sum(conf_mat)\n",
    "cat(sprintf(\"Accuracy: %.1f%%\\n\", accuracy * 100))\n",
    "\n",
    "# ── ROC curve and AUC ─────────────────────────────────────────────────────────\n",
    "roc_obj <- pROC::roc(\n",
    "  response  = as.numeric(cars_logit$am) - 1,\n",
    "  predictor = cars_logit$pred_prob\n",
    ")\n",
    "pROC::auc(roc_obj)\n",
    "# AUC interpretation:\n",
    "# 0.5: no discrimination (random)\n",
    "# 0.7-0.8: acceptable\n",
    "# 0.8-0.9: excellent\n",
    "# > 0.9: outstanding\n",
    "\n",
    "plot(roc_obj,\n",
    "     main   = \"ROC Curve\",\n",
    "     col    = \"#4a8fff\",\n",
    "     legacy.axes = TRUE)\n",
    "abline(a = 0, b = 1, lty = 2, col = \"gray60\")  # random classifier baseline\n",
    "\n",
    "# ── Hosmer-Lemeshow goodness-of-fit ──────────────────────────────────────────\n",
    "# Tests whether predicted probabilities match observed outcomes across deciles\n",
    "# H0: model fits well\n",
    "# p > 0.05: no evidence of poor fit\n",
    "ResourceSelection::hoslem.test(\n",
    "  x = as.numeric(cars_logit$am) - 1,\n",
    "  y = cars_logit$pred_prob,\n",
    "  g = 10\n",
    ")\n",
    "\n",
    "# ── Pseudo R² (model fit, not variance explained) ────────────────────────────\n",
    "performance::r2(model_logit)\n",
    "# McFadden's R²: 0.2-0.4 indicates excellent fit\n",
    "# Compare to null model — not directly interpretable as variance explained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08-visualization",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Visualizing Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08-visualization-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Predicted probability curve over range of weight ─────────────────────────\n",
    "pred_df <- expand.grid(\n",
    "  wt = seq(min(mtcars$wt), max(mtcars$wt), length.out = 100),\n",
    "  hp = mean(mtcars$hp)  # hold hp at its mean\n",
    ") %>%\n",
    "  mutate(pred_prob = predict(model_logit, newdata = ., type = \"response\"))\n",
    "\n",
    "ggplot() +\n",
    "  geom_ribbon(data = pred_df,\n",
    "              aes(x = wt,\n",
    "                  ymin = pred_prob - 1.96 * sqrt(pred_prob*(1-pred_prob)/nrow(mtcars)),\n",
    "                  ymax = pred_prob + 1.96 * sqrt(pred_prob*(1-pred_prob)/nrow(mtcars))),\n",
    "              alpha = 0.15, fill = \"#4a8fff\") +\n",
    "  geom_line(data = pred_df, aes(x = wt, y = pred_prob),\n",
    "            color = \"#4a8fff\", linewidth = 1) +\n",
    "  geom_jitter(data = cars_logit,\n",
    "              aes(x = wt, y = as.numeric(am) - 1, color = am),\n",
    "              height = 0.02, size = 2, alpha = 0.8) +\n",
    "  scale_color_manual(values = c(\"#ff6b6b\", \"#4fffb0\")) +\n",
    "  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"gray50\") +\n",
    "  labs(title = \"Predicted Probability of Manual Transmission\",\n",
    "       subtitle = \"Horsepower held at mean; dashed line = 0.5 decision threshold\",\n",
    "       x = \"Weight (1000 lbs)\",\n",
    "       y = \"P(manual)\",\n",
    "       color = \"Actual\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09-reporting",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reporting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09-reporting-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Full results table ────────────────────────────────────────────────────────\n",
    "broom::tidy(model_logit, exponentiate = TRUE, conf.int = TRUE) %>%\n",
    "  rename(OR = estimate, lower_95 = conf.low, upper_95 = conf.high) %>%\n",
    "  mutate(across(where(is.numeric), ~ round(.x, 3)))\n",
    "\n",
    "# ── Model fit ─────────────────────────────────────────────────────────────────\n",
    "cat(sprintf(\"AUC = %.3f\\n\", as.numeric(pROC::auc(roc_obj))))\n",
    "cat(sprintf(\"McFadden R² = %.3f\\n\",\n",
    "            as.numeric(performance::r2(model_logit)$R2_McFadden)))\n",
    "\n",
    "# Standard reporting format:\n",
    "# \"Vehicle weight was a significant negative predictor of manual transmission\n",
    "#  (OR = 0.03, 95% CI [0.001, 0.28], p = .006): heavier vehicles had lower\n",
    "#  odds of manual transmission. The model showed good discrimination\n",
    "#  (AUC = 0.93, McFadden R² = 0.59).\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10-pitfalls",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "**1. Interpreting coefficients as probabilities**  \n",
    "Raw `glm` coefficients are log-odds, not probabilities. Exponentiate to get odds ratios; use `predict(type = \"response\")` to get predicted probabilities.\n",
    "\n",
    "**2. Using the wrong threshold for classification**  \n",
    "The default 0.5 threshold is rarely optimal. In imbalanced datasets (e.g., rare fraud, rare disease), a lower threshold reduces false negatives at the cost of more false positives. Choose the threshold based on the relative costs of each error type in context.\n",
    "\n",
    "**3. Reporting accuracy alone for imbalanced outcomes**  \n",
    "A model that always predicts the majority class has high accuracy but no predictive value. Use AUC, precision-recall, F1, or sensitivity/specificity for imbalanced outcomes.\n",
    "\n",
    "**4. Not checking for complete separation**  \n",
    "If a predictor perfectly separates the two groups, the algorithm converges on infinite coefficients. Warning signs: very large coefficients, inflated standard errors. Solution: penalized regression (Firth's method via `logistf` package).\n",
    "\n",
    "**5. Ignoring the EPV rule**  \n",
    "With too few events relative to predictors, coefficients are unreliable. Aim for at least 10-20 events (occurrences of the rarer outcome) per predictor in the model.\n",
    "\n",
    "**6. Using pseudo R² as variance explained**  \n",
    "McFadden's R² and similar measures are not directly analogous to R² in linear regression. Use AUC and calibration metrics as primary evaluation tools.\n",
    "\n",
    "---\n",
    "\n",
    "## Extensions\n",
    "\n",
    "| Situation | Solution |\n",
    "|---|---|\n",
    "| Outcome has 3+ unordered categories | Multinomial regression (`multinomial_regression.ipynb`) |\n",
    "| Outcome has 3+ ordered categories | Ordinal regression (`ordinal_regression.ipynb`) |\n",
    "| Severe class imbalance | SMOTE or cost-sensitive learning (`10_classification/imbalanced_data.ipynb`) |\n",
    "| Non-independent observations | Mixed effects logistic regression (`03_mixed_effects_models/glmm_basics.ipynb`) |\n",
    "| Many predictors | Regularized logistic regression (`regularized_regression.ipynb`) |\n",
    "\n",
    "---\n",
    "*r_methods_library · Samantha McGarrigle · [github.com/samantha-mcgarrigle](https://github.com/samantha-mcgarrigle)*"
   ]
  }
 ]
}"
