{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "R"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01-overview",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression in R\n",
    "\n",
    "## Overview\n",
    "\n",
    "Multinomial logistic regression extends binary logistic regression to outcomes with **three or more unordered categories**. It fits a separate set of log-odds coefficients for each category relative to a chosen reference category, so a model with k outcome levels produces k-1 sets of coefficients.\n",
    "\n",
    "| Model | Use Case |\n",
    "|---|---|\n",
    "| Multinomial logistic regression | 3+ outcome categories with no natural order |\n",
    "| Binary logistic regression | 2 outcome categories (see `logistic_regression.ipynb`) |\n",
    "| Ordinal logistic regression | 3+ outcome categories with a meaningful order (see `ordinal_regression.ipynb`) |\n",
    "\n",
    "> **Key output: relative risk ratios (RRR) / odds ratios per category**  \n",
    "> Each coefficient compares one outcome category to the reference category.  \n",
    "> A positive coefficient means the predictor increases the log-odds of that category vs. the reference.\n",
    "\n",
    "## Applications by Sector\n",
    "\n",
    "| Sector | Example |\n",
    "|---|---|\n",
    "| **Ecology** | What environmental variables predict which foraging behavior a tern exhibits (diving, hovering, or transiting)? What predicts habitat type used (marsh, upland, or mudflat)? |\n",
    "| **Healthcare** | What patient characteristics predict diagnosis category (condition A, B, or C)? What factors predict discharge disposition (home, rehab, or long-term care)? |\n",
    "| **Finance** | What features predict credit rating category (AAA, AA, A, BBB)? What predicts customer segment (high-value, mid-tier, or at-risk)? |\n",
    "| **Insurance** | What policyholder characteristics predict claim type (property, liability, or no claim)? What predicts policy tier chosen? |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02-assumptions",
   "metadata": {},
   "source": [
    "## Assumptions Checklist\n",
    "\n",
    "- [ ] **Unordered outcome:** Categories have no natural ranking — if they do, use ordinal regression instead\n",
    "- [ ] **Independence of observations:** No repeated measures or clustering\n",
    "- [ ] **Independence of irrelevant alternatives (IIA):** The odds ratio between any two categories is unaffected by the presence or absence of other categories — test with Hausman-McFadden test\n",
    "- [ ] **Linearity of log-odds:** Each continuous predictor has a linear relationship with the log-odds for each category comparison\n",
    "- [ ] **No perfect separation:** No predictor perfectly predicts membership in any category\n",
    "- [ ] **Adequate sample size:** At least 10-20 observations per outcome category per predictor (events per variable rule applies per category)\n",
    "- [ ] **No severe multicollinearity:** Check with VIF on component binary models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03-setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03-setup-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Libraries ────────────────────────────────────────────────────────────────\n",
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(nnet)         # multinom() for multinomial logistic regression\n",
    "library(broom)        # tidy model output\n",
    "library(car)          # VIF\n",
    "library(effects)      # marginal effects plots\n",
    "library(ggeffects)    # ggplot2-compatible marginal effects\n",
    "\n",
    "set.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04-data",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We use the built-in `iris` dataset: species (setosa, versicolor, virginica) as the three-category unordered outcome, predicted by sepal and petal measurements. This is a classic multiclass classification problem — the same structure applies directly to habitat type, diagnosis category, or customer segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04-data-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Inspect outcome distribution ──────────────────────────────────────────────\n",
    "table(iris$Species)\n",
    "prop.table(table(iris$Species))\n",
    "# Balanced classes here — real data often is not\n",
    "\n",
    "# ── Set reference category ────────────────────────────────────────────────────\n",
    "# All coefficients will be interpreted relative to this category\n",
    "# Choose the most natural reference (e.g. control group, most common category)\n",
    "iris$Species <- relevel(iris$Species, ref = \"setosa\")\n",
    "\n",
    "# ── Exploratory: predictor distributions by species ───────────────────────────\n",
    "iris %>%\n",
    "  pivot_longer(cols = -Species, names_to = \"measure\", values_to = \"value\") %>%\n",
    "  ggplot(aes(x = Species, y = value, fill = Species)) +\n",
    "  geom_boxplot(alpha = 0.7) +\n",
    "  facet_wrap(~measure, scales = \"free_y\") +\n",
    "  scale_fill_manual(values = c(\"#4a8fff\", \"#4fffb0\", \"#ffd166\")) +\n",
    "  labs(title = \"Predictor Distributions by Species\",\n",
    "       subtitle = \"Checking for separation between categories\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05-assumptions-testing",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Assumptions Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05-assumptions-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Sample size per category ──────────────────────────────────────────────────\n",
    "# Rough guideline: >= 10-20 observations per category per predictor\n",
    "n_predictors <- 2  # wt and hp in our model\n",
    "cat(\"Observations per category:\\n\")\n",
    "print(table(iris$Species))\n",
    "cat(sprintf(\"\\nMinimum recommended per category: %d\\n\", n_predictors * 10))\n",
    "\n",
    "# ── Linearity of log-odds: check visually per category ───────────────────────\n",
    "# Create binary indicators for each category vs. reference\n",
    "iris_check <- iris %>%\n",
    "  mutate(\n",
    "    versicolor_vs_setosa = as.integer(Species == \"versicolor\"),\n",
    "    virginica_vs_setosa  = as.integer(Species == \"virginica\")\n",
    "  )\n",
    "\n",
    "# Plot log-odds vs. Petal.Length for each binary comparison\n",
    "iris_check %>%\n",
    "  mutate(pl_bin = cut(Petal.Length, breaks = 5)) %>%\n",
    "  group_by(pl_bin) %>%\n",
    "  summarise(\n",
    "    p_vers = mean(versicolor_vs_setosa),\n",
    "    p_virg = mean(virginica_vs_setosa)\n",
    "  ) %>%\n",
    "  mutate(\n",
    "    logodds_vers = log(p_vers / (1 - p_vers)),\n",
    "    logodds_virg = log(p_virg / (1 - p_virg))\n",
    "  ) %>%\n",
    "  select(pl_bin, logodds_vers, logodds_virg) %>%\n",
    "  pivot_longer(-pl_bin, names_to = \"comparison\", values_to = \"logodds\") %>%\n",
    "  ggplot(aes(x = pl_bin, y = logodds, color = comparison, group = comparison)) +\n",
    "  geom_line() + geom_point(size = 2) +\n",
    "  scale_color_manual(values = c(\"#4a8fff\", \"#ff6b6b\")) +\n",
    "  labs(title = \"Log-Odds vs. Petal Length (binned)\",\n",
    "       subtitle = \"Should be approximately linear for each comparison\",\n",
    "       x = \"Petal Length (binned)\", y = \"Log-Odds\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06-fit",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06-fit-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Fit multinomial model ─────────────────────────────────────────────────────\n",
    "# nnet::multinom fits k-1 binary logistic models simultaneously\n",
    "# trace = FALSE suppresses iteration output\n",
    "model_multi <- nnet::multinom(\n",
    "  Species ~ Petal.Length + Petal.Width,\n",
    "  data  = iris,\n",
    "  trace = FALSE\n",
    ")\n",
    "summary(model_multi)\n",
    "# Two rows of coefficients: one per non-reference category\n",
    "# Rows: versicolor vs setosa, virginica vs setosa\n",
    "\n",
    "# ── Z-statistics and p-values (not provided by default) ──────────────────────\n",
    "z_scores <- summary(model_multi)$coefficients /\n",
    "            summary(model_multi)$standard.errors\n",
    "p_values <- 2 * pnorm(abs(z_scores), lower.tail = FALSE)\n",
    "\n",
    "cat(\"\\nZ-scores:\\n\");  print(round(z_scores, 3))\n",
    "cat(\"\\nP-values:\\n\");  print(round(p_values, 4))\n",
    "\n",
    "# ── Relative risk ratios (exponentiated coefficients) ────────────────────────\n",
    "# RRR > 1: predictor increases relative probability of this category vs. reference\n",
    "# RRR < 1: predictor decreases relative probability vs. reference\n",
    "exp(coef(model_multi))\n",
    "\n",
    "# ── 95% CIs for RRRs ─────────────────────────────────────────────────────────\n",
    "exp(confint(model_multi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07-model-eval",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07-model-eval-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Predicted classes ─────────────────────────────────────────────────────────\n",
    "pred_class <- predict(model_multi, type = \"class\")\n",
    "pred_probs <- predict(model_multi, type = \"probs\")\n",
    "\n",
    "# ── Confusion matrix ──────────────────────────────────────────────────────────\n",
    "conf_mat <- table(Predicted = pred_class, Actual = iris$Species)\n",
    "print(conf_mat)\n",
    "\n",
    "# Overall accuracy\n",
    "accuracy <- sum(diag(conf_mat)) / sum(conf_mat)\n",
    "cat(sprintf(\"\\nOverall accuracy: %.1f%%\\n\", accuracy * 100))\n",
    "\n",
    "# Per-class accuracy\n",
    "cat(\"\\nPer-class accuracy:\\n\")\n",
    "print(round(diag(conf_mat) / colSums(conf_mat), 3))\n",
    "\n",
    "# ── Pseudo R² ────────────────────────────────────────────────────────────────\n",
    "# Compare log-likelihood of fitted model vs. null (intercept only)\n",
    "model_null <- nnet::multinom(Species ~ 1, data = iris, trace = FALSE)\n",
    "mcfadden_r2 <- 1 - (logLik(model_multi) / logLik(model_null))\n",
    "cat(sprintf(\"\\nMcFadden R²: %.3f\\n\", as.numeric(mcfadden_r2)))\n",
    "\n",
    "# ── AIC comparison ────────────────────────────────────────────────────────────\n",
    "AIC(model_null, model_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08-visualization",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Visualizing Predicted Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08-visualization-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Predicted probability curves over range of Petal.Length ──────────────────\n",
    "pred_grid <- data.frame(\n",
    "  Petal.Length = seq(min(iris$Petal.Length), max(iris$Petal.Length), length.out = 200),\n",
    "  Petal.Width  = mean(iris$Petal.Width)  # hold at mean\n",
    ")\n",
    "\n",
    "pred_grid <- cbind(\n",
    "  pred_grid,\n",
    "  predict(model_multi, newdata = pred_grid, type = \"probs\")\n",
    ") %>%\n",
    "  pivot_longer(cols = c(setosa, versicolor, virginica),\n",
    "               names_to  = \"Species\",\n",
    "               values_to = \"Probability\")\n",
    "\n",
    "ggplot(pred_grid, aes(x = Petal.Length, y = Probability, color = Species)) +\n",
    "  geom_line(linewidth = 1.2) +\n",
    "  scale_color_manual(values = c(\"#4a8fff\", \"#4fffb0\", \"#ffd166\")) +\n",
    "  labs(title = \"Predicted Probability of Each Species by Petal Length\",\n",
    "       subtitle = \"Petal width held at mean\",\n",
    "       x = \"Petal Length (cm)\",\n",
    "       y = \"Predicted Probability\") +\n",
    "  theme_minimal()\n",
    "\n",
    "# ── Stacked area plot: shows how probability mass shifts ─────────────────────\n",
    "ggplot(pred_grid, aes(x = Petal.Length, y = Probability, fill = Species)) +\n",
    "  geom_area() +\n",
    "  scale_fill_manual(values = c(\"#4a8fff\", \"#4fffb0\", \"#ffd166\")) +\n",
    "  labs(title = \"Probability Distribution Across Species by Petal Length\",\n",
    "       subtitle = \"Stacked area = total probability = 1 at every x value\",\n",
    "       x = \"Petal Length (cm)\",\n",
    "       y = \"Predicted Probability\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09-reporting",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reporting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09-reporting-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Clean results table ───────────────────────────────────────────────────────\n",
    "coefs  <- coef(model_multi)\n",
    "cis    <- confint(model_multi)\n",
    "rrrs   <- exp(coefs)\n",
    "ci_low <- exp(cis[,,1])\n",
    "ci_hi  <- exp(cis[,,2])\n",
    "\n",
    "for (cat in rownames(coefs)) {\n",
    "  cat(sprintf(\"\\n--- %s vs. setosa ---\\n\", cat))\n",
    "  result_df <- data.frame(\n",
    "    Term    = colnames(coefs),\n",
    "    RRR     = round(rrrs[cat, ], 3),\n",
    "    CI_low  = round(ci_low[cat, ], 3),\n",
    "    CI_high = round(ci_hi[cat, ], 3),\n",
    "    p_value = round(p_values[cat, ], 4)\n",
    "  )\n",
    "  print(result_df)\n",
    "}\n",
    "\n",
    "# Standard reporting format:\n",
    "# \"Petal length significantly predicted species membership.\n",
    "#  Compared to setosa, each 1 cm increase in petal length increased the\n",
    "#  relative risk of versicolor (RRR = X.XX, 95% CI [X.XX, X.XX], p < .001)\n",
    "#  and virginica (RRR = X.XX, 95% CI [X.XX, X.XX], p < .001).\n",
    "#  The model achieved X% accuracy and McFadden R² = 0.XX.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10-pitfalls",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "**1. Using multinomial regression for ordered outcomes**  \n",
    "If categories have a natural order (e.g. low/medium/high severity, mild/moderate/severe), use ordinal logistic regression — it is more parsimonious and respects the ordering structure.\n",
    "\n",
    "**2. Forgetting that coefficients are relative to the reference category**  \n",
    "A significant coefficient for versicolor vs. setosa says nothing about versicolor vs. virginica. To compare non-reference categories directly, refit the model with a different reference level.\n",
    "\n",
    "**3. Not computing p-values manually**  \n",
    "`nnet::multinom()` does not return p-values by default — you must compute them from z-scores as shown above. Reporting summary output without p-values is incomplete.\n",
    "\n",
    "**4. Reporting coefficients instead of relative risk ratios**  \n",
    "Exponentiate coefficients to get RRRs before reporting. Raw log-odds coefficients are difficult to interpret substantively.\n",
    "\n",
    "**5. Ignoring the IIA assumption**  \n",
    "Multinomial logistic regression assumes that the odds ratio between any two categories is unaffected by the other categories. This is not always realistic. If IIA is violated, consider nested logit or mixed logit models.\n",
    "\n",
    "**6. Small per-category sample sizes**  \n",
    "With rare categories, coefficient estimates are unstable and CIs are wide. Ensure adequate events per variable (≥ 10) for each pairwise comparison.\n",
    "\n",
    "---\n",
    "*r_methods_library · Samantha McGarrigle · [github.com/samantha-mcgarrigle](https://github.com/samantha-mcgarrigle)*"
   ]
  }
 ]
}"
