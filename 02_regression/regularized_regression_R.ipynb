{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "R"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01-overview",
   "metadata": {},
   "source": [
    "# Regularized Regression in R\n",
    "\n",
    "## Overview\n",
    "\n",
    "Regularized regression adds a penalty term to the loss function that shrinks coefficient estimates toward zero. This reduces overfitting, handles multicollinearity, and performs automatic variable selection — making it the standard approach when the number of predictors is large relative to n, or when predictors are highly correlated.\n",
    "\n",
    "| Method | Penalty | Effect |\n",
    "|---|---|---|\n",
    "| **Ridge (L2)** | Sum of squared coefficients (β²) | Shrinks all coefficients toward zero; none exactly zero; handles multicollinearity well |\n",
    "| **Lasso (L1)** | Sum of absolute coefficients (\\|β\\|) | Shrinks some coefficients to exactly zero; performs variable selection |\n",
    "| **Elastic net** | Weighted combination of L1 + L2 | Balances ridge and lasso; preferred when predictors are correlated and selection is needed |\n",
    "\n",
    "> **Choosing between them:**  \n",
    "> - Many predictors, expect most to matter → Ridge  \n",
    "> - Many predictors, expect only a few to matter → Lasso  \n",
    "> - Correlated predictors and want selection → Elastic net  \n",
    "> - Unsure → try elastic net first\n",
    "\n",
    "## Applications by Sector\n",
    "\n",
    "| Sector | Example |\n",
    "|---|---|\n",
    "| **Ecology** | Predicting invertebrate diversity from a large set of correlated water chemistry variables; selecting the most important habitat features from a wide survey instrument |\n",
    "| **Healthcare** | Predicting patient outcomes from high-dimensional clinical data with many correlated biomarkers; selecting predictors from electronic health record feature sets |\n",
    "| **Finance** | Building a credit scoring model from many correlated financial ratios; predicting asset returns from a large factor set |\n",
    "| **Insurance** | Selecting predictive features for claim frequency models from wide policyholder feature sets; handling correlated demographic and risk variables |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02-assumptions",
   "metadata": {},
   "source": [
    "## Assumptions Checklist\n",
    "\n",
    "Regularized regression inherits the structural assumptions of linear or logistic regression, with some important differences:\n",
    "\n",
    "- [ ] **Response type matches model family:** Continuous → gaussian; binary → binomial; count → poisson\n",
    "- [ ] **Predictors are scaled:** `glmnet` requires predictors to be on the same scale — standardize before fitting (done automatically by default in `glmnet`)\n",
    "- [ ] **Lambda selected by cross-validation:** Never choose the penalty parameter on the training data; always use CV\n",
    "- [ ] **No data leakage:** Scaling parameters (mean, SD) must be estimated on training data only and applied to test data\n",
    "- [ ] **Interpretability caveat:** Regularized coefficients are biased by design — they are optimized for prediction, not unbiased estimation. Do not interpret shrunk coefficients as you would OLS coefficients.\n",
    "\n",
    "> **Regularized regression does NOT fix:**  \n",
    "> Non-independence of observations (use mixed models), non-linearity (use GAMs or tree models), or non-normal residuals in linear regression (use appropriate GLM family)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03-setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03-setup-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Libraries ────────────────────────────────────────────────────────────────\n",
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(glmnet)       # ridge, lasso, and elastic net via penalized GLMs\n",
    "library(caret)        # cross-validation framework\n",
    "library(broom)        # tidy model output\n",
    "library(vip)          # variable importance plots\n",
    "\n",
    "set.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04-data",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We simulate a dataset with 20 predictors (many correlated) and a continuous response. This mirrors real scenarios where a large feature set needs to be reduced for a predictive model — water chemistry panels, clinical labs, financial ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04-data-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Simulate high-dimensional data with correlated predictors ─────────────────\n",
    "n  <- 200\n",
    "p  <- 20   # number of predictors\n",
    "\n",
    "# Correlated predictor matrix (mimics a water chemistry panel)\n",
    "sigma     <- matrix(0.5, p, p); diag(sigma) <- 1\n",
    "X_raw     <- MASS::mvrnorm(n, mu = rep(0, p), Sigma = sigma)\n",
    "colnames(X_raw) <- paste0(\"var\", 1:p)\n",
    "\n",
    "# Only 5 of 20 predictors truly matter\n",
    "true_betas <- c(1.5, -1.2, 0.8, 0, 0, -0.6, 0, 0, 0, 0.9,\n",
    "                rep(0, 10))\n",
    "y <- X_raw %*% true_betas + rnorm(n, 0, 1.5)\n",
    "\n",
    "# Combine into data frame\n",
    "sim_data <- as.data.frame(X_raw) %>% mutate(response = as.numeric(y))\n",
    "\n",
    "cat(sprintf(\"Dataset: %d observations, %d predictors\\n\", n, p))\n",
    "cat(\"True non-zero predictors: var1, var2, var3, var6, var10\\n\")\n",
    "\n",
    "# ── Train/test split ──────────────────────────────────────────────────────────\n",
    "train_idx  <- sample(1:n, size = floor(0.8 * n))\n",
    "train_data <- sim_data[train_idx, ]\n",
    "test_data  <- sim_data[-train_idx, ]\n",
    "\n",
    "# ── glmnet requires matrix input ──────────────────────────────────────────────\n",
    "X_train <- as.matrix(train_data[, paste0(\"var\", 1:p)])\n",
    "y_train <- train_data$response\n",
    "X_test  <- as.matrix(test_data[, paste0(\"var\", 1:p)])\n",
    "y_test  <- test_data$response\n",
    "\n",
    "# glmnet standardizes predictors internally by default (standardize = TRUE)\n",
    "# Coefficients are returned on original scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05-ridge",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ridge Regression (L2)\n",
    "\n",
    "Shrinks all coefficients toward zero but never to exactly zero. Best when most predictors contribute to the response and multicollinearity is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05-ridge-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Fit ridge over grid of lambda values ──────────────────────────────────────\n",
    "# alpha = 0 → ridge; alpha = 1 → lasso; 0 < alpha < 1 → elastic net\n",
    "ridge_fit <- glmnet(X_train, y_train, alpha = 0, family = \"gaussian\")\n",
    "\n",
    "# ── Coefficient path plot ────────────────────────────────────────────────────\n",
    "plot(ridge_fit, xvar = \"lambda\", label = TRUE,\n",
    "     main = \"Ridge: Coefficient Paths vs. Log(Lambda)\")\n",
    "# All coefficients shrink toward 0 as lambda increases\n",
    "# but none reach exactly 0 (ridge property)\n",
    "\n",
    "# ── Select optimal lambda via cross-validation ────────────────────────────────\n",
    "ridge_cv <- cv.glmnet(X_train, y_train, alpha = 0, nfolds = 10)\n",
    "plot(ridge_cv, main = \"Ridge: CV Error vs. Log(Lambda)\")\n",
    "\n",
    "# Two standard lambda choices:\n",
    "lambda_min <- ridge_cv$lambda.min    # minimizes CV error\n",
    "lambda_1se <- ridge_cv$lambda.1se    # largest lambda within 1 SE of minimum\n",
    "                                     # more regularized, often preferred\n",
    "cat(sprintf(\"lambda.min = %.4f | lambda.1se = %.4f\\n\", lambda_min, lambda_1se))\n",
    "\n",
    "# ── Final ridge model at lambda.1se ──────────────────────────────────────────\n",
    "ridge_coefs <- coef(ridge_cv, s = \"lambda.1se\")\n",
    "print(round(ridge_coefs, 4))\n",
    "\n",
    "# ── Test set performance ──────────────────────────────────────────────────────\n",
    "ridge_pred <- predict(ridge_cv, newx = X_test, s = \"lambda.1se\")\n",
    "ridge_rmse <- sqrt(mean((y_test - ridge_pred)^2))\n",
    "ridge_r2   <- cor(y_test, ridge_pred)^2\n",
    "cat(sprintf(\"Ridge — Test RMSE: %.3f | Test R²: %.3f\\n\", ridge_rmse, ridge_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06-lasso",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lasso Regression (L1)\n",
    "\n",
    "Shrinks some coefficients to exactly zero, performing automatic variable selection. Best when you believe only a subset of predictors truly matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06-lasso-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Fit lasso via cross-validation ───────────────────────────────────────────\n",
    "lasso_cv <- cv.glmnet(X_train, y_train, alpha = 1, nfolds = 10)\n",
    "\n",
    "# ── Coefficient path ──────────────────────────────────────────────────────────\n",
    "plot(lasso_cv$glmnet.fit, xvar = \"lambda\", label = TRUE,\n",
    "     main = \"Lasso: Coefficient Paths vs. Log(Lambda)\")\n",
    "# Coefficients drop to exactly 0 as lambda increases\n",
    "# Numbers at top = number of non-zero coefficients at each lambda\n",
    "\n",
    "plot(lasso_cv, main = \"Lasso: CV Error vs. Log(Lambda)\")\n",
    "\n",
    "# ── Selected variables at lambda.1se ─────────────────────────────────────────\n",
    "lasso_coefs <- coef(lasso_cv, s = \"lambda.1se\")\n",
    "selected    <- lasso_coefs[lasso_coefs[, 1] != 0, , drop = FALSE]\n",
    "cat(\"Non-zero coefficients selected by lasso:\\n\")\n",
    "print(round(selected, 4))\n",
    "# Compare to true non-zero: var1, var2, var3, var6, var10\n",
    "\n",
    "# ── Test set performance ──────────────────────────────────────────────────────\n",
    "lasso_pred <- predict(lasso_cv, newx = X_test, s = \"lambda.1se\")\n",
    "lasso_rmse <- sqrt(mean((y_test - lasso_pred)^2))\n",
    "lasso_r2   <- cor(y_test, lasso_pred)^2\n",
    "cat(sprintf(\"Lasso — Test RMSE: %.3f | Test R²: %.3f\\n\", lasso_rmse, lasso_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07-elasticnet",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Elastic Net\n",
    "\n",
    "Combines L1 and L2 penalties. The `alpha` parameter controls the mix: alpha = 1 is lasso, alpha = 0 is ridge. Values between 0 and 1 blend both. Tuning alpha via an outer cross-validation loop is best practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07-elasticnet-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Tune alpha and lambda simultaneously ──────────────────────────────────────\n",
    "# Outer loop: try multiple alpha values\n",
    "# Inner loop: cv.glmnet selects best lambda for each alpha\n",
    "alpha_grid  <- seq(0, 1, by = 0.1)\n",
    "enet_results <- map_dfr(alpha_grid, function(a) {\n",
    "  cv_fit <- cv.glmnet(X_train, y_train, alpha = a, nfolds = 10)\n",
    "  tibble(\n",
    "    alpha      = a,\n",
    "    lambda_min = cv_fit$lambda.min,\n",
    "    lambda_1se = cv_fit$lambda.1se,\n",
    "    cvm_min    = min(cv_fit$cvm)  # minimum CV mean squared error\n",
    "  )\n",
    "})\n",
    "\n",
    "print(enet_results)\n",
    "best_alpha <- enet_results$alpha[which.min(enet_results$cvm_min)]\n",
    "cat(sprintf(\"\\nBest alpha: %.1f\\n\", best_alpha))\n",
    "\n",
    "# ── Fit final elastic net with best alpha ─────────────────────────────────────\n",
    "enet_cv <- cv.glmnet(X_train, y_train, alpha = best_alpha, nfolds = 10)\n",
    "\n",
    "enet_coefs <- coef(enet_cv, s = \"lambda.1se\")\n",
    "enet_selected <- enet_coefs[enet_coefs[, 1] != 0, , drop = FALSE]\n",
    "cat(\"Non-zero coefficients selected by elastic net:\\n\")\n",
    "print(round(enet_selected, 4))\n",
    "\n",
    "# ── Test set performance ──────────────────────────────────────────────────────\n",
    "enet_pred <- predict(enet_cv, newx = X_test, s = \"lambda.1se\")\n",
    "enet_rmse <- sqrt(mean((y_test - enet_pred)^2))\n",
    "enet_r2   <- cor(y_test, enet_pred)^2\n",
    "cat(sprintf(\"Elastic Net — Test RMSE: %.3f | Test R²: %.3f\\n\", enet_rmse, enet_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08-comparison",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08-comparison-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── OLS benchmark ────────────────────────────────────────────────────────────\n",
    "ols_fit  <- lm(response ~ ., data = train_data)\n",
    "ols_pred <- predict(ols_fit, newdata = test_data)\n",
    "ols_rmse <- sqrt(mean((y_test - ols_pred)^2))\n",
    "ols_r2   <- cor(y_test, ols_pred)^2\n",
    "\n",
    "# ── Summary comparison table ──────────────────────────────────────────────────\n",
    "comparison <- tribble(\n",
    "  ~Model,          ~Test_RMSE,  ~Test_R2,   ~N_Predictors,\n",
    "  \"OLS\",           ols_rmse,    ols_r2,     p,\n",
    "  \"Ridge\",         ridge_rmse,  ridge_r2,   p,           # ridge keeps all\n",
    "  \"Lasso\",         lasso_rmse,  lasso_r2,   sum(lasso_coefs[-1] != 0),\n",
    "  \"Elastic Net\",   enet_rmse,   enet_r2,    sum(enet_coefs[-1] != 0)\n",
    ")\n",
    "print(comparison %>% mutate(across(where(is.numeric), ~ round(.x, 3))))\n",
    "\n",
    "# ── Coefficient comparison plot ───────────────────────────────────────────────\n",
    "coef_df <- tibble(\n",
    "  predictor = paste0(\"var\", 1:p),\n",
    "  OLS       = coef(ols_fit)[-1],\n",
    "  Ridge     = as.numeric(ridge_coefs)[-1],\n",
    "  Lasso     = as.numeric(lasso_coefs)[-1],\n",
    "  ElasticNet = as.numeric(enet_coefs)[-1],\n",
    "  True      = true_betas\n",
    ") %>%\n",
    "  pivot_longer(-predictor, names_to = \"model\", values_to = \"coefficient\")\n",
    "\n",
    "ggplot(coef_df, aes(x = predictor, y = coefficient, color = model, group = model)) +\n",
    "  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"gray70\") +\n",
    "  geom_line(alpha = 0.6) +\n",
    "  geom_point(size = 2) +\n",
    "  scale_color_manual(values = c(\"#4a8fff\", \"#4fffb0\", \"#ffd166\", \"#ff6b6b\", \"gray30\")) +\n",
    "  labs(title = \"Coefficient Estimates by Method\",\n",
    "       subtitle = \"Gray = true values; regularized methods shrink toward 0\",\n",
    "       x = \"Predictor\", y = \"Coefficient\", color = \"Model\") +\n",
    "  theme_minimal() +\n",
    "  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09-logistic",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Regularized Logistic Regression\n",
    "\n",
    "`glmnet` handles binary outcomes by setting `family = \"binomial\"`. The same ridge/lasso/elastic net logic applies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09-logistic-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Simulate binary outcome ───────────────────────────────────────────────────\n",
    "log_odds <- X_raw %*% (true_betas * 0.8)\n",
    "y_bin    <- rbinom(n, 1, prob = plogis(log_odds))\n",
    "\n",
    "X_train_bin <- X_raw[train_idx, ]\n",
    "y_train_bin <- y_bin[train_idx]\n",
    "X_test_bin  <- X_raw[-train_idx, ]\n",
    "y_test_bin  <- y_bin[-train_idx]\n",
    "\n",
    "# ── Regularized logistic regression (lasso) ───────────────────────────────────\n",
    "lasso_logit_cv <- cv.glmnet(\n",
    "  X_train_bin, y_train_bin,\n",
    "  alpha  = 1,\n",
    "  family = \"binomial\",\n",
    "  nfolds = 10\n",
    ")\n",
    "\n",
    "# Selected variables\n",
    "logit_coefs <- coef(lasso_logit_cv, s = \"lambda.1se\")\n",
    "cat(\"Selected predictors (lasso logistic regression):\\n\")\n",
    "print(logit_coefs[logit_coefs[, 1] != 0, , drop = FALSE])\n",
    "\n",
    "# ── Predicted probabilities and AUC ──────────────────────────────────────────\n",
    "pred_probs <- predict(lasso_logit_cv, newx = X_test_bin,\n",
    "                      s = \"lambda.1se\", type = \"response\")\n",
    "cat(sprintf(\"Test AUC: %.3f\\n\",\n",
    "            pROC::auc(pROC::roc(y_test_bin, as.numeric(pred_probs),\n",
    "                                quiet = TRUE))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10-pitfalls",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "**1. Not scaling predictors before fitting**  \n",
    "`glmnet` standardizes internally by default, but if you pre-process manually, ensure predictors are standardized. The penalty treats all coefficients equally, so predictors on different scales will be penalized differently if not scaled.\n",
    "\n",
    "**2. Using the training set to select lambda**  \n",
    "Always use cross-validation (`cv.glmnet`) to select lambda. Selecting lambda on the training data produces optimistic performance estimates and overfits the regularization itself.\n",
    "\n",
    "**3. Interpreting regularized coefficients as unbiased estimates**  \n",
    "Regularization intentionally biases coefficients toward zero to reduce variance. Regularized coefficients are optimized for prediction, not for unbiased estimation of true effects. Do not interpret them the same way as OLS coefficients.\n",
    "\n",
    "**4. Treating lasso-selected variables as the definitive true predictors**  \n",
    "Lasso is sensitive to collinearity — among a group of correlated predictors, it tends to select one arbitrarily. Variable selection results vary with the data sample. Report uncertainty around selection.\n",
    "\n",
    "**5. Forgetting to apply training-set scaling to test data**  \n",
    "When preprocessing manually, always fit scaling parameters (mean, SD) on training data only, then apply those same parameters to test data. Fitting on the full dataset leaks information.\n",
    "\n",
    "**6. Choosing lambda.min instead of lambda.1se without justification**  \n",
    "`lambda.min` minimizes CV error but may overfit. `lambda.1se` is more regularized and often generalizes better. Default to `lambda.1se` unless prediction accuracy on the training distribution is the primary goal.\n",
    "\n",
    "---\n",
    "\n",
    "## When to Use Each Method\n",
    "\n",
    "| Situation | Recommended Method |\n",
    "|---|---|\n",
    "| p >> n (more predictors than observations) | Lasso or elastic net |\n",
    "| Many correlated predictors, most matter | Ridge |\n",
    "| Many correlated predictors, want selection | Elastic net |\n",
    "| Grouped predictors (e.g. gene pathways) | Group lasso (see `gglasso` package) |\n",
    "| Need unbiased coefficients for inference | OLS or GLM (not regularized regression) |\n",
    "\n",
    "---\n",
    "*r_methods_library · Samantha McGarrigle · [github.com/samantha-mcgarrigle](https://github.com/samantha-mcgarrigle)*"
   ]
  }
 ]
}"
