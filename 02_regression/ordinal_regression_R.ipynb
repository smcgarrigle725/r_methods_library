{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "R"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01-overview",
   "metadata": {},
   "source": [
    "# Ordinal Logistic Regression in R\n",
    "\n",
    "## Overview\n",
    "\n",
    "Ordinal logistic regression models outcomes with **three or more ordered categories** — where the categories have a meaningful ranking but the distances between them are not assumed to be equal. It is more parsimonious than multinomial regression for ordered outcomes and respects the ordinal structure of the data.\n",
    "\n",
    "The most common form is the **proportional odds model**, which assumes that the effect of each predictor is the same across all category thresholds (the proportional odds assumption).\n",
    "\n",
    "| Model | Use Case |\n",
    "|---|---|\n",
    "| Proportional odds model | Ordered outcome, effect of predictors constant across thresholds |\n",
    "| Partial proportional odds | Some predictors violate proportional odds — relax assumption selectively |\n",
    "| Multinomial logistic | Unordered categories (see `multinomial_regression.ipynb`) |\n",
    "\n",
    "> **Key output: odds ratios**  \n",
    "> Each OR represents the change in odds of being in a *higher* category (vs. all lower categories combined) for a one-unit increase in the predictor.\n",
    "\n",
    "## Applications by Sector\n",
    "\n",
    "| Sector | Example |\n",
    "|---|---|\n",
    "| **Ecology** | What predicts invertebrate abundance class (absent/rare/common/abundant)? What factors predict habitat quality rating (poor/fair/good/excellent)? |\n",
    "| **Healthcare** | What predicts pain severity (none/mild/moderate/severe)? What factors predict patient-reported outcome score categories? What predicts cancer stage? |\n",
    "| **Finance** | What predicts credit rating tier (BBB/A/AA/AAA)? What factors predict customer satisfaction rating (1-5 stars)? |\n",
    "| **Insurance** | What predicts claim severity category (minor/moderate/major/catastrophic)? What factors predict policy tier chosen? |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02-assumptions",
   "metadata": {},
   "source": [
    "## Assumptions Checklist\n",
    "\n",
    "- [ ] **Ordered outcome:** Categories have a meaningful, consistent rank order\n",
    "- [ ] **Independence of observations:** No repeated measures or clustering\n",
    "- [ ] **Proportional odds (parallel lines):** The effect of each predictor is consistent across all category thresholds — this is the key assumption to test\n",
    "- [ ] **Linearity of log-odds:** Continuous predictors have a linear relationship with the log-odds of being in a higher category\n",
    "- [ ] **No perfect separation:** No predictor perfectly predicts category membership\n",
    "- [ ] **Adequate cell counts:** At least 5-10 observations per outcome category\n",
    "- [ ] **No severe multicollinearity:** Check VIF\n",
    "\n",
    "> **The proportional odds assumption is the most critical** — if violated for a predictor, the single OR across all thresholds is misleading. Test with the Brant test and score test.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03-setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03-setup-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Libraries ────────────────────────────────────────────────────────────────\n",
    "library(tidyverse)\n",
    "library(ggplot2)\n",
    "library(MASS)         # polr() for proportional odds model\n",
    "library(brant)        # Brant test for proportional odds assumption\n",
    "library(broom)        # tidy model output\n",
    "library(effects)      # marginal effects\n",
    "library(ggeffects)    # ggplot2 marginal effects plots\n",
    "library(performance)  # model performance metrics\n",
    "\n",
    "set.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04-data",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We simulate an ordered dataset representing **habitat quality ratings** (Poor / Fair / Good / Excellent) as a function of two continuous environmental predictors. This mirrors real ecological and industry use cases where the response is an expert rating or severity category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04-data-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Simulate ordered habitat quality data ─────────────────────────────────────\n",
    "n <- 200\n",
    "habitat_data <- tibble(\n",
    "  vegetation_cover = rnorm(n, mean = 50, sd = 20),   # % vegetation cover\n",
    "  disturbance_index = rnorm(n, mean = 5, sd = 2),    # disturbance score (higher = worse)\n",
    "  # Generate latent quality score\n",
    "  latent_quality = 0.05 * vegetation_cover -\n",
    "                   0.4  * disturbance_index +\n",
    "                   rnorm(n, 0, 1)\n",
    ") %>%\n",
    "  mutate(\n",
    "    # Cut latent score into ordered categories\n",
    "    quality = cut(\n",
    "      latent_quality,\n",
    "      breaks = quantile(latent_quality, probs = c(0, 0.25, 0.5, 0.75, 1)),\n",
    "      labels = c(\"Poor\", \"Fair\", \"Good\", \"Excellent\"),\n",
    "      include.lowest = TRUE\n",
    "    ),\n",
    "    # Ensure ordered factor\n",
    "    quality = factor(quality,\n",
    "                     levels = c(\"Poor\", \"Fair\", \"Good\", \"Excellent\"),\n",
    "                     ordered = TRUE)\n",
    "  )\n",
    "\n",
    "# ── Inspect ───────────────────────────────────────────────────────────────────\n",
    "table(habitat_data$quality)\n",
    "summary(habitat_data[, c(\"vegetation_cover\", \"disturbance_index\")])\n",
    "\n",
    "# ── Exploratory plots ─────────────────────────────────────────────────────────\n",
    "habitat_data %>%\n",
    "  pivot_longer(cols = c(vegetation_cover, disturbance_index),\n",
    "               names_to = \"predictor\", values_to = \"value\") %>%\n",
    "  ggplot(aes(x = quality, y = value, fill = quality)) +\n",
    "  geom_boxplot(alpha = 0.7) +\n",
    "  facet_wrap(~predictor, scales = \"free_y\") +\n",
    "  scale_fill_manual(values = c(\"#ff6b6b\", \"#ffd166\", \"#4fffb0\", \"#4a8fff\")) +\n",
    "  labs(title = \"Predictor Distributions by Habitat Quality Category\",\n",
    "       subtitle = \"Ordered from Poor (left) to Excellent (right)\",\n",
    "       x = \"Quality Rating\") +\n",
    "  theme_minimal() +\n",
    "  theme(legend.position = \"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05-assumptions-testing",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Assumptions Testing\n",
    "\n",
    "### Proportional Odds Assumption\n",
    "\n",
    "The proportional odds assumption states that the OR for each predictor is constant across all category thresholds. Visually, this means the regression lines for each binary split of the outcome should be parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05-po-visual-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Visual check: fit separate binary logistic models at each threshold ────────\n",
    "# If proportional odds holds, slopes should be approximately equal\n",
    "thresholds <- list(\n",
    "  \"Fair+ vs Poor\"      = as.integer(habitat_data$quality >= \"Fair\"),\n",
    "  \"Good+ vs Poor/Fair\" = as.integer(habitat_data$quality >= \"Good\"),\n",
    "  \"Excellent vs rest\"  = as.integer(habitat_data$quality == \"Excellent\")\n",
    ")\n",
    "\n",
    "threshold_coefs <- map_dfr(names(thresholds), function(thresh_name) {\n",
    "  y <- thresholds[[thresh_name]]\n",
    "  m <- glm(y ~ vegetation_cover + disturbance_index,\n",
    "            data = habitat_data, family = binomial)\n",
    "  tidy(m) %>%\n",
    "    filter(term != \"(Intercept)\") %>%\n",
    "    mutate(threshold = thresh_name)\n",
    "})\n",
    "\n",
    "# If proportional odds holds, estimates should be similar across thresholds\n",
    "ggplot(threshold_coefs, aes(x = threshold, y = estimate,\n",
    "                             color = term, group = term)) +\n",
    "  geom_line(linewidth = 1) +\n",
    "  geom_point(size = 3) +\n",
    "  geom_errorbar(aes(ymin = estimate - 1.96*std.error,\n",
    "                    ymax = estimate + 1.96*std.error),\n",
    "                width = 0.1) +\n",
    "  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"gray50\") +\n",
    "  scale_color_manual(values = c(\"#4a8fff\", \"#ff6b6b\")) +\n",
    "  labs(title = \"Proportional Odds Visual Check\",\n",
    "       subtitle = \"Coefficients should be similar across thresholds if assumption holds\",\n",
    "       x = \"Threshold\", y = \"Log-Odds Coefficient\", color = \"Predictor\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05-po-brant-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Brant test (formal test of proportional odds assumption) ──────────────────\n",
    "# Fit the model first, then test\n",
    "model_ord <- MASS::polr(\n",
    "  quality ~ vegetation_cover + disturbance_index,\n",
    "  data   = habitat_data,\n",
    "  Hess   = TRUE   # required for standard errors and Brant test\n",
    ")\n",
    "\n",
    "brant::brant(model_ord)\n",
    "# Output: omnibus test + per-predictor tests\n",
    "# H0: proportional odds assumption holds\n",
    "# p > 0.05: assumption not violated\n",
    "# p < 0.05: assumption violated for that predictor\n",
    "# — if only one predictor violates: consider partial proportional odds model\n",
    "# — if omnibus violated: consider multinomial regression instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06-fit",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06-fit-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Fit proportional odds model ───────────────────────────────────────────────\n",
    "model_ord <- MASS::polr(\n",
    "  quality ~ vegetation_cover + disturbance_index,\n",
    "  data   = habitat_data,\n",
    "  Hess   = TRUE,\n",
    "  method = \"logistic\"  # logistic link = proportional odds\n",
    "                       # alternatives: \"probit\", \"cloglog\", \"cauchit\"\n",
    ")\n",
    "summary(model_ord)\n",
    "# Output sections:\n",
    "# Coefficients: predictor effects (log-odds scale)\n",
    "# Intercepts: threshold parameters (cutpoints between ordered categories)\n",
    "\n",
    "# ── P-values (not printed by default) ────────────────────────────────────────\n",
    "coef_table <- coef(summary(model_ord))\n",
    "p_values   <- pnorm(abs(coef_table[, \"t value\"]), lower.tail = FALSE) * 2\n",
    "cbind(coef_table, p_value = round(p_values, 4))\n",
    "\n",
    "# ── Odds ratios with 95% CIs ──────────────────────────────────────────────────\n",
    "# Exponentiate to convert from log-odds to odds ratio scale\n",
    "or_table <- exp(cbind(\n",
    "  OR      = coef(model_ord),\n",
    "  CI_low  = confint(model_ord)[, 1],\n",
    "  CI_high = confint(model_ord)[, 2]\n",
    "))\n",
    "print(round(or_table, 3))\n",
    "# OR > 1: predictor increases odds of being in a higher quality category\n",
    "# OR < 1: predictor decreases odds of being in a higher quality category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07-model-eval",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07-eval-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Predicted categories ──────────────────────────────────────────────────────\n",
    "pred_class <- predict(model_ord)\n",
    "pred_probs <- predict(model_ord, type = \"probs\")\n",
    "\n",
    "# ── Confusion matrix ──────────────────────────────────────────────────────────\n",
    "conf_mat <- table(Predicted = pred_class, Actual = habitat_data$quality)\n",
    "print(conf_mat)\n",
    "cat(sprintf(\"\\nOverall accuracy: %.1f%%\\n\",\n",
    "            sum(diag(conf_mat)) / sum(conf_mat) * 100))\n",
    "\n",
    "# ── Pseudo R² ────────────────────────────────────────────────────────────────\n",
    "model_null <- MASS::polr(quality ~ 1, data = habitat_data, Hess = TRUE)\n",
    "mcfadden   <- 1 - (logLik(model_ord) / logLik(model_null))\n",
    "cat(sprintf(\"McFadden R²: %.3f\\n\", as.numeric(mcfadden)))\n",
    "\n",
    "# ── AIC ───────────────────────────────────────────────────────────────────────\n",
    "AIC(model_null, model_ord)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08-visualization",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Visualizing Predicted Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08-visualization-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Predicted probability curves over range of vegetation cover ───────────────\n",
    "pred_grid <- data.frame(\n",
    "  vegetation_cover  = seq(min(habitat_data$vegetation_cover),\n",
    "                          max(habitat_data$vegetation_cover),\n",
    "                          length.out = 200),\n",
    "  disturbance_index = mean(habitat_data$disturbance_index)\n",
    ")\n",
    "\n",
    "pred_grid <- cbind(\n",
    "  pred_grid,\n",
    "  predict(model_ord, newdata = pred_grid, type = \"probs\")\n",
    ") %>%\n",
    "  pivot_longer(cols = c(Poor, Fair, Good, Excellent),\n",
    "               names_to  = \"Quality\",\n",
    "               values_to = \"Probability\") %>%\n",
    "  mutate(Quality = factor(Quality,\n",
    "                          levels = c(\"Poor\", \"Fair\", \"Good\", \"Excellent\")))\n",
    "\n",
    "# Line plot\n",
    "ggplot(pred_grid,\n",
    "       aes(x = vegetation_cover, y = Probability, color = Quality)) +\n",
    "  geom_line(linewidth = 1.2) +\n",
    "  scale_color_manual(values = c(\"#ff6b6b\", \"#ffd166\", \"#4fffb0\", \"#4a8fff\")) +\n",
    "  labs(title = \"Predicted Probability of Each Quality Rating by Vegetation Cover\",\n",
    "       subtitle = \"Disturbance index held at mean\",\n",
    "       x = \"Vegetation Cover (%)\",\n",
    "       y = \"Predicted Probability\") +\n",
    "  theme_minimal()\n",
    "\n",
    "# Stacked area plot\n",
    "ggplot(pred_grid,\n",
    "       aes(x = vegetation_cover, y = Probability, fill = Quality)) +\n",
    "  geom_area() +\n",
    "  scale_fill_manual(values = c(\"#ff6b6b\", \"#ffd166\", \"#4fffb0\", \"#4a8fff\")) +\n",
    "  labs(title = \"Probability Distribution Across Quality Ratings\",\n",
    "       subtitle = \"Ordered from Poor (bottom) to Excellent (top)\",\n",
    "       x = \"Vegetation Cover (%)\", y = \"Predicted Probability\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09-reporting",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reporting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09-reporting-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Clean OR table ────────────────────────────────────────────────────────────\n",
    "results_df <- data.frame(\n",
    "  Predictor = names(coef(model_ord)),\n",
    "  OR        = round(exp(coef(model_ord)), 3),\n",
    "  CI_low    = round(exp(confint(model_ord)[,1]), 3),\n",
    "  CI_high   = round(exp(confint(model_ord)[,2]), 3),\n",
    "  p_value   = round(p_values[names(coef(model_ord))], 4)\n",
    ")\n",
    "print(results_df)\n",
    "\n",
    "# Standard reporting format:\n",
    "# \"Vegetation cover significantly predicted habitat quality rating\n",
    "#  (OR = X.XX, 95% CI [X.XX, X.XX], p = .XXX): each percentage point\n",
    "#  increase in vegetation cover increased the odds of being in a higher\n",
    "#  quality category by X%. The proportional odds assumption was met\n",
    "#  (Brant test, p = .XXX). McFadden R² = 0.XX.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10-pitfalls",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "**1. Not testing the proportional odds assumption**  \n",
    "This is the defining assumption of the model. Always run the Brant test. If violated for all predictors, multinomial regression is more appropriate. If violated for only one predictor, consider a partial proportional odds model.\n",
    "\n",
    "**2. Using ordinal regression for unordered categories**  \n",
    "If categories have no natural order, the proportional odds framework is not meaningful. Use multinomial logistic regression instead.\n",
    "\n",
    "**3. Forgetting that MASS::polr() uses a different sign convention**  \n",
    "`polr()` parameterizes the model so that a positive coefficient means the predictor *decreases* the odds of being in a higher category — the opposite of most software. Check the documentation and verify the direction of effects with predicted probabilities.\n",
    "\n",
    "**4. Not reporting p-values**  \n",
    "`polr()` does not return p-values by default. Always compute and report them explicitly as shown above.\n",
    "\n",
    "**5. Treating ordered categories as continuous**  \n",
    "Assigning numeric codes (1, 2, 3, 4) and running linear regression assumes equal intervals between categories. Ordinal regression makes no such assumption and is more appropriate.\n",
    "\n",
    "**6. Ignoring sparse categories**  \n",
    "Very few observations in a category (< 5) makes threshold estimation unreliable. Consider collapsing adjacent categories if conceptually justified.\n",
    "\n",
    "---\n",
    "*r_methods_library · Samantha McGarrigle · [github.com/samantha-mcgarrigle](https://github.com/samantha-mcgarrigle)*"
   ]
  }
 ]
}"
